{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the code for a pair of cleaning techniques intended to improve the effectiveness of next activity prediction on polluted datasets."
      ],
      "metadata": {
        "id": "uAonqyU2gpLQ"
      },
      "id": "uAonqyU2gpLQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "kDl5QFRr_vPp"
      },
      "id": "kDl5QFRr_vPp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "9ldr_qgr_x3J"
      },
      "id": "9ldr_qgr_x3J"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import statistics\n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from scipy.spatial import distance as scipy_distance\n",
        "\n",
        "from sklearn.cluster import HDBSCAN, AgglomerativeClustering\n",
        "from sklearn.metrics import pairwise_distances\n",
        "!pip install Levenshtein\n",
        "import Levenshtein as lev\n",
        "from collections import Counter\n",
        "\n",
        "!pip install fasttext\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "import nltk\n",
        "#nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "#fasttext.util.download_model('en', if_exists='ignore')\n",
        "nlp_model = fasttext.load_model('cc.en.300.bin')\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "LYvz9hpnFAe0"
      },
      "id": "LYvz9hpnFAe0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Globals"
      ],
      "metadata": {
        "id": "aVRMjHuLxDBy"
      },
      "id": "aVRMjHuLxDBy"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_types_1 = [\"DISTORTED\", \"POLLUTED.NORND\", \"POLLUTED.RANDOM\"]\n",
        "pollution_types_2 = [\"SYNONYM\", \"DISTORTED-activity\", \"POLLUTED.NORND-activity\", \"POLLUTED.RANDOM-activity\"]\n",
        "pollution_types_3 = [\"SYNONYM\", \"HOMONYM\", \"DISTORTED-activity\", \"POLLUTED.NORND-activity\", \"POLLUTED.RANDOM-activity\"]\n",
        "percentages = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "profiling_metrics = ['UNKNOWNS', 'DISTINCT', 'AVG_DISTINCT_PER_CASE', 'UNIQUENESS']\n",
        "dq_scorings = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
        "metrics = profiling_metrics+dq_scorings\n",
        "metrics_time = metrics + [\"time\"]\n",
        "limit = 2"
      ],
      "metadata": {
        "id": "hJDHSuJmYMmF"
      },
      "id": "hJDHSuJmYMmF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "r1xyvO2P_zdR"
      },
      "id": "r1xyvO2P_zdR"
    },
    {
      "cell_type": "code",
      "source": [
        "def profiling(test_set, df, subset=None):\n",
        "\n",
        "  scores = {}\n",
        "\n",
        "  UNKNOWNS = len(set(test_set.CCDOEV.unique())-set(df.CCDOEV.unique())) # labels found in the test set absent from the training set\n",
        "  DISTINCT = df.CCDOEV.nunique()\n",
        "  COUNT = df.CCDOEV.count()\n",
        "  AVG_DISTINCT_PER_CASE = df.groupby('NUMPRO').CCDOEV.nunique().mean()\n",
        "  UNIQUENESS = DISTINCT / COUNT\n",
        "\n",
        "  scores['UNKNOWNS'] = UNKNOWNS\n",
        "  scores['DISTINCT'] = DISTINCT\n",
        "  scores['AVG_DISTINCT_PER_CASE'] = AVG_DISTINCT_PER_CASE\n",
        "  scores['UNIQUENESS'] = UNIQUENESS\n",
        "\n",
        "  return scores"
      ],
      "metadata": {
        "id": "edhbaFidCEOv"
      },
      "id": "edhbaFidCEOv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conf_matrix(clean, dirty):\n",
        "  \"\"\"\n",
        "  Returns classification metrics for a list of labels compared to a reference\n",
        "  \"\"\"\n",
        "  out = {}\n",
        "\n",
        "  out[\"accuracy\"] = round(accuracy_score(clean, dirty),4)\n",
        "  out[\"precision\"] = round(precision_score(clean, dirty, average='weighted', zero_division=np.nan),4)\n",
        "  out[\"recall\"] = round(recall_score(clean, dirty, average='weighted', zero_division=np.nan),4)\n",
        "  out[\"f1\"] = round(f1_score(clean, dirty, average='weighted'),4)\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "OKTQ9qQxAegQ"
      },
      "id": "OKTQ9qQxAegQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clustering_cleaning(df, dist=lev.distance):\n",
        "  \"\"\"\n",
        "  Performs two-step clustering on a set of labels to dieentify the correct nummber\n",
        "  of clusters and then replace each label with the most common label of its cluster\n",
        "  \"\"\"\n",
        "  temp = df.copy()\n",
        "\n",
        "  labels = temp.CCDOEV.unique()\n",
        "\n",
        "  distances_matrix = pairwise_distances(labels, labels, metric=dist, n_jobs=-1) # Takes the most time\n",
        "\n",
        "  # First clustering to get the number of clusters\n",
        "  hdbscan = HDBSCAN(min_cluster_size=2, metric=\"precomputed\", n_jobs=-1)\n",
        "  hdbscan.fit(distances_matrix)\n",
        "\n",
        "  # print(len(np.unique(hdbscan.labels_)), \"clusters\")\n",
        "\n",
        "  num_clusters = max(hdbscan.labels_) + 1\n",
        "  if num_clusters <= 0:\n",
        "    num_clusters = 1\n",
        "\n",
        "  # Second, definitive clustering\n",
        "  agglo = AgglomerativeClustering(linkage='complete', metric=\"precomputed\", n_clusters=num_clusters)\n",
        "  agglo.fit(distances_matrix)\n",
        "\n",
        "  out = dict(zip(labels, agglo.labels_))\n",
        "\n",
        "  temp.CCDOEV = temp.CCDOEV.map(out).map({i:Counter([label for label in temp.CCDOEV if out[label]==i]).most_common(1)[0][0] for i in np.unique(agglo.labels_)})\n",
        "  return temp\n",
        "\n",
        "def get_embedding(sw):\n",
        "  \"\"\"sw can be either a string or a word\"\"\"\n",
        "  embedding = nlp_model.get_sentence_vector(sw)\n",
        "  return embedding\n",
        "\n",
        "def get_antonyms(word):\n",
        "  \"\"\"Attempts to list down antonyms of a word.\n",
        "     Works sometimes\"\"\"\n",
        "  antonyms = []\n",
        "  for syn in wordnet.synsets(word):\n",
        "      for i in syn.lemmas():\n",
        "          if i.antonyms():\n",
        "                antonyms.append(i.antonyms()[0].name())\n",
        "\n",
        "  antonyms_full = antonyms.copy()\n",
        "  for anto in antonyms:\n",
        "    for syn in wordnet.synsets(anto):\n",
        "        for lm in syn.lemmas():\n",
        "            antonyms_full.append(lm.name())\n",
        "\n",
        "  return set(antonyms_full)\n",
        "\n",
        "def my_nlp_distance(s1, s2):\n",
        "  \"\"\"\n",
        "  Returns semantic distance between two strings s1 and s2, with penalty for antonyms\n",
        "  \"\"\"\n",
        "  words1 = s1.split()\n",
        "  words2 = s2.split()\n",
        "  antos1 = []\n",
        "  antos2 = []\n",
        "\n",
        "  penalty = 0 # temp\n",
        "\n",
        "  for word in words1:\n",
        "    temp = list(get_antonyms(word))\n",
        "    antos1 += temp\n",
        "\n",
        "  for word in words2:\n",
        "    temp = list(get_antonyms(word))\n",
        "    antos2 += temp\n",
        "\n",
        "  penalty = 0.25*(len(set(words1).intersection(set(antos2)))+len(set(words2).intersection(set(antos1)))) #add a 0.25 penalty for each pair of antonyms found\n",
        "\n",
        "  return penalty + scipy_distance.cosine(get_embedding(s1), get_embedding(s2))\n",
        "\n",
        "def to_patterns(labels):\n",
        "    \"\"\"Creates a list of 3-tuples of labels\"\"\"\n",
        "    patterns = list(zip(labels[:-2], labels[1:-1], labels[2:])) # Python is an incredible language\n",
        "    return patterns\n",
        "\n",
        "def to_labels(patterns):\n",
        "    \"\"\"Takes a list of patterns and makes it a list of labels\"\"\"\n",
        "    return [patterns[0][0]] + [pattern[1] for pattern in patterns] + [patterns[-1][-1]]\n",
        "\n",
        "def patterns_distance(p1, p2):\n",
        "    \"\"\"Calculates some semantic distance between patterns,\n",
        "      defined here as the cosine distance between the embeddings\n",
        "      of same-position strings in the patterns\"\"\"\n",
        "    dist = 0\n",
        "    for i in range(3):\n",
        "        dist += my_nlp_distance(p1[i], p2[i])\n",
        "    return dist\n",
        "\n",
        "def sequence_cleaning(df):\n",
        "  \"\"\"Cleans a dataset by identifying the most common sequences of events\"\"\"\n",
        "\n",
        "  patterns = to_patterns(df.CCDOEV.values)\n",
        "  patterns_frequencies = {pattern:0 for pattern in patterns}\n",
        "  for pattern in patterns: # Count occurences of each pattern\n",
        "    patterns_frequencies[pattern]+=1\n",
        "\n",
        "  c = df.CCDOEV.value_counts().values\n",
        "  ratio = c.std() / c.mean()\n",
        "  threshold = int((0.005 if ratio < 1 else 0.01)*len(patterns)) # Empirical\n",
        "\n",
        "  frequent_patterns = [pattern for pattern, freq in patterns_frequencies.items() if freq >= threshold]\n",
        "  rare_patterns = [pattern for pattern, freq in patterns_frequencies.items() if freq < threshold]\n",
        "\n",
        "  mapping = {}\n",
        "  for x in set(patterns):\n",
        "    mapping[x] = x\n",
        "    if x in rare_patterns:\n",
        "      min = np.inf\n",
        "      for y in frequent_patterns:\n",
        "        if patterns_distance(x,y) < min:\n",
        "          min = patterns_distance(x,y)\n",
        "          mapping[x] = y\n",
        "\n",
        "  rebuilt_patterns = [mapping[pattern] for pattern in patterns]\n",
        "\n",
        "  temp = df.copy()\n",
        "  temp.CCDOEV = to_labels(rebuilt_patterns)\n",
        "\n",
        "  return temp\n",
        "\n",
        "def cleaner(df, method, dist=lev.distance):\n",
        "  \"\"\"\n",
        "  Cleans labels in dataframe df using specified method\n",
        "  \"\"\"\n",
        "  start_time = time.time()\n",
        "\n",
        "  temp = df.copy()\n",
        "  if (method==\"clustering\"):\n",
        "    temp = clustering_cleaning(temp, dist=dist)\n",
        "\n",
        "  elif (method==\"sequences\"):\n",
        "    temp = sequence_cleaning(temp)\n",
        "\n",
        "  print(f\"Took {round((time.time() - start_time)/60, 3)} minutes\")\n",
        "\n",
        "  return temp"
      ],
      "metadata": {
        "id": "l6UgatGrJlqT"
      },
      "execution_count": null,
      "outputs": [],
      "id": "l6UgatGrJlqT"
    },
    {
      "cell_type": "code",
      "source": [
        "def reference_assess(dataset, pollution_type):\n",
        "  \"\"\"\n",
        "  Computes profiling metrics for non-cleaned datasets\n",
        "  \"\"\"\n",
        "  final_scores = {}\n",
        "\n",
        "  test_set = pd.read_csv(f\"./{dataset}/{dataset}/{dataset}-TEST-CLEAN.csv\")\n",
        "\n",
        "  df_ref = pd.read_csv(f\"./{dataset}/{dataset}/{dataset}_prepared/{dataset}-TRAIN-CLEAN.csv\")\n",
        "  ref = df_ref.CCDOEV\n",
        "\n",
        "  final_scores[0.] = {}\n",
        "  final_scores[0.].update(profiling(test_set, df_ref))\n",
        "  final_scores[0.].update(conf_matrix(ref, ref))\n",
        "  final_scores[0.].update({\"time\":0.})\n",
        "\n",
        "  # Uncleaned datasets\n",
        "  for percentage in percentages:\n",
        "    scores = {}\n",
        "    final_scores[percentage] = {}\n",
        "    for i in range(8):\n",
        "      df = pd.read_csv(f\"./{dataset}/{dataset}/{dataset}_prepared/{dataset}-TRAIN-{pollution_type}-{percentage}-{i}.csv\")\n",
        "      start_time = time.time()\n",
        "\n",
        "      scores[i] = {}\n",
        "      scores[i].update(profiling(test_set, df))\n",
        "      scores[i].update(conf_matrix(df_ref.CCDOEV, df.CCDOEV))\n",
        "      scores[i].update({\"time\":0.})\n",
        "\n",
        "    final_scores[percentage] = {key:np.average(np.array([scores[i][key] for i in range(8)])) for key in scores[0]}\n",
        "\n",
        "  return final_scores"
      ],
      "metadata": {
        "id": "W8GXriEJgrsB"
      },
      "id": "W8GXriEJgrsB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_experiment(dataset, pollution_type, method, dist=lev.distance):\n",
        "  \"\"\"\n",
        "  Cleans labels in dataframe df using specified method\n",
        "  \"\"\"\n",
        "  final_scores = {}\n",
        "\n",
        "  initial_time = time.time()\n",
        "\n",
        "  test_set = pd.read_csv(f\"./{dataset}/{dataset}/{dataset}-TEST-CLEAN.csv\")\n",
        "\n",
        "  df_ref = pd.read_csv(f\"./{dataset}/{dataset}/{dataset}_prepared/{dataset}-TRAIN-CLEAN.csv\")\n",
        "\n",
        "  # Unpolluted dataset\n",
        "  start_time = time.time()\n",
        "  temp = cleaner(df_ref, method, dist=dist)\n",
        "\n",
        "  final_scores[0.] = {}\n",
        "  final_scores[0.].update(profiling(test_set, temp))\n",
        "  final_scores[0.].update(conf_matrix(df_ref.CCDOEV, temp.CCDOEV))\n",
        "  final_scores[0.].update({\"time\":time.time()-start_time})\n",
        "\n",
        "  # Polluted datasets\n",
        "  for percentage in percentages:\n",
        "    scores = {}\n",
        "    final_scores[percentage] = {}\n",
        "    for i in range(limit):\n",
        "      df = pd.read_csv(f\"./{dataset}/{dataset}/{dataset}_prepared/{dataset}-TRAIN-{pollution_type}-{percentage}-{i}.csv\")\n",
        "      start_time = time.time()\n",
        "      temp = cleaner(df, method, dist=dist)\n",
        "\n",
        "      temp.to_csv(f\"./{dataset}/{dataset}/{dataset}_cleaned/{dataset}-TRAIN-{pollution_type}-{percentage}-{i}-CLEANED-{method.upper()}-HAMMING.csv\", index=False) # TEMP: remove later\n",
        "\n",
        "      scores[i] = {}\n",
        "      scores[i].update(profiling(test_set, temp))\n",
        "      scores[i].update(conf_matrix(df_ref.CCDOEV, temp.CCDOEV))\n",
        "      scores[i].update({\"time\":time.time()-start_time})\n",
        "\n",
        "    final_scores[percentage] = {key:np.average(np.array([scores[i][key] for i in range(limit)])) for key in scores[0]}\n",
        "\n",
        "  print(f\"Total: took {round((time.time() - initial_time)/60, 3)} minutes\")\n",
        "\n",
        "  return final_scores"
      ],
      "metadata": {
        "id": "gJDEqRcsOEE2"
      },
      "id": "gJDEqRcsOEE2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "def hamm(s1,s2):\n",
        "\n",
        "  if len(s1)>len(s2):\n",
        "    s2 = s2.ljust(len(s1), \"-\")\n",
        "  else:\n",
        "    s1 = s1.ljust(len(s2), \"-\")\n",
        "\n",
        "  l1 = list(s1)\n",
        "  l2 = list(s2)\n",
        "  return distance.hamming(l1, l2)"
      ],
      "metadata": {
        "id": "0PP3Db-I3MJp"
      },
      "id": "0PP3Db-I3MJp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BPIC '11"
      ],
      "metadata": {
        "id": "PzIurNjV_gW5"
      },
      "id": "PzIurNjV_gW5"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"BPIC11_f1\""
      ],
      "metadata": {
        "id": "cwBx4eFuDCTy"
      },
      "id": "cwBx4eFuDCTy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference"
      ],
      "metadata": {
        "id": "9bZjn4jDisNt"
      },
      "id": "9bZjn4jDisNt"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "6u-Y9PsMiufH"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6u-Y9PsMiufH"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "UGvKpKhDiufH"
      },
      "execution_count": null,
      "outputs": [],
      "id": "UGvKpKhDiufH"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "UGkrvRvZiufI"
      },
      "execution_count": null,
      "outputs": [],
      "id": "UGkrvRvZiufI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering"
      ],
      "metadata": {
        "id": "zFg2T3TjCzZs"
      },
      "id": "zFg2T3TjCzZs"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"clustering\""
      ],
      "metadata": {
        "id": "GcZaJvtDDJWx"
      },
      "id": "GcZaJvtDDJWx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "i8BuruVICpJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63f6561-ef0b-4e79-9313-a60f4a823511"
      },
      "id": "i8BuruVICpJs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.013 minutes\n",
            "Took 0.026 minutes\n",
            "Took 0.03 minutes\n",
            "Took 0.023 minutes\n",
            "Took 0.055 minutes\n",
            "Took 0.056 minutes\n",
            "Took 0.061 minutes\n",
            "Took 0.173 minutes\n",
            "Took 0.157 minutes\n",
            "Took 0.166 minutes\n",
            "Took 0.393 minutes\n",
            "Took 0.366 minutes\n",
            "Took 0.292 minutes\n",
            "Took 0.437 minutes\n",
            "Took 0.431 minutes\n",
            "Took 0.443 minutes\n",
            "Took 0.599 minutes\n",
            "Took 0.633 minutes\n",
            "Took 0.6 minutes\n",
            "Total: took 5.114 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "iNl9z1Q9CxRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "603cbd21-6a75-46ce-cd07-b2b150ef0214"
      },
      "id": "iNl9z1Q9CxRr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.003 minutes\n",
            "Took 0.009 minutes\n",
            "Took 0.008 minutes\n",
            "Took 0.008 minutes\n",
            "Took 0.009 minutes\n",
            "Took 0.019 minutes\n",
            "Took 0.011 minutes\n",
            "Took 0.011 minutes\n",
            "Took 0.011 minutes\n",
            "Took 0.011 minutes\n",
            "Took 0.013 minutes\n",
            "Took 0.012 minutes\n",
            "Took 0.012 minutes\n",
            "Took 0.016 minutes\n",
            "Took 0.014 minutes\n",
            "Took 0.014 minutes\n",
            "Took 0.015 minutes\n",
            "Took 0.014 minutes\n",
            "Took 0.019 minutes\n",
            "Total: took 0.387 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "6sZeLtEeCxVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddf8399-ba14-4a48-ed0c-4005aa674814"
      },
      "id": "6sZeLtEeCxVb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.004 minutes\n",
            "Took 0.043 minutes\n",
            "Took 0.041 minutes\n",
            "Took 0.033 minutes\n",
            "Took 0.094 minutes\n",
            "Took 0.099 minutes\n",
            "Took 0.105 minutes\n",
            "Took 0.346 minutes\n",
            "Took 0.371 minutes\n",
            "Took 0.36 minutes\n",
            "Took 0.856 minutes\n",
            "Took 0.767 minutes\n",
            "Took 0.821 minutes\n",
            "Took 1.576 minutes\n",
            "Took 1.674 minutes\n",
            "Took 1.551 minutes\n",
            "Took 2.543 minutes\n",
            "Took 2.961 minutes\n",
            "Took 2.482 minutes\n",
            "Total: took 16.883 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Hamming"
      ],
      "metadata": {
        "id": "d6BSORUjv9Fb"
      },
      "id": "d6BSORUjv9Fb"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"clustering\""
      ],
      "metadata": {
        "id": "-AFB7uZZv9Fb"
      },
      "execution_count": null,
      "outputs": [],
      "id": "-AFB7uZZv9Fb"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29cf95f-a185-4c00-aa97-9f61c0195004",
        "id": "GrB9rl3zv9Fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.053 minutes\n",
            "Took 0.676 minutes\n",
            "Took 0.676 minutes\n",
            "Took 1.543 minutes\n",
            "Took 1.386 minutes\n",
            "Took 3.957 minutes\n",
            "Took 4.109 minutes\n",
            "Took 7.229 minutes\n",
            "Took 7.611 minutes\n",
            "Took 11.419 minutes\n",
            "Took 11.272 minutes\n",
            "Took 17.636 minutes\n",
            "Took 16.71 minutes\n",
            "Total: took 84.369 minutes\n"
          ]
        }
      ],
      "id": "GrB9rl3zv9Fc"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084369dc-0c6c-4d8c-9be4-d8d5a79162a2",
        "id": "LfTwcHu0v9Fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.016 minutes\n",
            "Took 0.057 minutes\n",
            "Took 0.056 minutes\n",
            "Took 0.075 minutes\n",
            "Took 0.067 minutes\n",
            "Took 0.088 minutes\n",
            "Took 0.086 minutes\n",
            "Took 0.101 minutes\n",
            "Took 0.098 minutes\n",
            "Took 0.124 minutes\n",
            "Took 0.139 minutes\n",
            "Took 0.118 minutes\n",
            "Took 0.124 minutes\n",
            "Total: took 1.237 minutes\n"
          ]
        }
      ],
      "id": "LfTwcHu0v9Fc"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a207dff-c2d3-4c80-ee8c-bf608116b43d",
        "id": "5VcifVPiv9Fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.016 minutes\n",
            "Took 0.879 minutes\n",
            "Took 0.872 minutes\n",
            "Took 3.052 minutes\n",
            "Took 3.05 minutes\n",
            "Took 11.901 minutes\n",
            "Took 11.455 minutes\n",
            "Took 24.892 minutes\n",
            "Took 24.786 minutes\n",
            "Took 43.593 minutes\n",
            "Took 43.362 minutes\n",
            "Took 67.417 minutes\n",
            "Took 67.549 minutes\n",
            "Total: took 302.906 minutes\n"
          ]
        }
      ],
      "id": "5VcifVPiv9Fd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequences"
      ],
      "metadata": {
        "id": "dXUYotAYC31p"
      },
      "id": "dXUYotAYC31p"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"sequences\""
      ],
      "metadata": {
        "id": "Bz0ycoCcDLeg"
      },
      "id": "Bz0ycoCcDLeg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "4bZVUr97EFtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5964f3d-fbc2-4278-dc77-f1debac37479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.811 minutes\n",
            "Took 1.058 minutes\n",
            "Took 1.062 minutes\n",
            "Took 1.053 minutes\n",
            "Took 0.955 minutes\n",
            "Took 1.11 minutes\n",
            "Took 1.162 minutes\n",
            "Took 0.4 minutes\n",
            "Took 0.415 minutes\n",
            "Took 0.408 minutes\n",
            "Took 0.055 minutes\n",
            "Took 0.049 minutes\n",
            "Took 0.05 minutes\n",
            "Took 0.068 minutes\n",
            "Took 0.068 minutes\n",
            "Took 0.068 minutes\n",
            "Took 0.085 minutes\n",
            "Took 0.089 minutes\n",
            "Took 0.093 minutes\n",
            "Total: took 9.221 minutes\n"
          ]
        }
      ],
      "id": "4bZVUr97EFtQ"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "NzOyWtMaEFtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c68c63-a33f-4322-c125-0c70b08d9a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.608 minutes\n",
            "Took 0.81 minutes\n",
            "Took 0.783 minutes\n",
            "Took 0.767 minutes\n",
            "Took 0.832 minutes\n",
            "Took 0.679 minutes\n",
            "Took 0.73 minutes\n",
            "Took 0.136 minutes\n",
            "Took 0.119 minutes\n",
            "Took 0.112 minutes\n",
            "Took 0.013 minutes\n",
            "Took 0.012 minutes\n",
            "Took 0.012 minutes\n",
            "Took 0.016 minutes\n",
            "Took 0.015 minutes\n",
            "Took 0.013 minutes\n",
            "Took 0.014 minutes\n",
            "Took 0.016 minutes\n",
            "Took 0.014 minutes\n",
            "Total: took 5.846 minutes\n"
          ]
        }
      ],
      "id": "NzOyWtMaEFtR"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "hU2Hu1B_EFtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9cf467b-7b0c-42e8-8ca7-21766732618c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.76 minutes\n",
            "Took 1.137 minutes\n",
            "Took 1.13 minutes\n",
            "Took 1.06 minutes\n",
            "Took 0.997 minutes\n",
            "Took 1.421 minutes\n",
            "Took 1.154 minutes\n",
            "Took 0.283 minutes\n",
            "Took 0.305 minutes\n",
            "Took 0.306 minutes\n",
            "Took 0.086 minutes\n",
            "Took 0.079 minutes\n",
            "Took 0.077 minutes\n",
            "Took 0.113 minutes\n",
            "Took 0.115 minutes\n",
            "Took 0.118 minutes\n",
            "Took 0.157 minutes\n",
            "Took 0.126 minutes\n",
            "Took 0.139 minutes\n",
            "Total: took 9.759 minutes\n"
          ]
        }
      ],
      "id": "hU2Hu1B_EFtS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BPIC '15"
      ],
      "metadata": {
        "id": "QWrLd8kB_kBR"
      },
      "id": "QWrLd8kB_kBR"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"BPIC15_1_f2\""
      ],
      "metadata": {
        "id": "MXzZcTUyDby-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MXzZcTUyDby-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference"
      ],
      "metadata": {
        "id": "06bzYVd6jtYC"
      },
      "id": "06bzYVd6jtYC"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "LpAy8sryjtYD"
      },
      "execution_count": null,
      "outputs": [],
      "id": "LpAy8sryjtYD"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "z0W-vm3FjtYE"
      },
      "execution_count": null,
      "outputs": [],
      "id": "z0W-vm3FjtYE"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "dOv15kCejtYF"
      },
      "execution_count": null,
      "outputs": [],
      "id": "dOv15kCejtYF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering"
      ],
      "metadata": {
        "id": "IDAAzp8QEH2x"
      },
      "id": "IDAAzp8QEH2x"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"clustering\""
      ],
      "metadata": {
        "id": "F9HvpWmGEH2y"
      },
      "execution_count": null,
      "outputs": [],
      "id": "F9HvpWmGEH2y"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "bGXsm_idEH2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff16dc38-2af6-4072-996b-2cf9b320bd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.005 minutes\n",
            "Took 0.039 minutes\n",
            "Took 0.04 minutes\n",
            "Took 0.038 minutes\n",
            "Took 0.095 minutes\n",
            "Took 0.092 minutes\n",
            "Took 0.093 minutes\n",
            "Took 0.256 minutes\n",
            "Took 0.25 minutes\n",
            "Took 0.246 minutes\n",
            "Took 0.547 minutes\n",
            "Took 0.519 minutes\n",
            "Took 0.487 minutes\n",
            "Took 0.865 minutes\n",
            "Took 1.573 minutes\n",
            "Took 1.556 minutes\n",
            "Took 2.29 minutes\n",
            "Took 2.326 minutes\n",
            "Took 2.216 minutes\n",
            "Total: took 13.764 minutes\n"
          ]
        }
      ],
      "id": "bGXsm_idEH2y"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "tzg-731iEH2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6d35ed-4737-4376-c7d6-e1633127c486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.013 minutes\n",
            "Took 0.045 minutes\n",
            "Took 0.045 minutes\n",
            "Took 0.042 minutes\n",
            "Took 0.063 minutes\n",
            "Took 0.058 minutes\n",
            "Took 0.054 minutes\n",
            "Took 0.078 minutes\n",
            "Took 0.078 minutes\n",
            "Took 0.074 minutes\n",
            "Took 0.09 minutes\n",
            "Took 0.088 minutes\n",
            "Took 0.087 minutes\n",
            "Took 0.1 minutes\n",
            "Took 0.097 minutes\n",
            "Took 0.092 minutes\n",
            "Took 0.105 minutes\n",
            "Took 0.108 minutes\n",
            "Took 0.104 minutes\n",
            "Total: took 1.801 minutes\n"
          ]
        }
      ],
      "id": "tzg-731iEH2y"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "zmPbNe31EH2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b2d445-3c36-4aec-c538-6dc4c603af85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.012 minutes\n",
            "Took 0.124 minutes\n",
            "Took 0.098 minutes\n",
            "Took 0.062 minutes\n",
            "Took 0.193 minutes\n",
            "Took 0.15 minutes\n",
            "Took 0.155 minutes\n",
            "Took 0.523 minutes\n",
            "Took 0.519 minutes\n",
            "Took 0.505 minutes\n",
            "Took 1.051 minutes\n",
            "Took 1.273 minutes\n",
            "Took 1.222 minutes\n",
            "Took 1.865 minutes\n",
            "Took 1.844 minutes\n",
            "Took 1.928 minutes\n",
            "Took 3.042 minutes\n",
            "Took 2.947 minutes\n",
            "Took 3.474 minutes\n",
            "Total: took 21.216 minutes\n"
          ]
        }
      ],
      "id": "zmPbNe31EH2y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Hamming"
      ],
      "metadata": {
        "id": "zmS6qomnwC4P"
      },
      "id": "zmS6qomnwC4P"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"clustering\""
      ],
      "metadata": {
        "id": "QIwAynB7wC4Q"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QIwAynB7wC4Q"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fb3315-1431-4624-895a-d3b51cd2f75d",
        "id": "smQncyU1wC4Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.034 minutes\n",
            "Took 0.799 minutes\n",
            "Took 0.762 minutes\n",
            "Took 2.199 minutes\n",
            "Took 2.19 minutes\n",
            "Took 6.652 minutes\n",
            "Took 6.645 minutes\n",
            "Took 12.739 minutes\n",
            "Took 12.63 minutes\n",
            "Took 19.9 minutes\n",
            "Took 19.604 minutes\n",
            "Took 27.84 minutes\n",
            "Took 27.672 minutes\n",
            "Total: took 139.766 minutes\n"
          ]
        }
      ],
      "id": "smQncyU1wC4Q"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a3b6d1-54a6-4d06-b34c-81bb73a4f780",
        "id": "HLKY4bM-wC4Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.034 minutes\n",
            "Took 0.242 minutes\n",
            "Took 0.256 minutes\n",
            "Took 0.372 minutes\n",
            "Took 0.376 minutes\n",
            "Took 0.567 minutes\n",
            "Took 0.566 minutes\n",
            "Took 0.705 minutes\n",
            "Took 0.711 minutes\n",
            "Took 0.813 minutes\n",
            "Took 0.823 minutes\n",
            "Took 0.93 minutes\n",
            "Took 0.934 minutes\n",
            "Total: took 7.424 minutes\n"
          ]
        }
      ],
      "id": "HLKY4bM-wC4Q"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86a5473-a451-4ef1-cb00-95668380a024",
        "id": "d0SSnA-EwC4Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.033 minutes\n",
            "Took 1.252 minutes\n",
            "Took 1.263 minutes\n",
            "Took 4.202 minutes\n",
            "Took 4.213 minutes\n",
            "Took 15.388 minutes\n",
            "Took 15.399 minutes\n",
            "Took 33.483 minutes\n",
            "Took 33.525 minutes\n",
            "Took 68.038 minutes\n",
            "Took 74.61 minutes\n",
            "Took 110.526 minutes\n",
            "Took 98.0 minutes\n",
            "Total: took 460.038 minutes\n"
          ]
        }
      ],
      "id": "d0SSnA-EwC4Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequences"
      ],
      "metadata": {
        "id": "RVhGHaosEH2y"
      },
      "id": "RVhGHaosEH2y"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"sequences\""
      ],
      "metadata": {
        "id": "exQsyDIbEH2z"
      },
      "execution_count": null,
      "outputs": [],
      "id": "exQsyDIbEH2z"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "XXObNJfqEH2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3510a8e0-7bc3-48c0-e9ff-5bc48d8b35d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.307 minutes\n",
            "Took 0.347 minutes\n",
            "Took 0.337 minutes\n",
            "Took 0.297 minutes\n",
            "Took 0.024 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.043 minutes\n",
            "Took 0.048 minutes\n",
            "Took 0.056 minutes\n",
            "Took 0.069 minutes\n",
            "Took 0.082 minutes\n",
            "Took 0.083 minutes\n",
            "Took 0.113 minutes\n",
            "Took 0.102 minutes\n",
            "Took 0.112 minutes\n",
            "Took 0.146 minutes\n",
            "Took 0.164 minutes\n",
            "Took 0.152 minutes\n",
            "Total: took 2.737 minutes\n"
          ]
        }
      ],
      "id": "XXObNJfqEH2z"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "BTtKgIcMEH2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eba7ece-99f7-45d6-e3d2-9f3ec011e0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.269 minutes\n",
            "Took 0.228 minutes\n",
            "Took 0.232 minutes\n",
            "Took 0.227 minutes\n",
            "Took 0.013 minutes\n",
            "Took 0.014 minutes\n",
            "Took 0.013 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.03 minutes\n",
            "Took 0.03 minutes\n",
            "Took 0.03 minutes\n",
            "Took 0.035 minutes\n",
            "Took 0.035 minutes\n",
            "Took 0.035 minutes\n",
            "Took 0.039 minutes\n",
            "Took 0.04 minutes\n",
            "Took 0.04 minutes\n",
            "Total: took 1.544 minutes\n"
          ]
        }
      ],
      "id": "BTtKgIcMEH2z"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "I0KBhXLxEH2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b9ac66-9e93-42ff-8fec-c3335966bab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.257 minutes\n",
            "Took 0.296 minutes\n",
            "Took 0.287 minutes\n",
            "Took 0.289 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.025 minutes\n",
            "Took 0.033 minutes\n",
            "Took 0.054 minutes\n",
            "Took 0.052 minutes\n",
            "Took 0.051 minutes\n",
            "Took 0.081 minutes\n",
            "Took 0.081 minutes\n",
            "Took 0.084 minutes\n",
            "Took 0.119 minutes\n",
            "Took 0.114 minutes\n",
            "Took 0.116 minutes\n",
            "Took 0.158 minutes\n",
            "Took 0.183 minutes\n",
            "Took 0.164 minutes\n",
            "Total: took 2.674 minutes\n"
          ]
        }
      ],
      "id": "I0KBhXLxEH2z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Credit"
      ],
      "metadata": {
        "id": "mwn61l--EJto"
      },
      "id": "mwn61l--EJto"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"Credit\""
      ],
      "metadata": {
        "id": "QzeefdMWEJto"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QzeefdMWEJto"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference"
      ],
      "metadata": {
        "id": "cBGXFrJFju0d"
      },
      "id": "cBGXFrJFju0d"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED-activity\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "xuUCxWHvju0e"
      },
      "execution_count": null,
      "outputs": [],
      "id": "xuUCxWHvju0e"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND-activity\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "aOlQvrf2ju0e"
      },
      "execution_count": null,
      "outputs": [],
      "id": "aOlQvrf2ju0e"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM-activity\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "4462I7oqju0e"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4462I7oqju0e"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"SYNONYM\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "qD8XuICcj0UX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "qD8XuICcj0UX"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"HOMONYM\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "SHqUehS2j0ab"
      },
      "execution_count": null,
      "outputs": [],
      "id": "SHqUehS2j0ab"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering"
      ],
      "metadata": {
        "id": "bf-6kkcpEJto"
      },
      "id": "bf-6kkcpEJto"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"clustering\""
      ],
      "metadata": {
        "id": "qefT0e4EEJtp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "qefT0e4EEJtp"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "jjDc4L1XEJtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61a9cb0-694c-48f9-c982-7664cd0480a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.0 minutes\n",
            "Took 0.021 minutes\n",
            "Took 0.019 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.047 minutes\n",
            "Took 0.048 minutes\n",
            "Took 0.044 minutes\n",
            "Took 0.103 minutes\n",
            "Took 0.108 minutes\n",
            "Took 0.113 minutes\n",
            "Took 0.174 minutes\n",
            "Took 0.173 minutes\n",
            "Took 0.185 minutes\n",
            "Took 0.283 minutes\n",
            "Took 0.251 minutes\n",
            "Took 0.256 minutes\n",
            "Took 0.342 minutes\n",
            "Took 0.335 minutes\n",
            "Took 0.351 minutes\n",
            "Total: took 3.172 minutes\n"
          ]
        }
      ],
      "id": "jjDc4L1XEJtp"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "rVKTOsxdEJtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f16ccc4-e001-44aa-e913-f45d6ab72f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.0 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Total: took 0.342 minutes\n"
          ]
        }
      ],
      "id": "rVKTOsxdEJtp"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "9U2Kjn-DEJtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d779fc0d-6634-4992-f7de-f1ecb6d90001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.0 minutes\n",
            "Took 0.094 minutes\n",
            "Took 0.093 minutes\n",
            "Took 0.095 minutes\n",
            "Took 0.388 minutes\n",
            "Took 0.399 minutes\n",
            "Took 0.396 minutes\n",
            "Took 1.61 minutes\n",
            "Took 1.541 minutes\n",
            "Took 1.582 minutes\n",
            "Took 3.499 minutes\n",
            "Took 3.274 minutes\n",
            "Took 3.542 minutes\n",
            "Took 6.999 minutes\n",
            "Took 7.049 minutes\n",
            "Took 6.426 minutes\n",
            "Took 13.786 minutes\n",
            "Took 12.094 minutes\n",
            "Took 12.182 minutes\n",
            "Total: took 75.395 minutes\n"
          ]
        }
      ],
      "id": "9U2Kjn-DEJtp"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"SYNONYM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "wCcP028hEodb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9933dd6-c23a-4eef-9413-1351ddef63ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.001 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Total: took 0.353 minutes\n"
          ]
        }
      ],
      "id": "wCcP028hEodb"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"HOMONYM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "1RFzSONpEodb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbbf26f-82ce-48d3-b222-c81e8b8bbc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.0 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.0 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.0 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Total: took 0.284 minutes\n"
          ]
        }
      ],
      "id": "1RFzSONpEodb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Hamming"
      ],
      "metadata": {
        "id": "9A9boE77wFTY"
      },
      "id": "9A9boE77wFTY"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"clustering\""
      ],
      "metadata": {
        "id": "DLbmnM9YwFTZ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "DLbmnM9YwFTZ"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a838373b-7bb7-4c8c-d298-69aaba3592bb",
        "id": "tp2eXj2GwFTZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.02 minutes\n",
            "Took 1.893 minutes\n",
            "Took 2.009 minutes\n",
            "Took 3.964 minutes\n",
            "Took 3.989 minutes\n",
            "Took 7.898 minutes\n",
            "Took 3.667 minutes\n",
            "Took 11.964 minutes\n",
            "Took 10.321 minutes\n",
            "Took 10.077 minutes\n",
            "Took 8.039 minutes\n",
            "Took 12.23 minutes\n",
            "Took 10.14 minutes\n",
            "Total: took 86.69 minutes\n"
          ]
        }
      ],
      "id": "tp2eXj2GwFTZ"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "eT9LvuhswFTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0863a4cf-5694-4755-99c9-8c0ec804eac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.001 minutes\n",
            "Took 0.004 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.004 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.004 minutes\n",
            "Total: took 0.229 minutes\n"
          ]
        }
      ],
      "id": "eT9LvuhswFTZ"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "Nbk13txzwFTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99475f89-a460-4b8b-b4d3-3a2074c58c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.004 minutes\n",
            "Took 2.617 minutes\n",
            "Took 2.601 minutes\n",
            "Took 11.376 minutes\n",
            "Took 12.418 minutes\n",
            "Took 46.39 minutes\n",
            "Took 41.393 minutes\n",
            "Took 93.472 minutes\n",
            "Took 97.41 minutes\n",
            "Took 167.26 minutes\n",
            "Took 164.542 minutes\n",
            "Took 258.803 minutes\n",
            "Took 259.795 minutes\n",
            "Total: took 1158.256 minutes\n"
          ]
        }
      ],
      "id": "Nbk13txzwFTa"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"SYNONYM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "z4SUZmJBwFTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c774de-4ae6-4ec6-a876-3cebd1ef0c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.003 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Total: took 0.177 minutes\n"
          ]
        }
      ],
      "id": "z4SUZmJBwFTa"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"HOMONYM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "RFUi8gGvwFTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708c6787-3939-4c99-c178-ae5fad0c1e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Total: took 0.162 minutes\n"
          ]
        }
      ],
      "id": "RFUi8gGvwFTa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequences"
      ],
      "metadata": {
        "id": "heXIPd_OEJtp"
      },
      "id": "heXIPd_OEJtp"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"sequences\""
      ],
      "metadata": {
        "id": "vjmXbpjlEJtp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "vjmXbpjlEJtp"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "kHN3DPUkEJtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156b24c2-5b2c-4905-bf24-c9fd06a26494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.006 minutes\n",
            "Took 1.625 minutes\n",
            "Took 1.65 minutes\n",
            "Took 1.618 minutes\n",
            "Took 2.626 minutes\n",
            "Took 2.552 minutes\n",
            "Took 2.766 minutes\n",
            "Took 4.583 minutes\n",
            "Took 4.577 minutes\n",
            "Took 4.654 minutes\n",
            "Took 5.15 minutes\n",
            "Took 5.18 minutes\n",
            "Took 5.313 minutes\n",
            "Took 5.359 minutes\n",
            "Took 5.522 minutes\n",
            "Took 5.282 minutes\n",
            "Took 2.117 minutes\n",
            "Took 1.893 minutes\n",
            "Took 1.874 minutes\n",
            "Total: took 64.622 minutes\n"
          ]
        }
      ],
      "id": "kHN3DPUkEJtq"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "KeFP8-49EJtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e2efa2-77e9-4f02-f49b-6d0747c00ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.003 minutes\n",
            "Took 0.199 minutes\n",
            "Took 0.21 minutes\n",
            "Took 0.212 minutes\n",
            "Took 0.318 minutes\n",
            "Took 0.314 minutes\n",
            "Took 0.326 minutes\n",
            "Took 0.572 minutes\n",
            "Took 0.547 minutes\n",
            "Took 0.56 minutes\n",
            "Took 0.577 minutes\n",
            "Took 0.589 minutes\n",
            "Took 0.582 minutes\n",
            "Took 0.531 minutes\n",
            "Took 0.546 minutes\n",
            "Took 0.546 minutes\n",
            "Took 0.104 minutes\n",
            "Took 0.188 minutes\n",
            "Took 0.198 minutes\n",
            "Total: took 7.399 minutes\n"
          ]
        }
      ],
      "id": "KeFP8-49EJtq"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "WupvEzK9EJtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94cfe133-9dd6-4941-ce57-a42582f38f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.003 minutes\n",
            "Took 2.743 minutes\n",
            "Took 2.732 minutes\n",
            "Took 2.704 minutes\n",
            "Took 4.754 minutes\n",
            "Took 4.995 minutes\n",
            "Took 4.876 minutes\n",
            "Took 8.609 minutes\n",
            "Took 8.782 minutes\n",
            "Took 8.751 minutes\n",
            "Took 9.385 minutes\n",
            "Took 9.304 minutes\n",
            "Took 9.245 minutes\n",
            "Took 8.851 minutes\n",
            "Took 8.551 minutes\n",
            "Took 8.774 minutes\n",
            "Took 1.925 minutes\n",
            "Took 3.18 minutes\n",
            "Took 3.175 minutes\n",
            "Total: took 111.61 minutes\n"
          ]
        }
      ],
      "id": "WupvEzK9EJtq"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"SYNONYM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "arQqfbGKEr0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24f9b9e-03ef-461e-83c5-36ac01079502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.003 minutes\n",
            "Took 0.116 minutes\n",
            "Took 0.114 minutes\n",
            "Took 0.124 minutes\n",
            "Took 0.157 minutes\n",
            "Took 0.149 minutes\n",
            "Took 0.16 minutes\n",
            "Took 0.207 minutes\n",
            "Took 0.197 minutes\n",
            "Took 0.21 minutes\n",
            "Took 0.206 minutes\n",
            "Took 0.218 minutes\n",
            "Took 0.219 minutes\n",
            "Took 0.349 minutes\n",
            "Took 0.354 minutes\n",
            "Took 0.376 minutes\n",
            "Took 0.289 minutes\n",
            "Took 0.319 minutes\n",
            "Took 0.281 minutes\n",
            "Total: took 4.32 minutes\n"
          ]
        }
      ],
      "id": "arQqfbGKEr0u"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"HOMONYM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "FfZaBNtLEr0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095f404b-b817-4918-9cdb-18af7f0934eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.003 minutes\n",
            "Took 0.02 minutes\n",
            "Took 0.02 minutes\n",
            "Took 0.02 minutes\n",
            "Took 0.023 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.023 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.022 minutes\n",
            "Took 0.02 minutes\n",
            "Took 0.018 minutes\n",
            "Took 0.019 minutes\n",
            "Took 0.017 minutes\n",
            "Took 0.017 minutes\n",
            "Took 0.016 minutes\n",
            "Took 0.015 minutes\n",
            "Took 0.015 minutes\n",
            "Took 0.015 minutes\n",
            "Took 0.015 minutes\n",
            "Total: took 0.611 minutes\n"
          ]
        }
      ],
      "id": "FfZaBNtLEr0v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pub"
      ],
      "metadata": {
        "id": "nZBChVHPEuzi"
      },
      "id": "nZBChVHPEuzi"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"Pub\""
      ],
      "metadata": {
        "id": "x7nTYgwWEuzj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "x7nTYgwWEuzj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference"
      ],
      "metadata": {
        "id": "qnVkLvVvj7wK"
      },
      "id": "qnVkLvVvj7wK"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED-activity\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "1n6TakLej7wK"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1n6TakLej7wK"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND-activity\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "7fmEBOp8j7wL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "7fmEBOp8j7wL"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM-activity\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "eeWbc3SMj7wL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "eeWbc3SMj7wL"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"SYNONYM\"\n",
        "scores = reference_assess(dataset, pollution_type)\n",
        "with open(f\"{dataset}/{dataset}/REFERENCE_{dataset}_{pollution_type}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "yfAAhjOsj7wL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "yfAAhjOsj7wL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering"
      ],
      "metadata": {
        "id": "u3Usvkv5Euzj"
      },
      "id": "u3Usvkv5Euzj"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"clustering\""
      ],
      "metadata": {
        "id": "8yylRBFaEuzj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "8yylRBFaEuzj"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "TE6MXrCuEuzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef282a3-90c7-47ef-c551-e287e2f8889d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.0 minutes\n",
            "Took 0.017 minutes\n",
            "Took 0.017 minutes\n",
            "Took 0.017 minutes\n",
            "Took 0.039 minutes\n",
            "Took 0.04 minutes\n",
            "Took 0.04 minutes\n",
            "Took 0.089 minutes\n",
            "Took 0.09 minutes\n",
            "Took 0.092 minutes\n",
            "Took 0.145 minutes\n",
            "Took 0.148 minutes\n",
            "Took 0.149 minutes\n",
            "Took 0.201 minutes\n",
            "Took 0.206 minutes\n",
            "Took 0.215 minutes\n",
            "Took 0.263 minutes\n",
            "Took 0.264 minutes\n",
            "Took 0.275 minutes\n",
            "Total: took 2.578 minutes\n"
          ]
        }
      ],
      "id": "TE6MXrCuEuzj"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "pMisBQkLEuzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1fc8a00-8322-4824-9092-54bdc25358aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.0 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Total: took 0.331 minutes\n"
          ]
        }
      ],
      "id": "pMisBQkLEuzk"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "W1VdpjaIEuzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2ead7f-c037-4a94-bbba-2f9aef4daa62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.0 minutes\n",
            "Took 0.108 minutes\n",
            "Took 0.115 minutes\n",
            "Took 0.114 minutes\n",
            "Took 0.459 minutes\n",
            "Took 0.537 minutes\n",
            "Took 0.364 minutes\n",
            "Took 1.472 minutes\n",
            "Took 1.433 minutes\n",
            "Took 1.438 minutes\n",
            "Took 3.325 minutes\n",
            "Took 3.189 minutes\n",
            "Took 3.217 minutes\n",
            "Took 6.261 minutes\n",
            "Took 5.984 minutes\n",
            "Took 6.046 minutes\n",
            "Took 11.081 minutes\n",
            "Took 11.319 minutes\n",
            "Took 11.508 minutes\n",
            "Total: took 68.295 minutes\n"
          ]
        }
      ],
      "id": "W1VdpjaIEuzk"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"SYNONYM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "oPCRb4gdEuzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71caeb8b-d9ac-4787-b036-0812acab8bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.001 minutes\n",
            "Total: took 0.317 minutes\n"
          ]
        }
      ],
      "id": "oPCRb4gdEuzk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Hamming"
      ],
      "metadata": {
        "id": "pmtZIoptwIEq"
      },
      "id": "pmtZIoptwIEq"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"clustering\""
      ],
      "metadata": {
        "id": "erad-spTwIEq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "erad-spTwIEq"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "I9I4NZPJwIEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a70d49-62cc-4712-e275-25a8bd90bb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.001 minutes\n",
            "Took 0.356 minutes\n",
            "Took 0.368 minutes\n",
            "Took 0.851 minutes\n",
            "Took 0.859 minutes\n",
            "Took 1.928 minutes\n",
            "Took 1.975 minutes\n",
            "Took 3.189 minutes\n",
            "Took 3.252 minutes\n",
            "Took 4.382 minutes\n",
            "Took 4.5 minutes\n",
            "Took 5.769 minutes\n",
            "Took 5.778 minutes\n",
            "Total: took 33.363 minutes\n"
          ]
        }
      ],
      "id": "I9I4NZPJwIEq"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "0W6XKJY9wIEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc1fcc1-feba-4608-ae50-168b402e9844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.001 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Took 0.003 minutes\n",
            "Total: took 0.191 minutes\n"
          ]
        }
      ],
      "id": "0W6XKJY9wIEr"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "IO40OaMCwIEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03dce35b-6871-4278-9da7-08f255b6fd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.001 minutes\n",
            "Took 2.725 minutes\n",
            "Took 2.72 minutes\n",
            "Took 13.517 minutes\n",
            "Took 11.005 minutes\n",
            "Took 43.782 minutes\n",
            "Took 43.724 minutes\n",
            "Took 99.052 minutes\n",
            "Took 97.571 minutes\n",
            "Took 182.527 minutes\n",
            "Took 176.288 minutes\n",
            "Took 276.939 minutes\n",
            "Took 287.23 minutes\n",
            "Total: took 1237.253 minutes\n"
          ]
        }
      ],
      "id": "IO40OaMCwIEr"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"SYNONYM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=hamm)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}-HAMMING.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "wWe4uROgwIEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d563218b-9e1f-4195-c155-10c9ff71b4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.002 minutes\n",
            "Took 0.001 minutes\n",
            "Took 0.002 minutes\n",
            "Total: took 0.208 minutes\n"
          ]
        }
      ],
      "id": "wWe4uROgwIEr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequences"
      ],
      "metadata": {
        "id": "YYuKNXjzEuzk"
      },
      "id": "YYuKNXjzEuzk"
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"sequences\""
      ],
      "metadata": {
        "id": "czAzmO0_Euzk"
      },
      "execution_count": null,
      "outputs": [],
      "id": "czAzmO0_Euzk"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"DISTORTED-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "fZ5fh-J7Euzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45176030-6265-49d2-cb91-5695ab7fd150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.018 minutes\n",
            "Took 1.113 minutes\n",
            "Took 1.09 minutes\n",
            "Took 1.109 minutes\n",
            "Took 1.847 minutes\n",
            "Took 1.826 minutes\n",
            "Took 1.892 minutes\n",
            "Took 3.415 minutes\n",
            "Took 3.327 minutes\n",
            "Took 3.515 minutes\n",
            "Took 4.67 minutes\n",
            "Took 4.406 minutes\n",
            "Took 4.383 minutes\n",
            "Took 5.714 minutes\n",
            "Took 4.974 minutes\n",
            "Took 5.278 minutes\n",
            "Took 1.063 minutes\n",
            "Took 1.73 minutes\n",
            "Took 1.065 minutes\n",
            "Total: took 52.707 minutes\n"
          ]
        }
      ],
      "id": "fZ5fh-J7Euzk"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.NORND-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "eAy_CvsXEuzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f3ce9b-aa63-47b9-e5b9-a1673986b7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.015 minutes\n",
            "Took 0.145 minutes\n",
            "Took 0.141 minutes\n",
            "Took 0.153 minutes\n",
            "Took 0.221 minutes\n",
            "Took 0.226 minutes\n",
            "Took 0.227 minutes\n",
            "Took 0.324 minutes\n",
            "Took 0.331 minutes\n",
            "Took 0.351 minutes\n",
            "Took 0.428 minutes\n",
            "Took 0.428 minutes\n",
            "Took 0.438 minutes\n",
            "Took 0.394 minutes\n",
            "Took 0.474 minutes\n",
            "Took 0.434 minutes\n",
            "Took 0.635 minutes\n",
            "Took 0.629 minutes\n",
            "Took 0.651 minutes\n",
            "Total: took 6.921 minutes\n"
          ]
        }
      ],
      "id": "eAy_CvsXEuzk"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"POLLUTED.RANDOM-activity\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "gtdAy_68Euzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ed1ab6-d7df-44e5-c621-cb0d9eab2f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.015 minutes\n",
            "Took 2.152 minutes\n",
            "Took 2.076 minutes\n",
            "Took 2.099 minutes\n",
            "Took 3.95 minutes\n",
            "Took 3.93 minutes\n",
            "Took 3.918 minutes\n",
            "Took 7.101 minutes\n",
            "Took 7.015 minutes\n",
            "Took 7.086 minutes\n",
            "Took 8.281 minutes\n",
            "Took 8.13 minutes\n",
            "Took 8.23 minutes\n",
            "Took 8.958 minutes\n",
            "Took 8.682 minutes\n",
            "Took 9.041 minutes\n",
            "Took 1.85 minutes\n",
            "Took 1.846 minutes\n",
            "Took 1.854 minutes\n",
            "Total: took 96.492 minutes\n"
          ]
        }
      ],
      "id": "gtdAy_68Euzl"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = \"SYNONYM\"\n",
        "scores = cleaning_experiment(dataset, pollution_type, method, dist=lev.distance)\n",
        "with open(f\"{dataset}/{dataset}/CLEANING_{dataset}_{pollution_type}_{method}.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores, f)"
      ],
      "metadata": {
        "id": "DN6Z-Dz5Euzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7362658a-7db7-40d1-bb27-eaec1ec893bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.015 minutes\n",
            "Took 0.101 minutes\n",
            "Took 0.099 minutes\n",
            "Took 0.097 minutes\n",
            "Took 0.134 minutes\n",
            "Took 0.133 minutes\n",
            "Took 0.125 minutes\n",
            "Took 0.196 minutes\n",
            "Took 0.185 minutes\n",
            "Took 0.179 minutes\n",
            "Took 0.547 minutes\n",
            "Took 0.479 minutes\n",
            "Took 0.501 minutes\n",
            "Took 0.608 minutes\n",
            "Took 0.546 minutes\n",
            "Took 0.58 minutes\n",
            "Took 0.606 minutes\n",
            "Took 0.581 minutes\n",
            "Took 0.58 minutes\n",
            "Total: took 6.566 minutes\n"
          ]
        }
      ],
      "id": "DN6Z-Dz5Euzl"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}