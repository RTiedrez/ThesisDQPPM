{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*The prediction pipeline is based on [Comuzzi, M., Kim, S., Ko, J., Salamov, M., Cappiello, C., & Pernici, B. (2024). On the Impact of Low-Quality Activity Labels in Predictive Process Monitoring. In ICPM 2024 Workshop \"ML4PM - Leveraging Machine Learning in Process Mining\"].*"
      ],
      "metadata": {
        "id": "EwHe36u_eHlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we run an LSTM-based remaining time prediction pipeline on various event logs where activity labels are ignored, to assess the weight of activity labels for the task. The first section ignores the activity labels and replaces them all with default values. The second section directly drops the Activity column from the training and test sets."
      ],
      "metadata": {
        "id": "kU7dkqz4e_hK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "kDl5QFRr_vPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "9ldr_qgr_x3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from datetime import datetime\n",
        "import csv\n",
        "import numpy as np\n",
        "import time\n",
        "import pickle\n",
        "import statistics\n",
        "import random\n",
        "\n",
        "from scipy.spatial import distance as scipy_distance\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, mean_absolute_error, confusion_matrix\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Masking\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)"
      ],
      "metadata": {
        "id": "LYvz9hpnFAe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bdb993-1b5f-476c-949e-787c624758ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/Polimi/S12/Thesis/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No labels when training"
      ],
      "metadata": {
        "id": "agYUeKK9i74p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "r1xyvO2P_zdR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YylwVt8v6agH"
      },
      "outputs": [],
      "source": [
        "def model_evaluate(df):\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  total_epochs = 300\n",
        "\n",
        "  # Group by NUMPRO and get the last event in each group\n",
        "  last_events = df.groupby('NUMPRO').tail(1)\n",
        "\n",
        "  df['DATAEV'] = pd.to_datetime(df['DATAEV'])\n",
        "  df.sort_values(['NUMPRO', 'DATAEV'], inplace=True)\n",
        "  df['case_end'] = df.groupby('NUMPRO')['DATAEV'].transform('max')\n",
        "  df['remaining_time'] = ((df['case_end'] - df['DATAEV']).dt.total_seconds() / 86400).astype(int)\n",
        "  df['event_idx'] = [0 for x in range(len(df))]  # You might need to replace with actual event encoding\n",
        "  df['time_diff'] = df.groupby('NUMPRO')['DATAEV'].diff().dt.total_seconds() / 86400\n",
        "  df['time_diff'] = df['time_diff'].fillna(0).astype(int)\n",
        "\n",
        "  # sequences for LSTM\n",
        "  sequences = df.groupby('NUMPRO').apply(lambda x: list(zip(x['event_idx'], x['time_diff']))) #without normalization\n",
        "\n",
        "  max_sequence_length = 100\n",
        "  # Convert sequences to a NumPy array with the correct shape\n",
        "  #sequences_array = [[[elem] for elem in seq] for seq in sequences] # Removed as it was causing the shape mismatch\n",
        "  sequences_padded = pad_sequences(sequences.tolist(), maxlen=max_sequence_length, padding='post', dtype='float32', value=-1)  # Convert to list before padding\n",
        "\n",
        "  # y values based on normalized remaining times\n",
        "  y_sequences = df.groupby('NUMPRO')['remaining_time'].apply(list)\n",
        "  y_padded = pad_sequences(y_sequences.tolist(), maxlen=max_sequence_length, padding='post', value=0)\n",
        "\n",
        "  # data split into training and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(sequences_padded, y_padded, test_size=0.2, random_state=42)\n",
        "\n",
        "  # data types are uniform\n",
        "  X_train = np.array(X_train, dtype='float32')\n",
        "  y_train = np.array(y_train, dtype='float32')\n",
        "  X_test = np.array(X_test, dtype='float32')\n",
        "  y_test = np.array(y_test, dtype='float32')\n",
        "\n",
        "  model = Sequential([\n",
        "      Masking(mask_value=-1, input_shape=(max_sequence_length, 2)), # input has 2 features per timestep\n",
        "      LSTM(256, return_sequences=False),\n",
        "      Dense(1, activation='relu'),\n",
        "  ])\n",
        "\n",
        "  def lr_scheduler(epoch, lr):\n",
        "      decay_rate = 0.1\n",
        "      decay_step = 90\n",
        "      if epoch % decay_step == 0 and epoch:\n",
        "          return lr * decay_rate\n",
        "      return lr\n",
        "\n",
        "  callbacks = [\n",
        "      LearningRateScheduler(lr_scheduler, verbose=0), # Changed verbose from 1 to 0\n",
        "      EarlyStopping(monitor='val_loss', patience=100, verbose=0),\n",
        "  ]\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='Adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "  history = model.fit(X_train, y_train, epochs=total_epochs, batch_size=32, validation_split=0.2, verbose=0, callbacks=callbacks) # Changed verbose from 1 to 0\n",
        "\n",
        "  print(\"Training time:\", (round((time.time() - start_time)/60,3)), \"minutes\")\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR1O8idJr0ZY"
      },
      "outputs": [],
      "source": [
        "def load_and_prepare_test_set(test_set):\n",
        "    test_df = test_set.copy()\n",
        "\n",
        "    # Specify column names\n",
        "    case_id_col = test_df.columns[0]\n",
        "    event_id_col = test_df.columns[1]\n",
        "    event_date_col = test_df.columns[2]\n",
        "\n",
        "    # Prepare the test data\n",
        "    test_df[event_date_col] = pd.to_datetime(test_df[event_date_col])\n",
        "    test_df.sort_values([case_id_col, event_date_col], inplace=True)\n",
        "    test_df['case_end'] = test_df.groupby(case_id_col)[event_date_col].transform('max')\n",
        "    test_df['remaining_time'] = ((test_df['case_end'] - test_df[event_date_col]).dt.total_seconds() / 86400).astype(float) # in days\n",
        "\n",
        "    # Handle unknown event labels\n",
        "    test_df['event_idx'] = [0 for x in range(len(test_df))]  # Initialize with a numerical value (e.g., 0)\n",
        "    test_df['time_diff'] = test_df.groupby(case_id_col)[event_date_col].diff().dt.total_seconds() / 86400 # in days\n",
        "    test_df['time_diff'] = test_df['time_diff'].fillna(0).astype(int)\n",
        "\n",
        "    # Generate X_test and y_test for each case\n",
        "    rows = []\n",
        "    case_ids = test_df[case_id_col].unique()\n",
        "    max_sequence_length = 100\n",
        "\n",
        "    for cid in case_ids:\n",
        "        case_data = test_df[test_df[case_id_col] == cid]\n",
        "        events = list(zip(case_data['event_idx'], case_data['time_diff']))  # Now contains numerical values\n",
        "        remaining_times = case_data['remaining_time'].values\n",
        "        event_ids = case_data[event_id_col].values\n",
        "\n",
        "        for i in range(1, len(events) + 1):\n",
        "            x_test = pad_sequences([events[:i]], maxlen=max_sequence_length, padding='post', dtype='float32', value=(-1, 0)) # Should work now\n",
        "            rows.append({\n",
        "                'case_id': cid,\n",
        "                'event_ids': event_ids[:i],\n",
        "                'x_test': x_test[0],\n",
        "                'y_test': remaining_times[i-1]\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uR95TbHr0ZZ"
      },
      "outputs": [],
      "source": [
        "def generate_predictions(test_set, model,):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Load and prepare the test set\n",
        "    test_df = load_and_prepare_test_set(test_set)\n",
        "\n",
        "    # Make predictions\n",
        "    X_test = np.stack(test_df['x_test'].values).astype('float32')\n",
        "    predictions = model.predict(X_test, verbose=1)\n",
        "\n",
        "    # Extract the last non-zero prediction for each sequence\n",
        "    test_df['prediction'] = [pred[np.nonzero(pred)[0][-1]] if np.nonzero(pred)[0].size > 0 else 0 for pred in predictions]\n",
        "\n",
        "    print(\"Evaluation time:\", (round((time.time() - start_time)/60,3)), \"minutes\")\n",
        "\n",
        "    # Edited to return evaluation time\n",
        "    return test_df[['case_id', 'event_ids', 'y_test', 'prediction']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mae(results_df): # in days\n",
        "    y_true = results_df['y_test'].values\n",
        "    y_pred = results_df['prediction'].values\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    return mae"
      ],
      "metadata": {
        "id": "2ss7QHYrQhCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tests"
      ],
      "metadata": {
        "id": "613fWwINLBiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in ['BPIC11_f1', 'BPIC15_1_f2', 'Credit', 'Pub', 'BPIC12', 'BPIC17']:\n",
        "  score = np.array([])\n",
        "  time_scores = np.array([])\n",
        "  df_test = pd.read_csv(f\"./{dataset}/{subset}/{subset}-TEST-CLEAN.csv\")\n",
        "  df_test = df_test[[\"NUMPRO\", \"DATAEV\", \"NUMGIU\"]]\n",
        "  for i in range(3):\n",
        "    start_time = time.time()\n",
        "    subset = dataset\n",
        "    df = pd.read_csv(f\"./{dataset}/{subset}/{subset}_prepared/{subset}-TRAIN-CLEAN.csv\")\n",
        "    df = df[[\"NUMPRO\", \"DATAEV\", \"NUMGIU\"]]\n",
        "    model = model_evaluate(df)\n",
        "    result_df = generate_predictions(df_test, model)\n",
        "    score = np.append(score, calculate_mae(result_df))\n",
        "    time_scores = np.append(time_scores, (round((time.time() - start_time)/60,3)))\n",
        "  score_avg = np.average(score)\n",
        "  time_avg = np.average(time_scores)\n",
        "  print(dataset, ':', score_avg)\n",
        "  print(dataset, ':', time_avg, \"minutes\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "gJxJxX9ktmHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f995b1e9-a8c0-48ae-a416-7141f97f65a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 1.426 minutes\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.02 minutes\n",
            "Training time: 1.373 minutes\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Evaluation time: 0.027 minutes\n",
            "Training time: 1.442 minutes\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Evaluation time: 0.021 minutes\n",
            "BPIC11_f1 : 176.34802106423373\n",
            "BPIC11_f1 : 1.4366666666666668 minutes\n",
            "\n",
            "Training time: 1.248 minutes\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.027 minutes\n",
            "Training time: 1.291 minutes\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Evaluation time: 0.029 minutes\n",
            "Training time: 1.321 minutes\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.027 minutes\n",
            "BPIC15_1_f2 : 44.23689610005821\n",
            "BPIC15_1_f2 : 1.3150000000000002 minutes\n",
            "\n",
            "Training time: 2.817 minutes\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.046 minutes\n",
            "Training time: 1.083 minutes\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.055 minutes\n",
            "Training time: 2.793 minutes\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.045 minutes\n",
            "Credit : 0.05405796966792642\n",
            "Credit : 2.280666666666667 minutes\n",
            "\n",
            "Training time: 1.649 minutes\n",
            "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.059 minutes\n",
            "Training time: 2.579 minutes\n",
            "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.058 minutes\n",
            "Training time: 2.801 minutes\n",
            "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.059 minutes\n",
            "Pub : 6.691374180563135\n",
            "Pub : 2.4120000000000004 minutes\n",
            "\n",
            "Training time: 7.589 minutes\n",
            "\u001b[1m1619/1619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
            "Evaluation time: 0.23 minutes\n",
            "Training time: 5.688 minutes\n",
            "\u001b[1m1619/1619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
            "Evaluation time: 0.24 minutes\n",
            "Training time: 6.368 minutes\n",
            "\u001b[1m1619/1619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
            "Evaluation time: 0.248 minutes\n",
            "BPIC12 : 8.181479164930384\n",
            "BPIC12 : 6.803 minutes\n",
            "\n",
            "Training time: 17.411 minutes\n",
            "\u001b[1m7534/7534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step\n",
            "Evaluation time: 0.905 minutes\n",
            "Training time: 8.26 minutes\n",
            "\u001b[1m7534/7534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.9 minutes\n",
            "Training time: 13.547 minutes\n",
            "\u001b[1m7534/7534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.714 minutes\n",
            "BPIC17 : 12.629940898522413\n",
            "BPIC17 : 13.949666666666666 minutes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No labels"
      ],
      "metadata": {
        "id": "RaPDxb4RbyQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "s2yueLO9byQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0fh-0ljbyQS"
      },
      "outputs": [],
      "source": [
        "def model_evaluate(df):\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  total_epochs = 300\n",
        "\n",
        "  # Group by NUMPRO and get the last event in each group\n",
        "  last_events = df.groupby('NUMPRO').tail(1)\n",
        "\n",
        "  df['DATAEV'] = pd.to_datetime(df['DATAEV'])\n",
        "  df.sort_values(['NUMPRO', 'DATAEV'], inplace=True)\n",
        "  df['case_end'] = df.groupby('NUMPRO')['DATAEV'].transform('max')\n",
        "  df['remaining_time'] = ((df['case_end'] - df['DATAEV']).dt.total_seconds() / 86400).astype(int)\n",
        "  df['time_diff'] = df.groupby('NUMPRO')['DATAEV'].diff().dt.total_seconds() / 86400\n",
        "  df['time_diff'] = df['time_diff'].fillna(0).astype(int)\n",
        "\n",
        "  # sequences for LSTM\n",
        "  sequences = df.groupby('NUMPRO').apply(lambda x: list(x['time_diff'])) #without normalization\n",
        "\n",
        "  max_sequence_length = 100\n",
        "  # Convert sequences to a NumPy array with the correct shape\n",
        "  #sequences_array = [[[elem] for elem in seq] for seq in sequences] # Removed as it was causing the shape mismatch\n",
        "  sequences_padded = pad_sequences(sequences.tolist(), maxlen=max_sequence_length, padding='post', dtype='float32', value=-1)  # Convert to list before padding\n",
        "\n",
        "  # y values based on normalized remaining times\n",
        "  y_sequences = df.groupby('NUMPRO')['remaining_time'].apply(list)\n",
        "  y_padded = pad_sequences(y_sequences.tolist(), maxlen=max_sequence_length, padding='post', value=0)\n",
        "\n",
        "  # data split into training and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(sequences_padded, y_padded, test_size=0.2, random_state=42)\n",
        "\n",
        "  # data types are uniform\n",
        "  X_train = np.array(X_train, dtype='float32')\n",
        "  y_train = np.array(y_train, dtype='float32')\n",
        "  X_test = np.array(X_test, dtype='float32')\n",
        "  y_test = np.array(y_test, dtype='float32')\n",
        "\n",
        "  model = Sequential([\n",
        "      Masking(mask_value=-1, input_shape=(max_sequence_length, 1)),\n",
        "      LSTM(256, return_sequences=False),\n",
        "      Dense(1, activation='relu'),\n",
        "  ])\n",
        "\n",
        "  def lr_scheduler(epoch, lr):\n",
        "      decay_rate = 0.1\n",
        "      decay_step = 90\n",
        "      if epoch % decay_step == 0 and epoch:\n",
        "          return lr * decay_rate\n",
        "      return lr\n",
        "\n",
        "  callbacks = [\n",
        "      LearningRateScheduler(lr_scheduler, verbose=0), # Changed verbose from 1 to 0\n",
        "      EarlyStopping(monitor='val_loss', patience=100, verbose=0),\n",
        "  ]\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='Adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "  history = model.fit(X_train, y_train, epochs=total_epochs, batch_size=32, validation_split=0.2, verbose=0, callbacks=callbacks) # Changed verbose from 1 to 0\n",
        "\n",
        "  print(\"Training time:\", (round((time.time() - start_time)/60,3)), \"minutes\")\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x-JdQpZbyQT"
      },
      "outputs": [],
      "source": [
        "def load_and_prepare_test_set(test_set):\n",
        "    test_df = test_set.copy()\n",
        "\n",
        "    # Specify column names\n",
        "    case_id_col = test_df.columns[0]\n",
        "    event_date_col = test_df.columns[1]\n",
        "\n",
        "    # Prepare the test data\n",
        "    test_df[event_date_col] = pd.to_datetime(test_df[event_date_col])\n",
        "    test_df.sort_values([case_id_col, event_date_col], inplace=True)\n",
        "    test_df['case_end'] = test_df.groupby(case_id_col)[event_date_col].transform('max')\n",
        "    test_df['remaining_time'] = ((test_df['case_end'] - test_df[event_date_col]).dt.total_seconds() / 86400).astype(float) # in days\n",
        "\n",
        "    # Handle unknown event labels\n",
        "    test_df['time_diff'] = test_df.groupby(case_id_col)[event_date_col].diff().dt.total_seconds() / 86400 # in days\n",
        "    test_df['time_diff'] = test_df['time_diff'].fillna(0).astype(int)\n",
        "\n",
        "    # Generate X_test and y_test for each case\n",
        "    rows = []\n",
        "    case_ids = test_df[case_id_col].unique()\n",
        "    max_sequence_length = 100\n",
        "\n",
        "    for cid in case_ids:\n",
        "        case_data = test_df[test_df[case_id_col] == cid]\n",
        "        events = list(case_data['time_diff'])\n",
        "        remaining_times = case_data['remaining_time'].values\n",
        "\n",
        "        for i in range(1, len(events) + 1):\n",
        "            x_test = pad_sequences([events[:i]], maxlen=max_sequence_length, padding='post', dtype='float32', value=(0))\n",
        "            rows.append({\n",
        "                'case_id': cid,\n",
        "                'x_test': x_test[0],\n",
        "                'y_test': remaining_times[i-1]\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STE7XUIKbyQT"
      },
      "outputs": [],
      "source": [
        "def generate_predictions(test_set, model,):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Load and prepare the test set\n",
        "    test_df = load_and_prepare_test_set(test_set)\n",
        "\n",
        "    # Make predictions\n",
        "    X_test = np.stack(test_df['x_test'].values).astype('float32')\n",
        "    predictions = model.predict(X_test, verbose=1)\n",
        "\n",
        "    # Extract the last non-zero prediction for each sequence\n",
        "    test_df['prediction'] = [pred[np.nonzero(pred)[0][-1]] if np.nonzero(pred)[0].size > 0 else 0 for pred in predictions]\n",
        "\n",
        "    print(\"Evaluation time:\", (round((time.time() - start_time)/60,3)), \"minutes\")\n",
        "\n",
        "    # Edited to return evaluation time\n",
        "    return test_df[['case_id', 'y_test', 'prediction']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mae(results_df): # in days\n",
        "    y_true = results_df['y_test'].values\n",
        "    y_pred = results_df['prediction'].values\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    return mae"
      ],
      "metadata": {
        "id": "nS2Z-W55byQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tests"
      ],
      "metadata": {
        "id": "XfRwggxBbyQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in ['BPIC11_f1', 'BPIC15_1_f2', 'Credit', 'Pub', 'BPIC12', 'BPIC17']:\n",
        "  subset = dataset\n",
        "  score = np.array([])\n",
        "  time_scores = np.array([])\n",
        "  df_test = pd.read_csv(f\"./{dataset}/{subset}/{subset}-TEST-CLEAN.csv\")\n",
        "  df_test = df_test[[\"NUMPRO\", \"DATAEV\", \"NUMGIU\"]]\n",
        "  for i in range(3):\n",
        "    start_time = time.time()\n",
        "    df = pd.read_csv(f\"./{dataset}/{subset}/{subset}_prepared/{subset}-TRAIN-CLEAN.csv\")\n",
        "    df = df[[\"NUMPRO\", \"DATAEV\", \"NUMGIU\"]]\n",
        "    model = model_evaluate(df)\n",
        "    result_df = generate_predictions(df_test, model)\n",
        "    score = np.append(score, calculate_mae(result_df))\n",
        "    time_scores = np.append(time_scores, (round((time.time() - start_time)/60,3)))\n",
        "  score_avg = np.average(score)\n",
        "  time_avg = np.average(time_scores)\n",
        "  print(dataset, ':', score_avg)\n",
        "  print(dataset, ':', time_avg, \"minutes\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f384672-f692-4dd2-9c70-99d182da41cf",
        "id": "YUBTvWDCbyQU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.528 minutes\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.019 minutes\n",
            "Training time: 1.413 minutes\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "Evaluation time: 0.027 minutes\n",
            "Training time: 1.401 minutes\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.019 minutes\n",
            "BPIC11_f1 : 176.9116745080565\n",
            "BPIC11_f1 : 1.136 minutes\n",
            "\n",
            "Training time: 1.184 minutes\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.026 minutes\n",
            "Training time: 1.274 minutes\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.025 minutes\n",
            "Training time: 1.3 minutes\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Evaluation time: 0.024 minutes\n",
            "BPIC15_1_f2 : 44.00802639552467\n",
            "BPIC15_1_f2 : 1.2803333333333333 minutes\n",
            "\n",
            "Training time: 1.227 minutes\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.046 minutes\n",
            "Training time: 1.74 minutes\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "Evaluation time: 0.056 minutes\n",
            "Training time: 1.107 minutes\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.042 minutes\n",
            "Credit : 0.054968866611563354\n",
            "Credit : 1.4126666666666665 minutes\n",
            "\n",
            "Training time: 2.808 minutes\n",
            "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.057 minutes\n",
            "Training time: 2.775 minutes\n",
            "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.061 minutes\n",
            "Training time: 2.596 minutes\n",
            "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.056 minutes\n",
            "Pub : 6.7129415505262005\n",
            "Pub : 2.7883333333333336 minutes\n",
            "\n",
            "Training time: 6.853 minutes\n",
            "\u001b[1m1619/1619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.162 minutes\n",
            "Training time: 8.437 minutes\n",
            "\u001b[1m1619/1619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.209 minutes\n",
            "Training time: 7.88 minutes\n",
            "\u001b[1m1619/1619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.15 minutes\n",
            "BPIC12 : 8.08705513963512\n",
            "BPIC12 : 7.903666666666666 minutes\n",
            "\n",
            "Training time: 8.194 minutes\n",
            "\u001b[1m7534/7534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.836 minutes\n",
            "Training time: 14.83 minutes\n",
            "\u001b[1m7534/7534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.651 minutes\n",
            "Training time: 17.915 minutes\n",
            "\u001b[1m7534/7534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step\n",
            "Evaluation time: 0.838 minutes\n",
            "BPIC17 : 12.745948562356775\n",
            "BPIC17 : 14.445 minutes\n",
            "\n"
          ]
        }
      ]
    }
  ]
}