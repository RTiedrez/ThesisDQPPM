{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the code for a number of naive cleaning tchniques intended to improve the effectiveness of remaining time prediction on polluted datasets."
      ],
      "metadata": {
        "id": "uAonqyU2gpLQ"
      },
      "id": "uAonqyU2gpLQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "kDl5QFRr_vPp"
      },
      "id": "kDl5QFRr_vPp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "9ldr_qgr_x3J"
      },
      "id": "9ldr_qgr_x3J"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import statistics\n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from scipy.spatial import distance as scipy_distance\n",
        "\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# init stemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#fasttext.util.download_model('en', if_exists='ignore')  # English (long to import) (uncomment to import the first time)\n",
        "nlp_model = fasttext.load_model('cc.en.300.bin')\n",
        "\n",
        "#!pip install -q python-Levenshtein\n",
        "import Levenshtein as lev\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "LYvz9hpnFAe0"
      },
      "id": "LYvz9hpnFAe0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Takes a while to download, only run for SYNONYMOUS\n",
        "#import fasttext\n",
        "#import fasttext.util\n",
        "#\n",
        "#fasttext.util.download_model('en', if_exists='ignore') # English\n",
        "#model = fasttext.load_model('cc.en.300.bin')\n",
        "#TODO: try other models"
      ],
      "metadata": {
        "id": "VNW5jUGXCWgb"
      },
      "id": "VNW5jUGXCWgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Globals"
      ],
      "metadata": {
        "id": "aVRMjHuLxDBy"
      },
      "id": "aVRMjHuLxDBy"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_types = [\"DISTORTED\", \"POLLUTED.NORND\", \"POLLUTED.RANDOM\"]\n",
        "percentages = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "dq = [\"DISTINCT\", \"UNIQUENESS\", \"CONSTANCY\"]\n",
        "dq_scorings = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
        "metrics = dq+dq_scorings\n",
        "metrics_time = metrics + [\"time\"]"
      ],
      "metadata": {
        "id": "hJDHSuJmYMmF"
      },
      "id": "hJDHSuJmYMmF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "r1xyvO2P_zdR"
      },
      "id": "r1xyvO2P_zdR"
    },
    {
      "cell_type": "code",
      "source": [
        "def DQ_assess(df, metrics): # might be renamed to \"profiling\" in the future\n",
        "  \"\"\"\n",
        "  Returns intrinsic DQ metrics for a list of labels\n",
        "  \"\"\"\n",
        "\n",
        "  output = {}\n",
        "\n",
        "  labels = df.CCDOEV\n",
        "\n",
        "  DISTINCT = labels.nunique() #\n",
        "  COUNT = labels.count()\n",
        "  ROWS = len(labels) # same\n",
        "  MAX_COUNTS = max(labels.value_counts())\n",
        "  AVG_EVENTS = df.groupby(\"NUMPRO\").size().mean()\n",
        "  AVG_LENGTH = labels.apply(len).mean()\n",
        "  TRACES = df.NUMPRO.nunique()\n",
        "\n",
        "  if \"COUNT\" in metrics:\n",
        "    output[\"COUNT\"] = COUNT\n",
        "  if \"DISTINCT\" in metrics:\n",
        "    output[\"DISTINCT\"] = DISTINCT\n",
        "  if \"UNIQUENESS\" in metrics:\n",
        "    UNIQUENESS = DISTINCT / ROWS\n",
        "    output[\"UNIQUENESS\"] = UNIQUENESS\n",
        "  if \"CONSTANCY\" in metrics:\n",
        "    CONSTANCY = MAX_COUNTS / COUNT\n",
        "    output[\"CONSTANCY\"] = CONSTANCY\n",
        "  if \"COMPLEXITY\" in metrics:\n",
        "    COMPLEXITY = AVG_EVENTS / TRACES\n",
        "    output[\"COMPLEXITY\"] = COMPLEXITY\n",
        "  if \"CONSISTENCY\" in metrics:\n",
        "    distances = labels.apply(len)-AVG_LENGTH\n",
        "    CONSISTENCY = distances.sum() / ROWS\n",
        "    output[\"CONSISTENCY\"] = CONSISTENCY\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "edhbaFidCEOv"
      },
      "id": "edhbaFidCEOv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_nlp_preprocess_2 = lambda s: ''.join([lemmatizer.lemmatize(word)+' ' for word in s.split()])[:-1].lower()\n",
        "\n",
        "embedding_db = {}\n",
        "def get_embedding(sw):\n",
        "  \"\"\"sw can be either a string or a word\"\"\"\n",
        "  if sw in embedding_db:\n",
        "    return embedding_db[sw]\n",
        "  else:\n",
        "    if len(sw.split()) > 1: #check if sentence or single word\n",
        "      embedding = nlp_model.get_sentence_vector(sw)\n",
        "      embedding_db[sw] = embedding\n",
        "    else:\n",
        "      embedding = nlp_model.get_word_vector(sw)\n",
        "      embedding_db[sw] = embedding\n",
        "    return embedding\n",
        "\n",
        "def get_antonyms(word):\n",
        "\n",
        "  antonyms = []\n",
        "  for syn in wordnet.synsets(word):\n",
        "      for i in syn.lemmas():\n",
        "          if i.antonyms():\n",
        "                antonyms.append(i.antonyms()[0].name())\n",
        "\n",
        "  antonyms_full = antonyms.copy()\n",
        "  for anto in antonyms:\n",
        "    for syn in wordnet.synsets(anto):\n",
        "        for lm in syn.lemmas():\n",
        "            antonyms_full.append(lm.name())\n",
        "\n",
        "  return set(antonyms_full)\n",
        "\n",
        "anto_db = {}\n",
        "def my_distance(s1, s2):\n",
        "  \"\"\"\n",
        "  Returns semantic distance between two strings s1 and s2, with penalty for antonyms\n",
        "  \"\"\"\n",
        "  words1 = s1.split()\n",
        "  words2 = s2.split()\n",
        "  antos1 = []\n",
        "  antos2 = []\n",
        "\n",
        "  penalty = 0 # temp\n",
        "\n",
        "  for word in words1:\n",
        "    if word in anto_db:\n",
        "      antos1 += anto_db[word]\n",
        "    else:\n",
        "      temp = list(get_antonyms(word))\n",
        "      antos1 += temp\n",
        "      anto_db[word] = temp\n",
        "\n",
        "  for word in words2:\n",
        "    if word in anto_db:\n",
        "      antos2 += anto_db[word]\n",
        "    else:\n",
        "      temp = list(get_antonyms(word))\n",
        "      antos2 += temp\n",
        "      anto_db[word] = temp\n",
        "\n",
        "  penalty = 0.25*(len(set(words1).intersection(set(antos2)))+len(set(words2).intersection(set(antos1)))) #add a 0.25 penalty for each pair of antonyms found\n",
        "\n",
        "  return penalty + scipy_distance.cosine(get_embedding(s1), get_embedding(s2))"
      ],
      "metadata": {
        "id": "JwW_IlEcgcSI"
      },
      "id": "JwW_IlEcgcSI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DBSCAN_labels(labels, distance=\"levenshtein\", threshold=1, preprocessing=None, sem_dist=None):\n",
        "  \"\"\"\n",
        "  Takes a list of labels as input, returns a clustering dict, and a dictionary containing all distances already computed\n",
        "  \"\"\"\n",
        "\n",
        "  ids = {s: None for s in labels} # Cluster IDs\n",
        "  k = 0\n",
        "  clustered = set() # Set of labels that have been assigned to a cluster\n",
        "  not_clustered = list(labels) # Labels that have yet to belong to a cluster\n",
        "\n",
        "  distances_dict = {}\n",
        "\n",
        "  if distance==\"semantic\":\n",
        "    if preprocessing is None:\n",
        "        preprocessing = lambda s: s\n",
        "\n",
        "    if sem_dist is None:\n",
        "        sem_dist = lambda s1, s2: scipy_distance.cosine(get_embedding(preprocessing(s1)), get_embedding(preprocessing(s2)))\n",
        "\n",
        "    distances_dict |= {(s1,s2):sem_dist(preprocessing(s1), preprocessing(s2)) for s1 in labels for s2 in labels} # precompute if semantic (TO_CHECK)\n",
        "\n",
        "  def get_distance(s1, s2, distance): # So we do not compute the same distance twice. # move it so cleaning() can use it\n",
        "      \"\"\"\n",
        "      Returns some distance between two strings s1 and s2, checking first if the distance was not computed before\n",
        "      \"\"\"\n",
        "      if (s1, s2) in distances_dict:\n",
        "          return distances_dict[(s1, s2)]\n",
        "      elif (s2,s1) in distances_dict:\n",
        "          return distances_dict[(s2, s1)]\n",
        "      else:\n",
        "          if distance == \"levenshtein\":\n",
        "              dist = lev.distance(s1, s2)\n",
        "          elif distance == \"hamming\": # Not used\n",
        "              dist = round(scipy_distance.hamming(list(s1), list(s2)) * len(list(s1)))\n",
        "          elif distance == 'semantic': # Very costly when labels diversity is huge\n",
        "              # Need to define global nlp_model beforehand\n",
        "              dist = distances_dict[(s1,s2)]\n",
        "\n",
        "          distances_dict[(s1, s2)] = dist\n",
        "          return dist\n",
        "\n",
        "  while not_clustered: # Stops when all labels belong to a cluster\n",
        "      to_check = [not_clustered[0]] # We need to select an initial datapoint for clustering\n",
        "      while to_check: # Stops when empty\n",
        "          x = to_check.pop(0)\n",
        "          closest_labels = [string for string in not_clustered if (get_distance(x, string, distance) <= threshold)]\n",
        "\n",
        "          for y in closest_labels:\n",
        "              if y not in clustered:\n",
        "                  ids[y] = k # Add label y to cluster k\n",
        "                  to_check.append(y) # We will need to check datapoints around y\n",
        "                  clustered.add(y)\n",
        "\n",
        "      not_clustered = [x for x in not_clustered if x not in clustered]\n",
        "      k += 1 # next cluster\n",
        "\n",
        "  return {index: list(set([x for x in labels if ids[x] == index])) for index in range(k)} # list(set()) to remove duplicates"
      ],
      "metadata": {
        "id": "id4JpHUkA13p"
      },
      "id": "id4JpHUkA13p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_most_common(clustering, frequencies):\n",
        "  \"\"\"\n",
        "  Returns a dict matching each label in clustering to its most common lookalike found in clustering\n",
        "  \"\"\"\n",
        "  C_better = {} # Match each string to its most common lookalike found in its cluster\n",
        "  for cluster in clustering.values(): # find most common in cluster\n",
        "    cluster_with_frequencies = [(activity,frequencies[activity]) for activity in cluster]\n",
        "    cluster_with_frequencies.sort(key=lambda x: x[1], reverse=True)\n",
        "    most_common = cluster_with_frequencies[0][0]\n",
        "    for activity in cluster:\n",
        "      C_better[activity] = most_common\n",
        "\n",
        "  return C_better"
      ],
      "metadata": {
        "id": "Kde0SntfAJjw"
      },
      "id": "Kde0SntfAJjw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conf_matrix(clean, dirty):\n",
        "  \"\"\"\n",
        "  Returns classification metrics for a list of labels compared to a reference\n",
        "  \"\"\"\n",
        "  test_accuracy = round(accuracy_score(clean, dirty),4)\n",
        "  test_precision = round(precision_score(clean, dirty, average='weighted', zero_division=np.nan),4)\n",
        "  test_recall = round(recall_score(clean, dirty, average='weighted', zero_division=np.nan),4)\n",
        "  test_f1 = round(f1_score(clean, dirty, average='weighted'),4)\n",
        "\n",
        "  return test_accuracy, test_precision, test_recall, test_f1"
      ],
      "metadata": {
        "id": "OKTQ9qQxAegQ"
      },
      "id": "OKTQ9qQxAegQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: split between cleaning and scoring\n",
        "def cleaning(pollution_type, reference_labels, technique=\"DBSCAN\", distance=\"levenshtein\", threshold=0, dataset=\"BPIC11_f1\", language=\"nl\", limit=8, preprocessing=None, sem_dist=None):\n",
        "  \"\"\"\n",
        "  Cleans a list of labels and returns its scores. Also saves cleaned dataset\n",
        "  \"\"\"\n",
        "  initial_time = time.time()\n",
        "  # distances_dict = {} takes way too much memory\n",
        "\n",
        "  #if technique == \"languageTool\":\n",
        "  #  tool = language_tool_python.LanguageTool(language)\n",
        "\n",
        "  scores_matrix_cleaned = {}\n",
        "  for percentage in percentages:\n",
        "    scores_matrix_cleaned[percentage] = {}\n",
        "    for i in range(limit):\n",
        "      start_time = time.time()\n",
        "      df = pd.read_csv(f\"{directory_path}{dataset}-TRAIN-{pollution_type}-{percentage}-{i}.csv\")\n",
        "      labels = df.CCDOEV\n",
        "      freq = labels.value_counts() # We need labels frequencies to either identify the most common one in a cluster or rare labels\n",
        "\n",
        "      if (technique == \"DBSCAN\"):\n",
        "        clustering = DBSCAN_labels(labels.unique(), distance, threshold, preprocessing=preprocessing, sem_dist=sem_dist) # clustering\n",
        "\n",
        "        mapping = cluster_most_common(clustering, freq.to_dict())\n",
        "\n",
        "      #elif (technique == \"languageTool\"): # Spellcheck (too slow)\n",
        "      #  mapping = {s:language_tool_python.utils.correct(s, tool.check(s)) for s in labels.unique()}\n",
        "\n",
        "      elif (technique==\"DROP\"): # Replace rare labels with empty strings\n",
        "        mapping = {}\n",
        "        for s in labels.unique():\n",
        "          if freq[s] >= threshold*len(labels):\n",
        "            mapping[s] = s\n",
        "          else:\n",
        "            mapping[s] = \"\"\n",
        "\n",
        "      elif (technique==\"DROP_DELETE\"): # Remove rows with rare labels\n",
        "        df = df[df.CCDOEV.isin(freq[freq>threshold*len(labels)].index)].reset_index(drop=True)\n",
        "        mapping = {s:s for s in labels.unique()}\n",
        "\n",
        "      cleaned_labels = labels.replace(mapping) # TO_CHECK: map changed to replace\n",
        "      df.CCDOEV = cleaned_labels\n",
        "\n",
        "      # Saving cleaned dataset\n",
        "      df.to_csv(f\"./{dataset}/{dataset}/{dataset}_cleaned/{dataset}-TRAIN-{pollution_type}-{percentage}-{i}_CLEANED-{distance}-{threshold}.csv\", index=False)\n",
        "      # Example: ./BPIC11_f1/BPIC11_f1/BPIC11_f1_cleaned/BPIC11_f1-TRAIN-DISTORTED-0.1-1_CLEANED-levenshtein-1.csv\n",
        "\n",
        "      scores_matrix_cleaned[percentage][i] =  DQ_assess(df, dq) | dict(zip(dq_scorings, conf_matrix(reference_labels, cleaned_labels)))\n",
        "\n",
        "      elapsed = time.time() - start_time\n",
        "      scores_matrix_cleaned[percentage][i][\"time\"] = elapsed\n",
        "\n",
        "      print(f\"{percentage}: {i+1}/{limit} done in {round(elapsed/60,3)} minutes\")\n",
        "\n",
        "  print(\"Total time:\", (round((time.time() - initial_time)/60,3)), \"minutes\")\n",
        "\n",
        "  if (technique != \"DROP_DELETE\"): # No scores for DROP_DELETE since the length of the dataset changes.\n",
        "    scores_matrix_cleaned_avg = {}\n",
        "    for percentage in percentages:\n",
        "      scores_matrix_cleaned_avg[percentage] = {}\n",
        "      for metric in metrics_time:\n",
        "        scores_matrix_cleaned_avg[percentage][metric] = np.mean([scores_matrix_cleaned[percentage][i][metric] for i in range(limit)])\n",
        "    return scores_matrix_cleaned_avg"
      ],
      "metadata": {
        "id": "XpoOAAWREUDU"
      },
      "id": "XpoOAAWREUDU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_db = {}\n",
        "\n",
        "def get_embedding(sw):\n",
        "  \"\"\"sw can be either a string or a word\"\"\"\n",
        "  if sw in embedding_db:\n",
        "    return embedding_db[sw]\n",
        "  else:\n",
        "    if len(sw.split()) > 1: #check if sentence or single word\n",
        "      embedding = nlp_model.get_sentence_vector(sw)\n",
        "      embedding_db[sw] = embedding\n",
        "    else:\n",
        "      embedding = nlp_model.get_word_vector(sw)\n",
        "      embedding_db[sw] = embedding\n",
        "    return embedding\n",
        "\n",
        "def get_antonyms(word):\n",
        "\n",
        "  antonyms = []\n",
        "\n",
        "  for syn in wordnet.synsets(word):\n",
        "      for i in syn.lemmas():\n",
        "          if i.antonyms():\n",
        "                antonyms.append(i.antonyms()[0].name())\n",
        "\n",
        "  antonyms_full = antonyms.copy()\n",
        "  for anto in antonyms:\n",
        "    for syn in wordnet.synsets(anto):\n",
        "        for lm in syn.lemmas():\n",
        "            antonyms_full.append(lm.name())\n",
        "\n",
        "  return set(antonyms_full)\n",
        "\n",
        "anto_db = {}\n",
        "\n",
        "def my_distance(s1, s2):\n",
        "  \"\"\"\n",
        "  Returns semantic distance between two strings s1 and s2, with penalty for antonyms\n",
        "  \"\"\"\n",
        "  words1 = s1.split()\n",
        "  words2 = s2.split()\n",
        "  antos1 = []\n",
        "  antos2 = []\n",
        "\n",
        "  penalty = 0 # temp\n",
        "\n",
        "  for word in words1:\n",
        "    if word in anto_db:\n",
        "      antos1 += anto_db[word]\n",
        "    else:\n",
        "      temp = list(get_antonyms(word))\n",
        "      antos1 += temp\n",
        "      anto_db[word] = temp\n",
        "\n",
        "  for word in words2:\n",
        "    if word in anto_db:\n",
        "      antos2 += anto_db[word]\n",
        "    else:\n",
        "      temp = list(get_antonyms(word))\n",
        "      antos2 += temp\n",
        "      anto_db[word] = temp\n",
        "\n",
        "  penalty = 0.25*(len(set(words1).intersection(set(antos2)))+len(set(words2).intersection(set(antos1)))) #add a 0.25 penalty for each pair of antonyms found\n",
        "\n",
        "  return penalty + scipy_distance.cosine(get_embedding(s1), get_embedding(s2))"
      ],
      "metadata": {
        "id": "J-kSFy5VklzV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "J-kSFy5VklzV"
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance as scipy_distance\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# init stemmer\n",
        "porter_stemmer=PorterStemmer()\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        "nlp_model = fasttext.load_model('cc.en.300.bin')\n",
        "\n",
        "def patterner(df):\n",
        "    \"\"\"Creates a list of 3-tuples of labels\"\"\"\n",
        "    labels = df['CCDOEV'].values\n",
        "    patterns = list(zip(labels[:-2], labels[1:-1], labels[2:]))\n",
        "    return patterns\n",
        "\n",
        "def patterns_distance(p1, p2, distance_matrix={}):\n",
        "    \"\"\"Calculates some semantic distance between patterns\"\"\"\n",
        "    dist = 0\n",
        "    for i in range(len(p1)): # should always be 3\n",
        "        dist += distance_matrix.get((p1[i], p2[i]), my_distance(p1[i], p2[i])) # Note à soi-même: utiliser .get() davantage\n",
        "    return dist\n",
        "\n",
        "def rebuild_labels(patterns):\n",
        "    \"\"\"Rebuilds labels from patterns\"\"\"\n",
        "    return [patterns[0][0]] + [pattern[1] for pattern in patterns] + [patterns[-1][-1]]\n",
        "\n",
        "def homo_cleaning(df):\n",
        "  \"\"\"Cleans a SYNONYM- or HOMONYM-corrupted dataset\"\"\"\n",
        "  start_time = time.time()\n",
        "\n",
        "  patterns = patterner(df)\n",
        "  patterns_frequencies = {pattern:0 for pattern in patterns}\n",
        "  for pattern in patterns: # Count occurences of each pattern\n",
        "    patterns_frequencies[pattern]+=1\n",
        "\n",
        "  c = df['CCDOEV'].value_counts().values\n",
        "  ratio = c.std() / c.mean()\n",
        "\n",
        "  threshold = 0.005 if ratio < 1 else 0.01\n",
        "  thresh = int(len(patterns) * threshold)\n",
        "\n",
        "  frequent_patterns = [pattern for pattern, freq in patterns_frequencies.items() if freq >= thresh]\n",
        "  rare_patterns = [pattern for pattern, freq in patterns_frequencies.items() if freq < thresh]\n",
        "\n",
        "  mapping = {}\n",
        "\n",
        "  for x in set(patterns):\n",
        "    mapping[x] = x\n",
        "    if x in rare_patterns:\n",
        "      min = np.inf\n",
        "      for y in frequent_patterns:\n",
        "        if patterns_distance(x,y) < min:\n",
        "          min = patterns_distance(x,y)\n",
        "          mapping[x] = y\n",
        "\n",
        "  df_final = df.copy()\n",
        "  rebuilt_patterns = [mapping[pattern] for pattern in patterns]\n",
        "  df_final[\"CCDOEV\"] = rebuild_labels(rebuilt_patterns)\n",
        "\n",
        "  return df_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4X4hrVnZ9Jr",
        "outputId": "1569569c-515f-4dbd-a19b-667315bcb517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\pokro\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "id": "c4X4hrVnZ9Jr"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: split between cleaning and scoring\n",
        "def cleaning_patterns(pollution_type, reference_labels, dataset=\"BPIC11_f1\", limit=8):\n",
        "  \"\"\"\n",
        "  Cleans a list of labels and returns its scores. Also saves cleaned dataset\n",
        "  \"\"\"\n",
        "  initial_time = time.time()\n",
        "\n",
        "  scores_matrix_cleaned = {}\n",
        "  for percentage in percentages:\n",
        "    scores_matrix_cleaned[percentage] = {}\n",
        "    for i in range(limit):\n",
        "      start_time = time.time()\n",
        "      df = pd.read_csv(f\"{directory_path}{dataset}-TRAIN-{pollution_type}-{percentage}-{i}.csv\")\n",
        "      labels = df.CCDOEV\n",
        "      freq = labels.value_counts() # We need labels frequencies to either identify the most common one in a cluster or rare labels\n",
        "\n",
        "      df = homo_cleaning(df)\n",
        "\n",
        "      # Saving cleaned dataset\n",
        "      df.to_csv(f\"./{dataset}/{dataset}/{dataset}_cleaned/{dataset}-TRAIN-{pollution_type}-{percentage}-{i}_CLEANED-{distance}.csv\", index=False)\n",
        "      # Example: ./BPIC11_f1/BPIC11_f1/BPIC11_f1_cleaned/BPIC11_f1-TRAIN-DISTORTED-0.1-1_CLEANED-levenshtein-1.csv\n",
        "\n",
        "      scores_matrix_cleaned[percentage][i] = DQ_assess(df, dq) | dict(zip(dq_scorings, conf_matrix(reference_labels, df.CCDOEV)))\n",
        "\n",
        "      elapsed = time.time() - start_time\n",
        "      scores_matrix_cleaned[percentage][i][\"time\"] = elapsed\n",
        "\n",
        "      print(f\"{percentage}: {i+1}/{limit} done in {round(elapsed/60,3)} minutes\")\n",
        "\n",
        "  print(\"Total time:\", (round((time.time() - initial_time)/60,3)), \"minutes\")\n",
        "\n",
        "  scores_matrix_cleaned_avg = {}\n",
        "  for percentage in percentages:\n",
        "    scores_matrix_cleaned_avg[percentage] = {}\n",
        "    for metric in metrics_time:\n",
        "      scores_matrix_cleaned_avg[percentage][metric] = np.mean([scores_matrix_cleaned[percentage][i][metric] for i in range(limit)])\n",
        "  return scores_matrix_cleaned_avg"
      ],
      "metadata": {
        "id": "l6UgatGrJlqT"
      },
      "execution_count": null,
      "outputs": [],
      "id": "l6UgatGrJlqT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BPIC '11"
      ],
      "metadata": {
        "id": "PzIurNjV_gW5"
      },
      "id": "PzIurNjV_gW5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "tLPPSdRyAHf9"
      },
      "id": "tLPPSdRyAHf9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defines"
      ],
      "metadata": {
        "id": "4nPB_tcjEbuV"
      },
      "id": "4nPB_tcjEbuV"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"BPIC11_f1\""
      ],
      "metadata": {
        "id": "ld_TOGiG3IJS"
      },
      "id": "ld_TOGiG3IJS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "directory_path = f'./{dataset}/{dataset}/{dataset}_prepared/'\n",
        "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-12T09:24:23.706194Z",
          "start_time": "2024-07-12T09:24:23.701590Z"
        },
        "id": "Vd-cxr8DD7gL"
      },
      "execution_count": null,
      "id": "Vd-cxr8DD7gL"
    },
    {
      "cell_type": "code",
      "source": [
        "files.remove(f'{dataset}-TRAIN-CLEAN.csv')"
      ],
      "metadata": {
        "id": "NdhHBXRXEs94"
      },
      "id": "NdhHBXRXEs94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ref = pd.read_csv(f'./{dataset}/{dataset}/{dataset}_prepared/{dataset}-TRAIN-CLEAN.csv')\n",
        "ref = df_ref.CCDOEV"
      ],
      "metadata": {
        "id": "v2vW1-QND0Ve"
      },
      "id": "v2vW1-QND0Ve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline"
      ],
      "metadata": {
        "id": "2EU7qsfK5l-U"
      },
      "id": "2EU7qsfK5l-U"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute DQ metrics for all corrupted datasets, to use as a baseline\n",
        "dq_dict = {}\n",
        "for pollution_type in pollution_types:\n",
        "  dq_dict[pollution_type] = {}\n",
        "  for percentage in percentages:\n",
        "    dq_dict[pollution_type][percentage] = {}\n",
        "    for i in range(8):\n",
        "      df = pd.read_csv(f\"{directory_path}{dataset}-TRAIN-{pollution_type}-{percentage}-{i}.csv\")\n",
        "      labels = df.CCDOEV\n",
        "      dq_dict[pollution_type][percentage][i] = DQ_assess(df, dq)| dict(zip(dq_scorings, conf_matrix(ref, labels)))"
      ],
      "metadata": {
        "id": "iNOMlBN5upAX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "iNOMlBN5upAX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Average the metrics\n",
        "dq_dict_avg = {}\n",
        "for pollution_type in pollution_types:\n",
        "  dq_dict_avg[pollution_type] = {}\n",
        "  for percentage in percentages:\n",
        "    dq_dict_avg[pollution_type][percentage] = {}\n",
        "    for metric in metrics:\n",
        "      dq_dict_avg[pollution_type][percentage][metric] = np.mean([dq_dict[pollution_type][percentage][i][metric] for i in range(8)])\n",
        "\n",
        "scorings = DQ_assess(df_ref, dq) | dict(zip(dq_scorings, conf_matrix(ref, ref)))\n",
        "\n",
        "dq_dict_avg[\"CLEAN\"] = {percentage:scorings for percentage in percentages}"
      ],
      "metadata": {
        "id": "AjLhI-ZwwVPa"
      },
      "id": "AjLhI-ZwwVPa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}-REF_scores_matrix_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(dq_dict_avg, f)"
      ],
      "metadata": {
        "id": "goMeZ_sMupAY"
      },
      "execution_count": null,
      "outputs": [],
      "id": "goMeZ_sMupAY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Levenshtein clustering (d=1)"
      ],
      "metadata": {
        "id": "MoqvuvQQRCCF"
      },
      "id": "MoqvuvQQRCCF"
    },
    {
      "cell_type": "code",
      "source": [
        "distance = \"levenshtein\" # should be renamed to 'distance'\n",
        "technique = \"DBSCAN\"\n",
        "threshold = 1\n",
        "scores_matrix_levenshtein1_avg = {}"
      ],
      "metadata": {
        "id": "2lrFhnIHiSdN"
      },
      "id": "2lrFhnIHiSdN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distorted"
      ],
      "metadata": {
        "id": "orIp0BQI_m0h"
      },
      "id": "orIp0BQI_m0h"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[0]\n",
        "scores_matrix_levenshtein1_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "x6byoNxYjaw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9dcaa2b-668f-4815-fb26-423835cd00d7"
      },
      "id": "x6byoNxYjaw9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.014 minutes\n",
            "0.05: 2/8 done in 0.014 minutes\n",
            "0.05: 3/8 done in 0.014 minutes\n",
            "0.05: 4/8 done in 0.014 minutes\n",
            "0.05: 5/8 done in 0.014 minutes\n",
            "0.05: 6/8 done in 0.014 minutes\n",
            "0.05: 7/8 done in 0.014 minutes\n",
            "0.05: 8/8 done in 0.014 minutes\n",
            "0.1: 1/8 done in 0.037 minutes\n",
            "0.1: 2/8 done in 0.038 minutes\n",
            "0.1: 3/8 done in 0.038 minutes\n",
            "0.1: 4/8 done in 0.039 minutes\n",
            "0.1: 5/8 done in 0.038 minutes\n",
            "0.1: 6/8 done in 0.038 minutes\n",
            "0.1: 7/8 done in 0.038 minutes\n",
            "0.1: 8/8 done in 0.037 minutes\n",
            "0.2: 1/8 done in 0.108 minutes\n",
            "0.2: 2/8 done in 0.113 minutes\n",
            "0.2: 3/8 done in 0.108 minutes\n",
            "0.2: 4/8 done in 0.108 minutes\n",
            "0.2: 5/8 done in 0.108 minutes\n",
            "0.2: 6/8 done in 0.109 minutes\n",
            "0.2: 7/8 done in 0.106 minutes\n",
            "0.2: 8/8 done in 0.106 minutes\n",
            "0.3: 1/8 done in 0.205 minutes\n",
            "0.3: 2/8 done in 0.214 minutes\n",
            "0.3: 3/8 done in 0.209 minutes\n",
            "0.3: 4/8 done in 0.206 minutes\n",
            "0.3: 5/8 done in 0.206 minutes\n",
            "0.3: 6/8 done in 0.206 minutes\n",
            "0.3: 7/8 done in 0.206 minutes\n",
            "0.3: 8/8 done in 0.204 minutes\n",
            "0.4: 1/8 done in 0.344 minutes\n",
            "0.4: 2/8 done in 0.362 minutes\n",
            "0.4: 3/8 done in 0.35 minutes\n",
            "0.4: 4/8 done in 0.339 minutes\n",
            "0.4: 5/8 done in 0.328 minutes\n",
            "0.4: 6/8 done in 0.33 minutes\n",
            "0.4: 7/8 done in 0.341 minutes\n",
            "0.4: 8/8 done in 0.325 minutes\n",
            "0.5: 1/8 done in 0.471 minutes\n",
            "0.5: 2/8 done in 0.474 minutes\n",
            "0.5: 3/8 done in 0.483 minutes\n",
            "0.5: 4/8 done in 0.475 minutes\n",
            "0.5: 5/8 done in 0.483 minutes\n",
            "0.5: 6/8 done in 0.478 minutes\n",
            "0.5: 7/8 done in 0.486 minutes\n",
            "0.5: 8/8 done in 0.481 minutes\n",
            "Total time: 9.489 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Nonrandom"
      ],
      "metadata": {
        "id": "Bsmis9if_qrx"
      },
      "id": "Bsmis9if_qrx"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[1]\n",
        "scores_matrix_levenshtein1_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "s2TdUVYRjwFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ba1d4a6-6a0c-4778-fdf3-0900f455fdee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.026 minutes\n",
            "0.05: 2/8 done in 0.027 minutes\n",
            "0.05: 3/8 done in 0.027 minutes\n",
            "0.05: 4/8 done in 0.026 minutes\n",
            "0.05: 5/8 done in 0.026 minutes\n",
            "0.05: 6/8 done in 0.026 minutes\n",
            "0.05: 7/8 done in 0.026 minutes\n",
            "0.05: 8/8 done in 0.025 minutes\n",
            "0.1: 1/8 done in 0.092 minutes\n",
            "0.1: 2/8 done in 0.103 minutes\n",
            "0.1: 3/8 done in 0.091 minutes\n",
            "0.1: 4/8 done in 0.09 minutes\n",
            "0.1: 5/8 done in 0.089 minutes\n",
            "0.1: 6/8 done in 0.089 minutes\n",
            "0.1: 7/8 done in 0.089 minutes\n",
            "0.1: 8/8 done in 0.089 minutes\n",
            "0.2: 1/8 done in 0.387 minutes\n",
            "0.2: 2/8 done in 0.39 minutes\n",
            "0.2: 3/8 done in 0.371 minutes\n",
            "0.2: 4/8 done in 0.369 minutes\n",
            "0.2: 5/8 done in 0.396 minutes\n",
            "0.2: 6/8 done in 0.388 minutes\n",
            "0.2: 7/8 done in 0.391 minutes\n",
            "0.2: 8/8 done in 0.38 minutes\n",
            "0.3: 1/8 done in 0.921 minutes\n",
            "0.3: 2/8 done in 0.938 minutes\n",
            "0.3: 3/8 done in 0.9 minutes\n",
            "0.3: 4/8 done in 0.904 minutes\n",
            "0.3: 5/8 done in 0.913 minutes\n",
            "0.3: 6/8 done in 0.913 minutes\n",
            "0.3: 7/8 done in 0.862 minutes\n",
            "0.3: 8/8 done in 0.904 minutes\n",
            "0.4: 1/8 done in 1.749 minutes\n",
            "0.4: 2/8 done in 1.818 minutes\n",
            "0.4: 3/8 done in 1.875 minutes\n",
            "0.4: 4/8 done in 1.742 minutes\n",
            "0.4: 5/8 done in 1.754 minutes\n",
            "0.4: 6/8 done in 1.776 minutes\n",
            "0.4: 7/8 done in 1.713 minutes\n",
            "0.4: 8/8 done in 1.737 minutes\n",
            "0.5: 1/8 done in 2.664 minutes\n",
            "0.5: 2/8 done in 2.885 minutes\n",
            "0.5: 3/8 done in 3.114 minutes\n",
            "0.5: 4/8 done in 3.296 minutes\n",
            "0.5: 5/8 done in 3.963 minutes\n",
            "0.5: 6/8 done in 3.655 minutes\n",
            "0.5: 7/8 done in 4.045 minutes\n",
            "0.5: 8/8 done in 2.791 minutes\n",
            "Total time: 51.849 minutes\n"
          ]
        }
      ],
      "id": "s2TdUVYRjwFp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Random"
      ],
      "metadata": {
        "id": "xl9nyKH6_pIq"
      },
      "id": "xl9nyKH6_pIq"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[2]\n",
        "scores_matrix_levenshtein1_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "rJsgOE7Sjvpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0578490-dd7a-4020-b942-9e91209ccbec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.004 minutes\n",
            "0.05: 2/8 done in 0.004 minutes\n",
            "0.05: 3/8 done in 0.004 minutes\n",
            "0.05: 4/8 done in 0.004 minutes\n",
            "0.05: 5/8 done in 0.004 minutes\n",
            "0.05: 6/8 done in 0.004 minutes\n",
            "0.05: 7/8 done in 0.004 minutes\n",
            "0.05: 8/8 done in 0.004 minutes\n",
            "0.1: 1/8 done in 0.004 minutes\n",
            "0.1: 2/8 done in 0.004 minutes\n",
            "0.1: 3/8 done in 0.004 minutes\n",
            "0.1: 4/8 done in 0.005 minutes\n",
            "0.1: 5/8 done in 0.004 minutes\n",
            "0.1: 6/8 done in 0.004 minutes\n",
            "0.1: 7/8 done in 0.004 minutes\n",
            "0.1: 8/8 done in 0.004 minutes\n",
            "0.2: 1/8 done in 0.005 minutes\n",
            "0.2: 2/8 done in 0.01 minutes\n",
            "0.2: 3/8 done in 0.005 minutes\n",
            "0.2: 4/8 done in 0.005 minutes\n",
            "0.2: 5/8 done in 0.005 minutes\n",
            "0.2: 6/8 done in 0.005 minutes\n",
            "0.2: 7/8 done in 0.005 minutes\n",
            "0.2: 8/8 done in 0.005 minutes\n",
            "0.3: 1/8 done in 0.006 minutes\n",
            "0.3: 2/8 done in 0.005 minutes\n",
            "0.3: 3/8 done in 0.005 minutes\n",
            "0.3: 4/8 done in 0.005 minutes\n",
            "0.3: 5/8 done in 0.005 minutes\n",
            "0.3: 6/8 done in 0.005 minutes\n",
            "0.3: 7/8 done in 0.005 minutes\n",
            "0.3: 8/8 done in 0.005 minutes\n",
            "0.4: 1/8 done in 0.005 minutes\n",
            "0.4: 2/8 done in 0.005 minutes\n",
            "0.4: 3/8 done in 0.005 minutes\n",
            "0.4: 4/8 done in 0.005 minutes\n",
            "0.4: 5/8 done in 0.005 minutes\n",
            "0.4: 6/8 done in 0.005 minutes\n",
            "0.4: 7/8 done in 0.005 minutes\n",
            "0.4: 8/8 done in 0.006 minutes\n",
            "0.5: 1/8 done in 0.005 minutes\n",
            "0.5: 2/8 done in 0.005 minutes\n",
            "0.5: 3/8 done in 0.005 minutes\n",
            "0.5: 4/8 done in 0.006 minutes\n",
            "0.5: 5/8 done in 0.005 minutes\n",
            "0.5: 6/8 done in 0.005 minutes\n",
            "0.5: 7/8 done in 0.005 minutes\n",
            "0.5: 8/8 done in 0.006 minutes\n",
            "Total time: 0.242 minutes\n"
          ]
        }
      ],
      "id": "rJsgOE7Sjvpt"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_{distance}-{threshold}_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores_matrix_levenshtein1_avg, f)"
      ],
      "metadata": {
        "id": "ExrBpifxoSnl"
      },
      "id": "ExrBpifxoSnl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Levenshtein clustering (d=5)"
      ],
      "metadata": {
        "id": "0ezhDSaWA44T"
      },
      "id": "0ezhDSaWA44T"
    },
    {
      "cell_type": "code",
      "source": [
        "distance = \"levenshtein\"\n",
        "technique = \"DBSCAN\"\n",
        "threshold = 5\n",
        "scores_matrix_levenshtein5_avg = {}"
      ],
      "metadata": {
        "id": "Tuhy3Lb8A44U"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Tuhy3Lb8A44U"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distorted"
      ],
      "metadata": {
        "id": "yA3EzKlBA44U"
      },
      "id": "yA3EzKlBA44U"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[0]\n",
        "scores_matrix_levenshtein5_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "-WUHLthRA44V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c618d542-0e2f-4412-96a4-fd503601b2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.014 minutes\n",
            "0.05: 2/8 done in 0.014 minutes\n",
            "0.05: 3/8 done in 0.015 minutes\n",
            "0.05: 4/8 done in 0.014 minutes\n",
            "0.05: 5/8 done in 0.014 minutes\n",
            "0.05: 6/8 done in 0.014 minutes\n",
            "0.05: 7/8 done in 0.015 minutes\n",
            "0.05: 8/8 done in 0.014 minutes\n",
            "0.1: 1/8 done in 0.037 minutes\n",
            "0.1: 2/8 done in 0.038 minutes\n",
            "0.1: 3/8 done in 0.039 minutes\n",
            "0.1: 4/8 done in 0.039 minutes\n",
            "0.1: 5/8 done in 0.039 minutes\n",
            "0.1: 6/8 done in 0.039 minutes\n",
            "0.1: 7/8 done in 0.038 minutes\n",
            "0.1: 8/8 done in 0.037 minutes\n",
            "0.2: 1/8 done in 0.11 minutes\n",
            "0.2: 2/8 done in 0.115 minutes\n",
            "0.2: 3/8 done in 0.108 minutes\n",
            "0.2: 4/8 done in 0.11 minutes\n",
            "0.2: 5/8 done in 0.111 minutes\n",
            "0.2: 6/8 done in 0.11 minutes\n",
            "0.2: 7/8 done in 0.106 minutes\n",
            "0.2: 8/8 done in 0.104 minutes\n",
            "0.3: 1/8 done in 0.202 minutes\n",
            "0.3: 2/8 done in 0.213 minutes\n",
            "0.3: 3/8 done in 0.213 minutes\n",
            "0.3: 4/8 done in 0.21 minutes\n",
            "0.3: 5/8 done in 0.207 minutes\n",
            "0.3: 6/8 done in 0.211 minutes\n",
            "0.3: 7/8 done in 0.202 minutes\n",
            "0.3: 8/8 done in 0.205 minutes\n",
            "0.4: 1/8 done in 0.328 minutes\n",
            "0.4: 2/8 done in 0.332 minutes\n",
            "0.4: 3/8 done in 0.341 minutes\n",
            "0.4: 4/8 done in 0.329 minutes\n",
            "0.4: 5/8 done in 0.326 minutes\n",
            "0.4: 6/8 done in 0.325 minutes\n",
            "0.4: 7/8 done in 0.331 minutes\n",
            "0.4: 8/8 done in 0.343 minutes\n",
            "0.5: 1/8 done in 0.478 minutes\n",
            "0.5: 2/8 done in 0.483 minutes\n",
            "0.5: 3/8 done in 0.488 minutes\n",
            "0.5: 4/8 done in 0.479 minutes\n",
            "0.5: 5/8 done in 0.477 minutes\n",
            "0.5: 6/8 done in 0.47 minutes\n",
            "0.5: 7/8 done in 0.47 minutes\n",
            "0.5: 8/8 done in 0.472 minutes\n",
            "Total time: 9.431 minutes\n"
          ]
        }
      ],
      "id": "-WUHLthRA44V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Nonrandom"
      ],
      "metadata": {
        "id": "Mw4LqBciA44X"
      },
      "id": "Mw4LqBciA44X"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[1]\n",
        "scores_matrix_levenshtein5_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "FRjd-RiEA44X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85176820-ea32-41d1-d292-6e7306bc855c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.026 minutes\n",
            "0.05: 2/8 done in 0.026 minutes\n",
            "0.05: 3/8 done in 0.028 minutes\n",
            "0.05: 4/8 done in 0.027 minutes\n",
            "0.05: 5/8 done in 0.028 minutes\n",
            "0.05: 6/8 done in 0.028 minutes\n",
            "0.05: 7/8 done in 0.026 minutes\n",
            "0.05: 8/8 done in 0.026 minutes\n",
            "0.1: 1/8 done in 0.09 minutes\n",
            "0.1: 2/8 done in 0.093 minutes\n",
            "0.1: 3/8 done in 0.089 minutes\n",
            "0.1: 4/8 done in 0.091 minutes\n",
            "0.1: 5/8 done in 0.094 minutes\n",
            "0.1: 6/8 done in 0.094 minutes\n",
            "0.1: 7/8 done in 0.095 minutes\n",
            "0.1: 8/8 done in 0.089 minutes\n",
            "0.2: 1/8 done in 0.372 minutes\n",
            "0.2: 2/8 done in 0.377 minutes\n",
            "0.2: 3/8 done in 0.373 minutes\n",
            "0.2: 4/8 done in 0.376 minutes\n",
            "0.2: 5/8 done in 0.382 minutes\n",
            "0.2: 6/8 done in 0.373 minutes\n",
            "0.2: 7/8 done in 0.388 minutes\n",
            "0.2: 8/8 done in 0.372 minutes\n",
            "0.3: 1/8 done in 0.873 minutes\n",
            "0.3: 2/8 done in 0.897 minutes\n",
            "0.3: 3/8 done in 0.908 minutes\n",
            "0.3: 4/8 done in 0.91 minutes\n",
            "0.3: 5/8 done in 0.906 minutes\n",
            "0.3: 6/8 done in 0.902 minutes\n",
            "0.3: 7/8 done in 0.914 minutes\n",
            "0.3: 8/8 done in 0.905 minutes\n",
            "0.4: 1/8 done in 1.701 minutes\n",
            "0.4: 2/8 done in 1.695 minutes\n",
            "0.4: 3/8 done in 1.696 minutes\n",
            "0.4: 4/8 done in 1.623 minutes\n",
            "0.4: 5/8 done in 1.57 minutes\n",
            "0.4: 6/8 done in 1.568 minutes\n",
            "0.4: 7/8 done in 1.565 minutes\n",
            "0.4: 8/8 done in 1.591 minutes\n",
            "0.5: 1/8 done in 2.554 minutes\n",
            "0.5: 2/8 done in 2.511 minutes\n",
            "0.5: 3/8 done in 2.675 minutes\n",
            "0.5: 4/8 done in 2.622 minutes\n",
            "0.5: 5/8 done in 2.672 minutes\n",
            "0.5: 6/8 done in 2.657 minutes\n",
            "0.5: 7/8 done in 2.537 minutes\n",
            "0.5: 8/8 done in 2.512 minutes\n",
            "Total time: 44.929 minutes\n"
          ]
        }
      ],
      "id": "FRjd-RiEA44X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Random"
      ],
      "metadata": {
        "id": "Y3Y07AbVA44W"
      },
      "id": "Y3Y07AbVA44W"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[2]\n",
        "scores_matrix_levenshtein5_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "_P5_0RQ9A44W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea03fd74-6d46-4e46-e75b-f0742ac41f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.004 minutes\n",
            "0.05: 2/8 done in 0.006 minutes\n",
            "0.05: 3/8 done in 0.006 minutes\n",
            "0.05: 4/8 done in 0.004 minutes\n",
            "0.05: 5/8 done in 0.004 minutes\n",
            "0.05: 6/8 done in 0.004 minutes\n",
            "0.05: 7/8 done in 0.004 minutes\n",
            "0.05: 8/8 done in 0.004 minutes\n",
            "0.1: 1/8 done in 0.004 minutes\n",
            "0.1: 2/8 done in 0.004 minutes\n",
            "0.1: 3/8 done in 0.004 minutes\n",
            "0.1: 4/8 done in 0.004 minutes\n",
            "0.1: 5/8 done in 0.004 minutes\n",
            "0.1: 6/8 done in 0.004 minutes\n",
            "0.1: 7/8 done in 0.004 minutes\n",
            "0.1: 8/8 done in 0.004 minutes\n",
            "0.2: 1/8 done in 0.005 minutes\n",
            "0.2: 2/8 done in 0.005 minutes\n",
            "0.2: 3/8 done in 0.005 minutes\n",
            "0.2: 4/8 done in 0.004 minutes\n",
            "0.2: 5/8 done in 0.005 minutes\n",
            "0.2: 6/8 done in 0.005 minutes\n",
            "0.2: 7/8 done in 0.004 minutes\n",
            "0.2: 8/8 done in 0.005 minutes\n",
            "0.3: 1/8 done in 0.005 minutes\n",
            "0.3: 2/8 done in 0.005 minutes\n",
            "0.3: 3/8 done in 0.005 minutes\n",
            "0.3: 4/8 done in 0.005 minutes\n",
            "0.3: 5/8 done in 0.005 minutes\n",
            "0.3: 6/8 done in 0.005 minutes\n",
            "0.3: 7/8 done in 0.005 minutes\n",
            "0.3: 8/8 done in 0.005 minutes\n",
            "0.4: 1/8 done in 0.006 minutes\n",
            "0.4: 2/8 done in 0.005 minutes\n",
            "0.4: 3/8 done in 0.005 minutes\n",
            "0.4: 4/8 done in 0.005 minutes\n",
            "0.4: 5/8 done in 0.005 minutes\n",
            "0.4: 6/8 done in 0.005 minutes\n",
            "0.4: 7/8 done in 0.005 minutes\n",
            "0.4: 8/8 done in 0.005 minutes\n",
            "0.5: 1/8 done in 0.005 minutes\n",
            "0.5: 2/8 done in 0.005 minutes\n",
            "0.5: 3/8 done in 0.005 minutes\n",
            "0.5: 4/8 done in 0.005 minutes\n",
            "0.5: 5/8 done in 0.005 minutes\n",
            "0.5: 6/8 done in 0.005 minutes\n",
            "0.5: 7/8 done in 0.005 minutes\n",
            "0.5: 8/8 done in 0.005 minutes\n",
            "Total time: 0.22 minutes\n"
          ]
        }
      ],
      "id": "_P5_0RQ9A44W"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_{distance}-{threshold}_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores_matrix_levenshtein5_avg, f)"
      ],
      "metadata": {
        "id": "QC3jIjDEoPNP"
      },
      "id": "QC3jIjDEoPNP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping (0.001)"
      ],
      "metadata": {
        "id": "mdLgklSGqlco"
      },
      "id": "mdLgklSGqlco"
    },
    {
      "cell_type": "code",
      "source": [
        "distance = \"DROP\"\n",
        "technique = \"DROP\"\n",
        "threshold = 0.001\n",
        "scores_matrix_drop001_avg = {}"
      ],
      "metadata": {
        "id": "VyXSN1cpqlcp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "VyXSN1cpqlcp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distorted"
      ],
      "metadata": {
        "id": "9kDKfilDqlcp"
      },
      "id": "9kDKfilDqlcp"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[0]\n",
        "scores_matrix_drop001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "x9oN81S9qlcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b65d69-98b5-4aee-bcf5-1aaabffe934c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.003 minutes\n",
            "0.05: 2/8 done in 0.003 minutes\n",
            "0.05: 3/8 done in 0.003 minutes\n",
            "0.05: 4/8 done in 0.003 minutes\n",
            "0.05: 5/8 done in 0.003 minutes\n",
            "0.05: 6/8 done in 0.003 minutes\n",
            "0.05: 7/8 done in 0.003 minutes\n",
            "0.05: 8/8 done in 0.003 minutes\n",
            "0.1: 1/8 done in 0.003 minutes\n",
            "0.1: 2/8 done in 0.003 minutes\n",
            "0.1: 3/8 done in 0.003 minutes\n",
            "0.1: 4/8 done in 0.003 minutes\n",
            "0.1: 5/8 done in 0.003 minutes\n",
            "0.1: 6/8 done in 0.003 minutes\n",
            "0.1: 7/8 done in 0.003 minutes\n",
            "0.1: 8/8 done in 0.003 minutes\n",
            "0.2: 1/8 done in 0.003 minutes\n",
            "0.2: 2/8 done in 0.003 minutes\n",
            "0.2: 3/8 done in 0.003 minutes\n",
            "0.2: 4/8 done in 0.003 minutes\n",
            "0.2: 5/8 done in 0.003 minutes\n",
            "0.2: 6/8 done in 0.003 minutes\n",
            "0.2: 7/8 done in 0.003 minutes\n",
            "0.2: 8/8 done in 0.003 minutes\n",
            "0.3: 1/8 done in 0.003 minutes\n",
            "0.3: 2/8 done in 0.003 minutes\n",
            "0.3: 3/8 done in 0.003 minutes\n",
            "0.3: 4/8 done in 0.003 minutes\n",
            "0.3: 5/8 done in 0.003 minutes\n",
            "0.3: 6/8 done in 0.003 minutes\n",
            "0.3: 7/8 done in 0.003 minutes\n",
            "0.3: 8/8 done in 0.003 minutes\n",
            "0.4: 1/8 done in 0.003 minutes\n",
            "0.4: 2/8 done in 0.003 minutes\n",
            "0.4: 3/8 done in 0.003 minutes\n",
            "0.4: 4/8 done in 0.003 minutes\n",
            "0.4: 5/8 done in 0.003 minutes\n",
            "0.4: 6/8 done in 0.003 minutes\n",
            "0.4: 7/8 done in 0.003 minutes\n",
            "0.4: 8/8 done in 0.003 minutes\n",
            "0.5: 1/8 done in 0.003 minutes\n",
            "0.5: 2/8 done in 0.003 minutes\n",
            "0.5: 3/8 done in 0.003 minutes\n",
            "0.5: 4/8 done in 0.003 minutes\n",
            "0.5: 5/8 done in 0.003 minutes\n",
            "0.5: 6/8 done in 0.003 minutes\n",
            "0.5: 7/8 done in 0.003 minutes\n",
            "0.5: 8/8 done in 0.003 minutes\n",
            "Total time: 0.141 minutes\n"
          ]
        }
      ],
      "id": "x9oN81S9qlcp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Nonrandom"
      ],
      "metadata": {
        "id": "kRbBrievqlcp"
      },
      "id": "kRbBrievqlcp"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[1]\n",
        "scores_matrix_drop001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "YKesQ-8Sqlcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fac27c8-2dd2-4108-ee93-c1e4ba20103e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.003 minutes\n",
            "0.05: 2/8 done in 0.003 minutes\n",
            "0.05: 3/8 done in 0.003 minutes\n",
            "0.05: 4/8 done in 0.003 minutes\n",
            "0.05: 5/8 done in 0.003 minutes\n",
            "0.05: 6/8 done in 0.003 minutes\n",
            "0.05: 7/8 done in 0.003 minutes\n",
            "0.05: 8/8 done in 0.003 minutes\n",
            "0.1: 1/8 done in 0.003 minutes\n",
            "0.1: 2/8 done in 0.003 minutes\n",
            "0.1: 3/8 done in 0.003 minutes\n",
            "0.1: 4/8 done in 0.003 minutes\n",
            "0.1: 5/8 done in 0.003 minutes\n",
            "0.1: 6/8 done in 0.003 minutes\n",
            "0.1: 7/8 done in 0.003 minutes\n",
            "0.1: 8/8 done in 0.003 minutes\n",
            "0.2: 1/8 done in 0.003 minutes\n",
            "0.2: 2/8 done in 0.003 minutes\n",
            "0.2: 3/8 done in 0.003 minutes\n",
            "0.2: 4/8 done in 0.003 minutes\n",
            "0.2: 5/8 done in 0.003 minutes\n",
            "0.2: 6/8 done in 0.003 minutes\n",
            "0.2: 7/8 done in 0.003 minutes\n",
            "0.2: 8/8 done in 0.003 minutes\n",
            "0.3: 1/8 done in 0.003 minutes\n",
            "0.3: 2/8 done in 0.003 minutes\n",
            "0.3: 3/8 done in 0.003 minutes\n",
            "0.3: 4/8 done in 0.003 minutes\n",
            "0.3: 5/8 done in 0.003 minutes\n",
            "0.3: 6/8 done in 0.003 minutes\n",
            "0.3: 7/8 done in 0.003 minutes\n",
            "0.3: 8/8 done in 0.003 minutes\n",
            "0.4: 1/8 done in 0.003 minutes\n",
            "0.4: 2/8 done in 0.003 minutes\n",
            "0.4: 3/8 done in 0.003 minutes\n",
            "0.4: 4/8 done in 0.003 minutes\n",
            "0.4: 5/8 done in 0.003 minutes\n",
            "0.4: 6/8 done in 0.003 minutes\n",
            "0.4: 7/8 done in 0.003 minutes\n",
            "0.4: 8/8 done in 0.003 minutes\n",
            "0.5: 1/8 done in 0.004 minutes\n",
            "0.5: 2/8 done in 0.003 minutes\n",
            "0.5: 3/8 done in 0.003 minutes\n",
            "0.5: 4/8 done in 0.003 minutes\n",
            "0.5: 5/8 done in 0.004 minutes\n",
            "0.5: 6/8 done in 0.003 minutes\n",
            "0.5: 7/8 done in 0.004 minutes\n",
            "0.5: 8/8 done in 0.004 minutes\n",
            "Total time: 0.15 minutes\n"
          ]
        }
      ],
      "id": "YKesQ-8Sqlcq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Random"
      ],
      "metadata": {
        "id": "aaVrzalAqlcp"
      },
      "id": "aaVrzalAqlcp"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[2]\n",
        "scores_matrix_drop001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "-f7L8cJzqlcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904e1396-6c09-4ab7-d8cd-19565096f089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.003 minutes\n",
            "0.05: 2/8 done in 0.003 minutes\n",
            "0.05: 3/8 done in 0.003 minutes\n",
            "0.05: 4/8 done in 0.003 minutes\n",
            "0.05: 5/8 done in 0.003 minutes\n",
            "0.05: 6/8 done in 0.003 minutes\n",
            "0.05: 7/8 done in 0.003 minutes\n",
            "0.05: 8/8 done in 0.003 minutes\n",
            "0.1: 1/8 done in 0.003 minutes\n",
            "0.1: 2/8 done in 0.003 minutes\n",
            "0.1: 3/8 done in 0.003 minutes\n",
            "0.1: 4/8 done in 0.003 minutes\n",
            "0.1: 5/8 done in 0.003 minutes\n",
            "0.1: 6/8 done in 0.003 minutes\n",
            "0.1: 7/8 done in 0.003 minutes\n",
            "0.1: 8/8 done in 0.003 minutes\n",
            "0.2: 1/8 done in 0.003 minutes\n",
            "0.2: 2/8 done in 0.003 minutes\n",
            "0.2: 3/8 done in 0.003 minutes\n",
            "0.2: 4/8 done in 0.003 minutes\n",
            "0.2: 5/8 done in 0.003 minutes\n",
            "0.2: 6/8 done in 0.003 minutes\n",
            "0.2: 7/8 done in 0.003 minutes\n",
            "0.2: 8/8 done in 0.003 minutes\n",
            "0.3: 1/8 done in 0.003 minutes\n",
            "0.3: 2/8 done in 0.003 minutes\n",
            "0.3: 3/8 done in 0.003 minutes\n",
            "0.3: 4/8 done in 0.003 minutes\n",
            "0.3: 5/8 done in 0.003 minutes\n",
            "0.3: 6/8 done in 0.003 minutes\n",
            "0.3: 7/8 done in 0.003 minutes\n",
            "0.3: 8/8 done in 0.003 minutes\n",
            "0.4: 1/8 done in 0.003 minutes\n",
            "0.4: 2/8 done in 0.003 minutes\n",
            "0.4: 3/8 done in 0.003 minutes\n",
            "0.4: 4/8 done in 0.003 minutes\n",
            "0.4: 5/8 done in 0.003 minutes\n",
            "0.4: 6/8 done in 0.003 minutes\n",
            "0.4: 7/8 done in 0.003 minutes\n",
            "0.4: 8/8 done in 0.003 minutes\n",
            "0.5: 1/8 done in 0.003 minutes\n",
            "0.5: 2/8 done in 0.003 minutes\n",
            "0.5: 3/8 done in 0.003 minutes\n",
            "0.5: 4/8 done in 0.003 minutes\n",
            "0.5: 5/8 done in 0.003 minutes\n",
            "0.5: 6/8 done in 0.003 minutes\n",
            "0.5: 7/8 done in 0.003 minutes\n",
            "0.5: 8/8 done in 0.003 minutes\n",
            "Total time: 0.135 minutes\n"
          ]
        }
      ],
      "id": "-f7L8cJzqlcp"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_{technique}-{threshold}_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores_matrix_drop001_avg, f)"
      ],
      "metadata": {
        "id": "DEYPnQIOoVx-"
      },
      "id": "DEYPnQIOoVx-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping (0.001) (delete)"
      ],
      "metadata": {
        "id": "ZC3-3j_0jPUH"
      },
      "id": "ZC3-3j_0jPUH"
    },
    {
      "cell_type": "code",
      "source": [
        "distance = \"DROP_DELETE\"\n",
        "technique = \"DROP_DELETE\"\n",
        "threshold = 0.001\n",
        "scores_matrix_drop_delete001_avg = {}"
      ],
      "metadata": {
        "id": "p0hon12fjPUH"
      },
      "execution_count": null,
      "outputs": [],
      "id": "p0hon12fjPUH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distorted"
      ],
      "metadata": {
        "id": "X66BqdAsjPUI"
      },
      "id": "X66BqdAsjPUI"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[0]\n",
        "scores_matrix_drop_delete001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "V75EDz-_jPUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049cd071-0e4c-4d12-bc65-cfd432a09b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.001 minutes\n",
            "0.05: 2/8 done in 0.001 minutes\n",
            "0.05: 3/8 done in 0.001 minutes\n",
            "0.05: 4/8 done in 0.001 minutes\n",
            "0.05: 5/8 done in 0.001 minutes\n",
            "0.05: 6/8 done in 0.001 minutes\n",
            "0.05: 7/8 done in 0.001 minutes\n",
            "0.05: 8/8 done in 0.001 minutes\n",
            "0.1: 1/8 done in 0.001 minutes\n",
            "0.1: 2/8 done in 0.001 minutes\n",
            "0.1: 3/8 done in 0.001 minutes\n",
            "0.1: 4/8 done in 0.001 minutes\n",
            "0.1: 5/8 done in 0.001 minutes\n",
            "0.1: 6/8 done in 0.001 minutes\n",
            "0.1: 7/8 done in 0.001 minutes\n",
            "0.1: 8/8 done in 0.001 minutes\n",
            "0.2: 1/8 done in 0.001 minutes\n",
            "0.2: 2/8 done in 0.001 minutes\n",
            "0.2: 3/8 done in 0.001 minutes\n",
            "0.2: 4/8 done in 0.001 minutes\n",
            "0.2: 5/8 done in 0.001 minutes\n",
            "0.2: 6/8 done in 0.001 minutes\n",
            "0.2: 7/8 done in 0.001 minutes\n",
            "0.2: 8/8 done in 0.001 minutes\n",
            "0.3: 1/8 done in 0.001 minutes\n",
            "0.3: 2/8 done in 0.001 minutes\n",
            "0.3: 3/8 done in 0.001 minutes\n",
            "0.3: 4/8 done in 0.001 minutes\n",
            "0.3: 5/8 done in 0.001 minutes\n",
            "0.3: 6/8 done in 0.001 minutes\n",
            "0.3: 7/8 done in 0.001 minutes\n",
            "0.3: 8/8 done in 0.001 minutes\n",
            "0.4: 1/8 done in 0.001 minutes\n",
            "0.4: 2/8 done in 0.001 minutes\n",
            "0.4: 3/8 done in 0.001 minutes\n",
            "0.4: 4/8 done in 0.001 minutes\n",
            "0.4: 5/8 done in 0.001 minutes\n",
            "0.4: 6/8 done in 0.001 minutes\n",
            "0.4: 7/8 done in 0.001 minutes\n",
            "0.4: 8/8 done in 0.001 minutes\n",
            "0.5: 1/8 done in 0.001 minutes\n",
            "0.5: 2/8 done in 0.001 minutes\n",
            "0.5: 3/8 done in 0.001 minutes\n",
            "0.5: 4/8 done in 0.001 minutes\n",
            "0.5: 5/8 done in 0.001 minutes\n",
            "0.5: 6/8 done in 0.001 minutes\n",
            "0.5: 7/8 done in 0.001 minutes\n",
            "0.5: 8/8 done in 0.001 minutes\n",
            "Total time: 0.035 minutes\n"
          ]
        }
      ],
      "id": "V75EDz-_jPUI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Nonrandom"
      ],
      "metadata": {
        "id": "FWfxtScejPUI"
      },
      "id": "FWfxtScejPUI"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[1]\n",
        "scores_matrix_drop_delete001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "xxP1Q7xsjPUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac129ab-ec4b-453d-89ca-76395bdfa897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.001 minutes\n",
            "0.05: 2/8 done in 0.001 minutes\n",
            "0.05: 3/8 done in 0.001 minutes\n",
            "0.05: 4/8 done in 0.001 minutes\n",
            "0.05: 5/8 done in 0.001 minutes\n",
            "0.05: 6/8 done in 0.001 minutes\n",
            "0.05: 7/8 done in 0.001 minutes\n",
            "0.05: 8/8 done in 0.001 minutes\n",
            "0.1: 1/8 done in 0.001 minutes\n",
            "0.1: 2/8 done in 0.001 minutes\n",
            "0.1: 3/8 done in 0.001 minutes\n",
            "0.1: 4/8 done in 0.001 minutes\n",
            "0.1: 5/8 done in 0.001 minutes\n",
            "0.1: 6/8 done in 0.001 minutes\n",
            "0.1: 7/8 done in 0.001 minutes\n",
            "0.1: 8/8 done in 0.001 minutes\n",
            "0.2: 1/8 done in 0.001 minutes\n",
            "0.2: 2/8 done in 0.001 minutes\n",
            "0.2: 3/8 done in 0.001 minutes\n",
            "0.2: 4/8 done in 0.001 minutes\n",
            "0.2: 5/8 done in 0.001 minutes\n",
            "0.2: 6/8 done in 0.001 minutes\n",
            "0.2: 7/8 done in 0.001 minutes\n",
            "0.2: 8/8 done in 0.001 minutes\n",
            "0.3: 1/8 done in 0.001 minutes\n",
            "0.3: 2/8 done in 0.001 minutes\n",
            "0.3: 3/8 done in 0.001 minutes\n",
            "0.3: 4/8 done in 0.001 minutes\n",
            "0.3: 5/8 done in 0.001 minutes\n",
            "0.3: 6/8 done in 0.001 minutes\n",
            "0.3: 7/8 done in 0.001 minutes\n",
            "0.3: 8/8 done in 0.001 minutes\n",
            "0.4: 1/8 done in 0.001 minutes\n",
            "0.4: 2/8 done in 0.001 minutes\n",
            "0.4: 3/8 done in 0.001 minutes\n",
            "0.4: 4/8 done in 0.001 minutes\n",
            "0.4: 5/8 done in 0.001 minutes\n",
            "0.4: 6/8 done in 0.001 minutes\n",
            "0.4: 7/8 done in 0.001 minutes\n",
            "0.4: 8/8 done in 0.001 minutes\n",
            "0.5: 1/8 done in 0.001 minutes\n",
            "0.5: 2/8 done in 0.001 minutes\n",
            "0.5: 3/8 done in 0.001 minutes\n",
            "0.5: 4/8 done in 0.001 minutes\n",
            "0.5: 5/8 done in 0.001 minutes\n",
            "0.5: 6/8 done in 0.001 minutes\n",
            "0.5: 7/8 done in 0.001 minutes\n",
            "0.5: 8/8 done in 0.001 minutes\n",
            "Total time: 0.04 minutes\n"
          ]
        }
      ],
      "id": "xxP1Q7xsjPUJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Random"
      ],
      "metadata": {
        "id": "lqeVJjE_jPUJ"
      },
      "id": "lqeVJjE_jPUJ"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[2]\n",
        "scores_matrix_drop_delete001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold)"
      ],
      "metadata": {
        "id": "91uQd2NxjPUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeea0586-d26c-41e6-91dc-af81c1c6e367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.001 minutes\n",
            "0.05: 2/8 done in 0.001 minutes\n",
            "0.05: 3/8 done in 0.001 minutes\n",
            "0.05: 4/8 done in 0.001 minutes\n",
            "0.05: 5/8 done in 0.001 minutes\n",
            "0.05: 6/8 done in 0.001 minutes\n",
            "0.05: 7/8 done in 0.001 minutes\n",
            "0.05: 8/8 done in 0.001 minutes\n",
            "0.1: 1/8 done in 0.001 minutes\n",
            "0.1: 2/8 done in 0.001 minutes\n",
            "0.1: 3/8 done in 0.001 minutes\n",
            "0.1: 4/8 done in 0.001 minutes\n",
            "0.1: 5/8 done in 0.001 minutes\n",
            "0.1: 6/8 done in 0.001 minutes\n",
            "0.1: 7/8 done in 0.001 minutes\n",
            "0.1: 8/8 done in 0.001 minutes\n",
            "0.2: 1/8 done in 0.001 minutes\n",
            "0.2: 2/8 done in 0.001 minutes\n",
            "0.2: 3/8 done in 0.001 minutes\n",
            "0.2: 4/8 done in 0.001 minutes\n",
            "0.2: 5/8 done in 0.001 minutes\n",
            "0.2: 6/8 done in 0.001 minutes\n",
            "0.2: 7/8 done in 0.001 minutes\n",
            "0.2: 8/8 done in 0.001 minutes\n",
            "0.3: 1/8 done in 0.001 minutes\n",
            "0.3: 2/8 done in 0.001 minutes\n",
            "0.3: 3/8 done in 0.001 minutes\n",
            "0.3: 4/8 done in 0.001 minutes\n",
            "0.3: 5/8 done in 0.001 minutes\n",
            "0.3: 6/8 done in 0.001 minutes\n",
            "0.3: 7/8 done in 0.001 minutes\n",
            "0.3: 8/8 done in 0.001 minutes\n",
            "0.4: 1/8 done in 0.001 minutes\n",
            "0.4: 2/8 done in 0.001 minutes\n",
            "0.4: 3/8 done in 0.001 minutes\n",
            "0.4: 4/8 done in 0.001 minutes\n",
            "0.4: 5/8 done in 0.001 minutes\n",
            "0.4: 6/8 done in 0.001 minutes\n",
            "0.4: 7/8 done in 0.001 minutes\n",
            "0.4: 8/8 done in 0.001 minutes\n",
            "0.5: 1/8 done in 0.001 minutes\n",
            "0.5: 2/8 done in 0.001 minutes\n",
            "0.5: 3/8 done in 0.001 minutes\n",
            "0.5: 4/8 done in 0.001 minutes\n",
            "0.5: 5/8 done in 0.001 minutes\n",
            "0.5: 6/8 done in 0.001 minutes\n",
            "0.5: 7/8 done in 0.001 minutes\n",
            "0.5: 8/8 done in 0.001 minutes\n",
            "Total time: 0.036 minutes\n"
          ]
        }
      ],
      "id": "91uQd2NxjPUJ"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_{technique}-{threshold}_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(scores_matrix_drop_delete001_avg, f)"
      ],
      "metadata": {
        "id": "7VW3CQtnjPUJ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "7VW3CQtnjPUJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BPIC '15"
      ],
      "metadata": {
        "id": "QWrLd8kB_kBR"
      },
      "id": "QWrLd8kB_kBR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "wMKREiYt4kyV"
      },
      "id": "wMKREiYt4kyV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defines"
      ],
      "metadata": {
        "id": "yC70IlrpxARR"
      },
      "id": "yC70IlrpxARR"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"BPIC15_1_f2\""
      ],
      "metadata": {
        "id": "jBUw9D6Q4kyV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "jBUw9D6Q4kyV"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "directory_path = f'./{dataset}/{dataset}/{dataset}_prepared/'\n",
        "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-12T09:24:23.706194Z",
          "start_time": "2024-07-12T09:24:23.701590Z"
        },
        "id": "nS-Vft_mxARS"
      },
      "execution_count": null,
      "id": "nS-Vft_mxARS"
    },
    {
      "cell_type": "code",
      "source": [
        "files.remove(f'{dataset}-TRAIN-CLEAN.csv')"
      ],
      "metadata": {
        "id": "UK_zM5TtxARS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "UK_zM5TtxARS"
    },
    {
      "cell_type": "code",
      "source": [
        "df_ref = pd.read_csv(f'./{dataset}/{dataset}/{dataset}_prepared/{dataset}-TRAIN-CLEAN.csv')\n",
        "ref = df_ref.CCDOEV"
      ],
      "metadata": {
        "id": "PvtF-oB1xARS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PvtF-oB1xARS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline"
      ],
      "metadata": {
        "id": "sy4ufQZk5wVM"
      },
      "id": "sy4ufQZk5wVM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute DQ metrics for all corrupted datasets, to use as a baseline\n",
        "_dq_dict = {}\n",
        "for pollution_type in pollution_types:\n",
        "  _dq_dict[pollution_type] = {}\n",
        "  for percentage in percentages:\n",
        "    _dq_dict[pollution_type][percentage] = {}\n",
        "    for i in range(8):\n",
        "      df = pd.read_csv(f\"{directory_path}{dataset}-TRAIN-{pollution_type}-{percentage}-{i}.csv\")\n",
        "      labels = df.CCDOEV\n",
        "      _dq_dict[pollution_type][percentage][i] = DQ_assess(df, dq) | dict(zip(dq_scorings, conf_matrix(ref, labels)))"
      ],
      "metadata": {
        "id": "ogBLXddtxARS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ogBLXddtxARS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Average the metrics\n",
        "_dq_dict_avg = {}\n",
        "for pollution_type in pollution_types:\n",
        "  _dq_dict_avg[pollution_type] = {}\n",
        "  for percentage in percentages:\n",
        "    _dq_dict_avg[pollution_type][percentage] = {}\n",
        "    for metric in metrics:\n",
        "      _dq_dict_avg[pollution_type][percentage][metric] = np.mean([_dq_dict[pollution_type][percentage][i][metric] for i in range(8)])\n",
        "\n",
        "scorings = DQ_assess(df_ref, dq) | dict(zip(dq_scorings, conf_matrix(ref, ref)))\n",
        "\n",
        "_dq_dict_avg[\"CLEAN\"] = {percentage:scorings for percentage in percentages}"
      ],
      "metadata": {
        "id": "AxIe_p_QxARS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "AxIe_p_QxARS"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}-REF_scores_matrix_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(_dq_dict_avg, f)"
      ],
      "metadata": {
        "id": "lyTzD4IBxARS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "lyTzD4IBxARS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Levenshtein clustering (d=1)"
      ],
      "metadata": {
        "id": "JF_JERrY4kyX"
      },
      "id": "JF_JERrY4kyX"
    },
    {
      "cell_type": "code",
      "source": [
        "distance = \"levenshtein\"\n",
        "technique = \"DBSCAN\"\n",
        "threshold = 1\n",
        "_scores_matrix_levenshtein1_avg = {}"
      ],
      "metadata": {
        "id": "x02re3Iq4kyX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "x02re3Iq4kyX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distorted"
      ],
      "metadata": {
        "id": "x3vhrZlB4kyX"
      },
      "id": "x3vhrZlB4kyX"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[0]\n",
        "_scores_matrix_levenshtein1_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "2_lwwrE74kyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d23baf4-bb70-40d4-b4c5-4342914c52c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.023 minutes\n",
            "0.05: 2/8 done in 0.023 minutes\n",
            "0.05: 3/8 done in 0.022 minutes\n",
            "0.05: 4/8 done in 0.022 minutes\n",
            "0.05: 5/8 done in 0.022 minutes\n",
            "0.05: 6/8 done in 0.023 minutes\n",
            "0.05: 7/8 done in 0.022 minutes\n",
            "0.05: 8/8 done in 0.022 minutes\n",
            "0.1: 1/8 done in 0.061 minutes\n",
            "0.1: 2/8 done in 0.059 minutes\n",
            "0.1: 3/8 done in 0.058 minutes\n",
            "0.1: 4/8 done in 0.057 minutes\n",
            "0.1: 5/8 done in 0.06 minutes\n",
            "0.1: 6/8 done in 0.064 minutes\n",
            "0.1: 7/8 done in 0.056 minutes\n",
            "0.1: 8/8 done in 0.059 minutes\n",
            "0.2: 1/8 done in 0.182 minutes\n",
            "0.2: 2/8 done in 0.179 minutes\n",
            "0.2: 3/8 done in 0.177 minutes\n",
            "0.2: 4/8 done in 0.181 minutes\n",
            "0.2: 5/8 done in 0.179 minutes\n",
            "0.2: 6/8 done in 0.179 minutes\n",
            "0.2: 7/8 done in 0.178 minutes\n",
            "0.2: 8/8 done in 0.179 minutes\n",
            "0.3: 1/8 done in 0.362 minutes\n",
            "0.3: 2/8 done in 0.357 minutes\n",
            "0.3: 3/8 done in 0.354 minutes\n",
            "0.3: 4/8 done in 0.355 minutes\n",
            "0.3: 5/8 done in 0.354 minutes\n",
            "0.3: 6/8 done in 0.357 minutes\n",
            "0.3: 7/8 done in 0.348 minutes\n",
            "0.3: 8/8 done in 0.345 minutes\n",
            "0.4: 1/8 done in 0.588 minutes\n",
            "0.4: 2/8 done in 0.58 minutes\n",
            "0.4: 3/8 done in 0.575 minutes\n",
            "0.4: 4/8 done in 0.575 minutes\n",
            "0.4: 5/8 done in 0.572 minutes\n",
            "0.4: 6/8 done in 0.58 minutes\n",
            "0.4: 7/8 done in 0.576 minutes\n",
            "0.4: 8/8 done in 0.566 minutes\n",
            "0.5: 1/8 done in 0.818 minutes\n",
            "0.5: 2/8 done in 0.805 minutes\n",
            "0.5: 3/8 done in 0.815 minutes\n",
            "0.5: 4/8 done in 0.797 minutes\n",
            "0.5: 5/8 done in 0.792 minutes\n",
            "0.5: 6/8 done in 0.799 minutes\n",
            "0.5: 7/8 done in 0.885 minutes\n",
            "0.5: 8/8 done in 0.811 minutes\n",
            "Total time: 16.054 minutes\n"
          ]
        }
      ],
      "id": "2_lwwrE74kyX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Nonrandom"
      ],
      "metadata": {
        "id": "sB8Frxja4kyX"
      },
      "id": "sB8Frxja4kyX"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[1]\n",
        "_scores_matrix_levenshtein1_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "uHOyDgYL4kyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7570817c-189d-4818-a184-3e97947d4ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.009 minutes\n",
            "0.05: 2/8 done in 0.009 minutes\n",
            "0.05: 3/8 done in 0.009 minutes\n",
            "0.05: 4/8 done in 0.009 minutes\n",
            "0.05: 5/8 done in 0.009 minutes\n",
            "0.05: 6/8 done in 0.009 minutes\n",
            "0.05: 7/8 done in 0.009 minutes\n",
            "0.05: 8/8 done in 0.01 minutes\n",
            "0.1: 1/8 done in 0.013 minutes\n",
            "0.1: 2/8 done in 0.013 minutes\n",
            "0.1: 3/8 done in 0.012 minutes\n",
            "0.1: 4/8 done in 0.012 minutes\n",
            "0.1: 5/8 done in 0.014 minutes\n",
            "0.1: 6/8 done in 0.013 minutes\n",
            "0.1: 7/8 done in 0.012 minutes\n",
            "0.1: 8/8 done in 0.012 minutes\n",
            "0.2: 1/8 done in 0.018 minutes\n",
            "0.2: 2/8 done in 0.018 minutes\n",
            "0.2: 3/8 done in 0.017 minutes\n",
            "0.2: 4/8 done in 0.017 minutes\n",
            "0.2: 5/8 done in 0.019 minutes\n",
            "0.2: 6/8 done in 0.018 minutes\n",
            "0.2: 7/8 done in 0.017 minutes\n",
            "0.2: 8/8 done in 0.017 minutes\n",
            "0.3: 1/8 done in 0.022 minutes\n",
            "0.3: 2/8 done in 0.023 minutes\n",
            "0.3: 3/8 done in 0.022 minutes\n",
            "0.3: 4/8 done in 0.023 minutes\n",
            "0.3: 5/8 done in 0.022 minutes\n",
            "0.3: 6/8 done in 0.022 minutes\n",
            "0.3: 7/8 done in 0.022 minutes\n",
            "0.3: 8/8 done in 0.021 minutes\n",
            "0.4: 1/8 done in 0.026 minutes\n",
            "0.4: 2/8 done in 0.025 minutes\n",
            "0.4: 3/8 done in 0.025 minutes\n",
            "0.4: 4/8 done in 0.025 minutes\n",
            "0.4: 5/8 done in 0.025 minutes\n",
            "0.4: 6/8 done in 0.029 minutes\n",
            "0.4: 7/8 done in 0.028 minutes\n",
            "0.4: 8/8 done in 0.025 minutes\n",
            "0.5: 1/8 done in 0.029 minutes\n",
            "0.5: 2/8 done in 0.028 minutes\n",
            "0.5: 3/8 done in 0.028 minutes\n",
            "0.5: 4/8 done in 0.028 minutes\n",
            "0.5: 5/8 done in 0.028 minutes\n",
            "0.5: 6/8 done in 0.028 minutes\n",
            "0.5: 7/8 done in 0.029 minutes\n",
            "0.5: 8/8 done in 0.027 minutes\n",
            "Total time: 0.929 minutes\n"
          ]
        }
      ],
      "id": "uHOyDgYL4kyY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Random"
      ],
      "metadata": {
        "id": "l5qM2VIp4kyY"
      },
      "id": "l5qM2VIp4kyY"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[2]\n",
        "_scores_matrix_levenshtein1_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "kl3FAGe04kyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fc5254-fff7-4f01-f54b-ddd75e136a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.035 minutes\n",
            "0.05: 2/8 done in 0.035 minutes\n",
            "0.05: 3/8 done in 0.035 minutes\n",
            "0.05: 4/8 done in 0.035 minutes\n",
            "0.05: 5/8 done in 0.034 minutes\n",
            "0.05: 6/8 done in 0.035 minutes\n",
            "0.05: 7/8 done in 0.035 minutes\n",
            "0.05: 8/8 done in 0.038 minutes\n",
            "0.1: 1/8 done in 0.129 minutes\n",
            "0.1: 2/8 done in 0.129 minutes\n",
            "0.1: 3/8 done in 0.124 minutes\n",
            "0.1: 4/8 done in 0.127 minutes\n",
            "0.1: 5/8 done in 0.117 minutes\n",
            "0.1: 6/8 done in 0.122 minutes\n",
            "0.1: 7/8 done in 0.117 minutes\n",
            "0.1: 8/8 done in 0.117 minutes\n",
            "0.2: 1/8 done in 0.502 minutes\n",
            "0.2: 2/8 done in 0.488 minutes\n",
            "0.2: 3/8 done in 0.475 minutes\n",
            "0.2: 4/8 done in 0.476 minutes\n",
            "0.2: 5/8 done in 0.476 minutes\n",
            "0.2: 6/8 done in 0.48 minutes\n",
            "0.2: 7/8 done in 0.491 minutes\n",
            "0.2: 8/8 done in 0.49 minutes\n",
            "0.3: 1/8 done in 1.128 minutes\n",
            "0.3: 2/8 done in 1.103 minutes\n",
            "0.3: 3/8 done in 1.179 minutes\n",
            "0.3: 4/8 done in 1.154 minutes\n",
            "0.3: 5/8 done in 1.142 minutes\n",
            "0.3: 6/8 done in 1.135 minutes\n",
            "0.3: 7/8 done in 1.182 minutes\n",
            "0.3: 8/8 done in 1.201 minutes\n",
            "0.4: 1/8 done in 2.138 minutes\n",
            "0.4: 2/8 done in 2.214 minutes\n",
            "0.4: 3/8 done in 2.315 minutes\n",
            "0.4: 4/8 done in 2.105 minutes\n",
            "0.4: 5/8 done in 2.083 minutes\n",
            "0.4: 6/8 done in 2.054 minutes\n",
            "0.4: 7/8 done in 2.135 minutes\n",
            "0.4: 8/8 done in 2.211 minutes\n",
            "0.5: 1/8 done in 3.681 minutes\n",
            "0.5: 2/8 done in 3.713 minutes\n",
            "0.5: 3/8 done in 3.951 minutes\n",
            "0.5: 4/8 done in 3.841 minutes\n",
            "0.5: 5/8 done in 3.782 minutes\n",
            "0.5: 6/8 done in 3.65 minutes\n",
            "0.5: 7/8 done in 3.747 minutes\n",
            "0.5: 8/8 done in 3.933 minutes\n",
            "Total time: 61.92 minutes\n"
          ]
        }
      ],
      "id": "kl3FAGe04kyY"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_{distance}-{d}_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(_scores_matrix_levenshtein1_avg, f)"
      ],
      "metadata": {
        "id": "KbHWz4fpoXWP"
      },
      "id": "KbHWz4fpoXWP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Levenshtein clustering (d=5)"
      ],
      "metadata": {
        "id": "lkdKawNAbZ2O"
      },
      "id": "lkdKawNAbZ2O"
    },
    {
      "cell_type": "code",
      "source": [
        "distance = \"levenshtein\"\n",
        "technique = \"DBSCAN\"\n",
        "threshold = 5\n",
        "_scores_matrix_levenshtein5_avg = {}"
      ],
      "metadata": {
        "id": "AC3S5a6NbZ2P"
      },
      "execution_count": null,
      "outputs": [],
      "id": "AC3S5a6NbZ2P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distorted"
      ],
      "metadata": {
        "id": "P4tPH9e3bZ2P"
      },
      "id": "P4tPH9e3bZ2P"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[0]\n",
        "_scores_matrix_levenshtein5_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "SLlTECRJbZ2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b430505-8660-4001-dd58-e113638d2aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.025 minutes\n",
            "0.05: 2/8 done in 0.022 minutes\n",
            "0.05: 3/8 done in 0.022 minutes\n",
            "0.05: 4/8 done in 0.023 minutes\n",
            "0.05: 5/8 done in 0.022 minutes\n",
            "0.05: 6/8 done in 0.022 minutes\n",
            "0.05: 7/8 done in 0.022 minutes\n",
            "0.05: 8/8 done in 0.022 minutes\n",
            "0.1: 1/8 done in 0.062 minutes\n",
            "0.1: 2/8 done in 0.061 minutes\n",
            "0.1: 3/8 done in 0.058 minutes\n",
            "0.1: 4/8 done in 0.06 minutes\n",
            "0.1: 5/8 done in 0.058 minutes\n",
            "0.1: 6/8 done in 0.062 minutes\n",
            "0.1: 7/8 done in 0.059 minutes\n",
            "0.1: 8/8 done in 0.06 minutes\n",
            "0.2: 1/8 done in 0.19 minutes\n",
            "0.2: 2/8 done in 0.19 minutes\n",
            "0.2: 3/8 done in 0.182 minutes\n",
            "0.2: 4/8 done in 0.183 minutes\n",
            "0.2: 5/8 done in 0.187 minutes\n",
            "0.2: 6/8 done in 0.182 minutes\n",
            "0.2: 7/8 done in 0.182 minutes\n",
            "0.2: 8/8 done in 0.182 minutes\n",
            "0.3: 1/8 done in 0.367 minutes\n",
            "0.3: 2/8 done in 0.368 minutes\n",
            "0.3: 3/8 done in 0.361 minutes\n",
            "0.3: 4/8 done in 0.375 minutes\n",
            "0.3: 5/8 done in 0.405 minutes\n",
            "0.3: 6/8 done in 0.373 minutes\n",
            "0.3: 7/8 done in 0.36 minutes\n",
            "0.3: 8/8 done in 0.357 minutes\n",
            "0.4: 1/8 done in 0.611 minutes\n",
            "0.4: 2/8 done in 0.595 minutes\n",
            "0.4: 3/8 done in 0.585 minutes\n",
            "0.4: 4/8 done in 0.608 minutes\n",
            "0.4: 5/8 done in 0.604 minutes\n",
            "0.4: 6/8 done in 0.605 minutes\n",
            "0.4: 7/8 done in 0.584 minutes\n",
            "0.4: 8/8 done in 0.591 minutes\n",
            "0.5: 1/8 done in 0.844 minutes\n",
            "0.5: 2/8 done in 0.842 minutes\n",
            "0.5: 3/8 done in 0.86 minutes\n",
            "0.5: 4/8 done in 0.824 minutes\n",
            "0.5: 5/8 done in 0.88 minutes\n",
            "0.5: 6/8 done in 0.922 minutes\n",
            "0.5: 7/8 done in 0.938 minutes\n",
            "0.5: 8/8 done in 0.883 minutes\n",
            "Total time: 16.877 minutes\n"
          ]
        }
      ],
      "id": "SLlTECRJbZ2P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Nonrandom"
      ],
      "metadata": {
        "id": "E0IKiBOPbZ2P"
      },
      "id": "E0IKiBOPbZ2P"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[1]\n",
        "_scores_matrix_levenshtein5_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "coqYCLmfbZ2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67aaf7c9-9430-47bf-e212-d2d6269a59a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.009 minutes\n",
            "0.05: 2/8 done in 0.009 minutes\n",
            "0.05: 3/8 done in 0.009 minutes\n",
            "0.05: 4/8 done in 0.01 minutes\n",
            "0.05: 5/8 done in 0.009 minutes\n",
            "0.05: 6/8 done in 0.009 minutes\n",
            "0.05: 7/8 done in 0.009 minutes\n",
            "0.05: 8/8 done in 0.009 minutes\n",
            "0.1: 1/8 done in 0.013 minutes\n",
            "0.1: 2/8 done in 0.013 minutes\n",
            "0.1: 3/8 done in 0.012 minutes\n",
            "0.1: 4/8 done in 0.012 minutes\n",
            "0.1: 5/8 done in 0.013 minutes\n",
            "0.1: 6/8 done in 0.012 minutes\n",
            "0.1: 7/8 done in 0.012 minutes\n",
            "0.1: 8/8 done in 0.012 minutes\n",
            "0.2: 1/8 done in 0.017 minutes\n",
            "0.2: 2/8 done in 0.017 minutes\n",
            "0.2: 3/8 done in 0.016 minutes\n",
            "0.2: 4/8 done in 0.016 minutes\n",
            "0.2: 5/8 done in 0.017 minutes\n",
            "0.2: 6/8 done in 0.017 minutes\n",
            "0.2: 7/8 done in 0.017 minutes\n",
            "0.2: 8/8 done in 0.016 minutes\n",
            "0.3: 1/8 done in 0.021 minutes\n",
            "0.3: 2/8 done in 0.021 minutes\n",
            "0.3: 3/8 done in 0.021 minutes\n",
            "0.3: 4/8 done in 0.02 minutes\n",
            "0.3: 5/8 done in 0.02 minutes\n",
            "0.3: 6/8 done in 0.021 minutes\n",
            "0.3: 7/8 done in 0.021 minutes\n",
            "0.3: 8/8 done in 0.02 minutes\n",
            "0.4: 1/8 done in 0.023 minutes\n",
            "0.4: 2/8 done in 0.023 minutes\n",
            "0.4: 3/8 done in 0.023 minutes\n",
            "0.4: 4/8 done in 0.023 minutes\n",
            "0.4: 5/8 done in 0.023 minutes\n",
            "0.4: 6/8 done in 0.023 minutes\n",
            "0.4: 7/8 done in 0.023 minutes\n",
            "0.4: 8/8 done in 0.023 minutes\n",
            "0.5: 1/8 done in 0.026 minutes\n",
            "0.5: 2/8 done in 0.025 minutes\n",
            "0.5: 3/8 done in 0.025 minutes\n",
            "0.5: 4/8 done in 0.026 minutes\n",
            "0.5: 5/8 done in 0.026 minutes\n",
            "0.5: 6/8 done in 0.026 minutes\n",
            "0.5: 7/8 done in 0.026 minutes\n",
            "0.5: 8/8 done in 0.025 minutes\n",
            "Total time: 0.857 minutes\n"
          ]
        }
      ],
      "id": "coqYCLmfbZ2P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Random"
      ],
      "metadata": {
        "id": "NgAZC_hNbZ2P"
      },
      "id": "NgAZC_hNbZ2P"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[2]\n",
        "_scores_matrix_levenshtein5_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "Spmer66AbZ2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6cd51b-d314-4d51-ee3e-61a2a8fc88f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.036 minutes\n",
            "0.05: 2/8 done in 0.036 minutes\n",
            "0.05: 3/8 done in 0.037 minutes\n",
            "0.05: 4/8 done in 0.037 minutes\n",
            "0.05: 5/8 done in 0.037 minutes\n",
            "0.05: 6/8 done in 0.037 minutes\n",
            "0.05: 7/8 done in 0.037 minutes\n",
            "0.05: 8/8 done in 0.037 minutes\n",
            "0.1: 1/8 done in 0.126 minutes\n",
            "0.1: 2/8 done in 0.129 minutes\n",
            "0.1: 3/8 done in 0.128 minutes\n",
            "0.1: 4/8 done in 0.126 minutes\n",
            "0.1: 5/8 done in 0.129 minutes\n",
            "0.1: 6/8 done in 0.124 minutes\n",
            "0.1: 7/8 done in 0.143 minutes\n",
            "0.1: 8/8 done in 0.133 minutes\n",
            "0.2: 1/8 done in 0.553 minutes\n",
            "0.2: 2/8 done in 0.543 minutes\n",
            "0.2: 3/8 done in 0.517 minutes\n",
            "0.2: 4/8 done in 0.537 minutes\n",
            "0.2: 5/8 done in 0.51 minutes\n",
            "0.2: 6/8 done in 0.567 minutes\n",
            "0.2: 7/8 done in 0.556 minutes\n",
            "0.2: 8/8 done in 0.544 minutes\n",
            "0.3: 1/8 done in 1.301 minutes\n",
            "0.3: 2/8 done in 1.218 minutes\n",
            "0.3: 3/8 done in 1.201 minutes\n",
            "0.3: 4/8 done in 1.289 minutes\n",
            "0.3: 5/8 done in 1.298 minutes\n",
            "0.3: 6/8 done in 1.228 minutes\n",
            "0.3: 7/8 done in 1.198 minutes\n",
            "0.3: 8/8 done in 1.16 minutes\n",
            "0.4: 1/8 done in 2.146 minutes\n",
            "0.4: 2/8 done in 2.133 minutes\n",
            "0.4: 3/8 done in 2.148 minutes\n",
            "0.4: 4/8 done in 2.152 minutes\n",
            "0.4: 5/8 done in 2.252 minutes\n",
            "0.4: 6/8 done in 2.269 minutes\n",
            "0.4: 7/8 done in 2.282 minutes\n",
            "0.4: 8/8 done in 2.085 minutes\n",
            "0.5: 1/8 done in 3.683 minutes\n",
            "0.5: 2/8 done in 3.602 minutes\n",
            "0.5: 3/8 done in 3.698 minutes\n",
            "0.5: 4/8 done in 3.867 minutes\n",
            "0.5: 5/8 done in 3.667 minutes\n",
            "0.5: 6/8 done in 3.757 minutes\n",
            "0.5: 7/8 done in 3.859 minutes\n",
            "0.5: 8/8 done in 3.738 minutes\n",
            "Total time: 62.889 minutes\n"
          ]
        }
      ],
      "id": "Spmer66AbZ2P"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_{distance}-{threshold}_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(_scores_matrix_levenshtein5_avg, f)"
      ],
      "metadata": {
        "id": "FtKTh3gcoYTG"
      },
      "id": "FtKTh3gcoYTG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping (0.001)"
      ],
      "metadata": {
        "id": "abRIrQJZbZ2Q"
      },
      "id": "abRIrQJZbZ2Q"
    },
    {
      "cell_type": "code",
      "source": [
        "distance = \"DROP\"\n",
        "technique = \"DROP\"\n",
        "threshold = 0.001\n",
        "_scores_matrix_drop001_avg = {}"
      ],
      "metadata": {
        "id": "jnbQidd2bZ2Q"
      },
      "execution_count": null,
      "outputs": [],
      "id": "jnbQidd2bZ2Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distorted"
      ],
      "metadata": {
        "id": "XpB7wwFebZ2Q"
      },
      "id": "XpB7wwFebZ2Q"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[0]\n",
        "_scores_matrix_drop001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "ykrEigyxbZ2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2961d550-3642-48b6-f665-8d1d927e12ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.004 minutes\n",
            "0.05: 2/8 done in 0.004 minutes\n",
            "0.05: 3/8 done in 0.004 minutes\n",
            "0.05: 4/8 done in 0.004 minutes\n",
            "0.05: 5/8 done in 0.004 minutes\n",
            "0.05: 6/8 done in 0.004 minutes\n",
            "0.05: 7/8 done in 0.004 minutes\n",
            "0.05: 8/8 done in 0.004 minutes\n",
            "0.1: 1/8 done in 0.004 minutes\n",
            "0.1: 2/8 done in 0.004 minutes\n",
            "0.1: 3/8 done in 0.004 minutes\n",
            "0.1: 4/8 done in 0.004 minutes\n",
            "0.1: 5/8 done in 0.004 minutes\n",
            "0.1: 6/8 done in 0.004 minutes\n",
            "0.1: 7/8 done in 0.004 minutes\n",
            "0.1: 8/8 done in 0.004 minutes\n",
            "0.2: 1/8 done in 0.004 minutes\n",
            "0.2: 2/8 done in 0.004 minutes\n",
            "0.2: 3/8 done in 0.004 minutes\n",
            "0.2: 4/8 done in 0.004 minutes\n",
            "0.2: 5/8 done in 0.004 minutes\n",
            "0.2: 6/8 done in 0.004 minutes\n",
            "0.2: 7/8 done in 0.004 minutes\n",
            "0.2: 8/8 done in 0.004 minutes\n",
            "0.3: 1/8 done in 0.004 minutes\n",
            "0.3: 2/8 done in 0.004 minutes\n",
            "0.3: 3/8 done in 0.004 minutes\n",
            "0.3: 4/8 done in 0.004 minutes\n",
            "0.3: 5/8 done in 0.004 minutes\n",
            "0.3: 6/8 done in 0.004 minutes\n",
            "0.3: 7/8 done in 0.004 minutes\n",
            "0.3: 8/8 done in 0.004 minutes\n",
            "0.4: 1/8 done in 0.004 minutes\n",
            "0.4: 2/8 done in 0.004 minutes\n",
            "0.4: 3/8 done in 0.004 minutes\n",
            "0.4: 4/8 done in 0.004 minutes\n",
            "0.4: 5/8 done in 0.004 minutes\n",
            "0.4: 6/8 done in 0.004 minutes\n",
            "0.4: 7/8 done in 0.004 minutes\n",
            "0.4: 8/8 done in 0.004 minutes\n",
            "0.5: 1/8 done in 0.004 minutes\n",
            "0.5: 2/8 done in 0.004 minutes\n",
            "0.5: 3/8 done in 0.004 minutes\n",
            "0.5: 4/8 done in 0.004 minutes\n",
            "0.5: 5/8 done in 0.004 minutes\n",
            "0.5: 6/8 done in 0.004 minutes\n",
            "0.5: 7/8 done in 0.004 minutes\n",
            "0.5: 8/8 done in 0.004 minutes\n",
            "Total time: 0.184 minutes\n"
          ]
        }
      ],
      "id": "ykrEigyxbZ2Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Nonrandom"
      ],
      "metadata": {
        "id": "aV4NEfXqbZ2Q"
      },
      "id": "aV4NEfXqbZ2Q"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[1]\n",
        "_scores_matrix_drop001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "Z4JwoeeUbZ2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a4ae7d-9765-428c-c573-b17578478ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.003 minutes\n",
            "0.05: 2/8 done in 0.003 minutes\n",
            "0.05: 3/8 done in 0.004 minutes\n",
            "0.05: 4/8 done in 0.003 minutes\n",
            "0.05: 5/8 done in 0.003 minutes\n",
            "0.05: 6/8 done in 0.004 minutes\n",
            "0.05: 7/8 done in 0.004 minutes\n",
            "0.05: 8/8 done in 0.004 minutes\n",
            "0.1: 1/8 done in 0.004 minutes\n",
            "0.1: 2/8 done in 0.003 minutes\n",
            "0.1: 3/8 done in 0.004 minutes\n",
            "0.1: 4/8 done in 0.003 minutes\n",
            "0.1: 5/8 done in 0.004 minutes\n",
            "0.1: 6/8 done in 0.003 minutes\n",
            "0.1: 7/8 done in 0.004 minutes\n",
            "0.1: 8/8 done in 0.003 minutes\n",
            "0.2: 1/8 done in 0.004 minutes\n",
            "0.2: 2/8 done in 0.004 minutes\n",
            "0.2: 3/8 done in 0.004 minutes\n",
            "0.2: 4/8 done in 0.003 minutes\n",
            "0.2: 5/8 done in 0.004 minutes\n",
            "0.2: 6/8 done in 0.004 minutes\n",
            "0.2: 7/8 done in 0.004 minutes\n",
            "0.2: 8/8 done in 0.004 minutes\n",
            "0.3: 1/8 done in 0.004 minutes\n",
            "0.3: 2/8 done in 0.004 minutes\n",
            "0.3: 3/8 done in 0.004 minutes\n",
            "0.3: 4/8 done in 0.004 minutes\n",
            "0.3: 5/8 done in 0.004 minutes\n",
            "0.3: 6/8 done in 0.004 minutes\n",
            "0.3: 7/8 done in 0.004 minutes\n",
            "0.3: 8/8 done in 0.004 minutes\n",
            "0.4: 1/8 done in 0.004 minutes\n",
            "0.4: 2/8 done in 0.004 minutes\n",
            "0.4: 3/8 done in 0.004 minutes\n",
            "0.4: 4/8 done in 0.004 minutes\n",
            "0.4: 5/8 done in 0.003 minutes\n",
            "0.4: 6/8 done in 0.004 minutes\n",
            "0.4: 7/8 done in 0.004 minutes\n",
            "0.4: 8/8 done in 0.004 minutes\n",
            "0.5: 1/8 done in 0.004 minutes\n",
            "0.5: 2/8 done in 0.004 minutes\n",
            "0.5: 3/8 done in 0.004 minutes\n",
            "0.5: 4/8 done in 0.004 minutes\n",
            "0.5: 5/8 done in 0.004 minutes\n",
            "0.5: 6/8 done in 0.004 minutes\n",
            "0.5: 7/8 done in 0.004 minutes\n",
            "0.5: 8/8 done in 0.004 minutes\n",
            "Total time: 0.173 minutes\n"
          ]
        }
      ],
      "id": "Z4JwoeeUbZ2Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Random"
      ],
      "metadata": {
        "id": "S0G9z1nBbZ2R"
      },
      "id": "S0G9z1nBbZ2R"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[2]\n",
        "_scores_matrix_drop001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "JQCDCdjHbZ2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8f775c-a5df-4ddf-8d7d-bbb106de7c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.004 minutes\n",
            "0.05: 2/8 done in 0.004 minutes\n",
            "0.05: 3/8 done in 0.004 minutes\n",
            "0.05: 4/8 done in 0.004 minutes\n",
            "0.05: 5/8 done in 0.004 minutes\n",
            "0.05: 6/8 done in 0.004 minutes\n",
            "0.05: 7/8 done in 0.004 minutes\n",
            "0.05: 8/8 done in 0.004 minutes\n",
            "0.1: 1/8 done in 0.004 minutes\n",
            "0.1: 2/8 done in 0.004 minutes\n",
            "0.1: 3/8 done in 0.004 minutes\n",
            "0.1: 4/8 done in 0.004 minutes\n",
            "0.1: 5/8 done in 0.004 minutes\n",
            "0.1: 6/8 done in 0.004 minutes\n",
            "0.1: 7/8 done in 0.004 minutes\n",
            "0.1: 8/8 done in 0.004 minutes\n",
            "0.2: 1/8 done in 0.004 minutes\n",
            "0.2: 2/8 done in 0.004 minutes\n",
            "0.2: 3/8 done in 0.004 minutes\n",
            "0.2: 4/8 done in 0.004 minutes\n",
            "0.2: 5/8 done in 0.004 minutes\n",
            "0.2: 6/8 done in 0.004 minutes\n",
            "0.2: 7/8 done in 0.004 minutes\n",
            "0.2: 8/8 done in 0.004 minutes\n",
            "0.3: 1/8 done in 0.004 minutes\n",
            "0.3: 2/8 done in 0.004 minutes\n",
            "0.3: 3/8 done in 0.004 minutes\n",
            "0.3: 4/8 done in 0.004 minutes\n",
            "0.3: 5/8 done in 0.004 minutes\n",
            "0.3: 6/8 done in 0.004 minutes\n",
            "0.3: 7/8 done in 0.004 minutes\n",
            "0.3: 8/8 done in 0.004 minutes\n",
            "0.4: 1/8 done in 0.004 minutes\n",
            "0.4: 2/8 done in 0.004 minutes\n",
            "0.4: 3/8 done in 0.004 minutes\n",
            "0.4: 4/8 done in 0.004 minutes\n",
            "0.4: 5/8 done in 0.004 minutes\n",
            "0.4: 6/8 done in 0.004 minutes\n",
            "0.4: 7/8 done in 0.004 minutes\n",
            "0.4: 8/8 done in 0.004 minutes\n",
            "0.5: 1/8 done in 0.004 minutes\n",
            "0.5: 2/8 done in 0.004 minutes\n",
            "0.5: 3/8 done in 0.004 minutes\n",
            "0.5: 4/8 done in 0.004 minutes\n",
            "0.5: 5/8 done in 0.005 minutes\n",
            "0.5: 6/8 done in 0.005 minutes\n",
            "0.5: 7/8 done in 0.005 minutes\n",
            "0.5: 8/8 done in 0.004 minutes\n",
            "Total time: 0.19 minutes\n"
          ]
        }
      ],
      "id": "JQCDCdjHbZ2R"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_{distance}-{threshold}_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(_scores_matrix_drop001_avg, f)"
      ],
      "metadata": {
        "id": "NHLxkaOsoZ0N"
      },
      "id": "NHLxkaOsoZ0N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping (0.001) (delete)"
      ],
      "metadata": {
        "id": "FxswJNXE__nq"
      },
      "id": "FxswJNXE__nq"
    },
    {
      "cell_type": "code",
      "source": [
        "distance = \"DROP_DELETE\"\n",
        "technique = \"DROP_DELETE\"\n",
        "threshold = 0.001\n",
        "_scores_matrix_drop_delete001_avg = {}"
      ],
      "metadata": {
        "id": "wa9lUZIL__nq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "wa9lUZIL__nq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distorted"
      ],
      "metadata": {
        "id": "_PufuQ_0__nr"
      },
      "id": "_PufuQ_0__nr"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[0]\n",
        "_scores_matrix_drop_delete001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "ckKpZIC6__nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a015f30-c436-4824-e067-77a4dea0ef61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.001 minutes\n",
            "0.05: 2/8 done in 0.001 minutes\n",
            "0.05: 3/8 done in 0.001 minutes\n",
            "0.05: 4/8 done in 0.001 minutes\n",
            "0.05: 5/8 done in 0.001 minutes\n",
            "0.05: 6/8 done in 0.001 minutes\n",
            "0.05: 7/8 done in 0.001 minutes\n",
            "0.05: 8/8 done in 0.001 minutes\n",
            "0.1: 1/8 done in 0.001 minutes\n",
            "0.1: 2/8 done in 0.001 minutes\n",
            "0.1: 3/8 done in 0.001 minutes\n",
            "0.1: 4/8 done in 0.001 minutes\n",
            "0.1: 5/8 done in 0.001 minutes\n",
            "0.1: 6/8 done in 0.001 minutes\n",
            "0.1: 7/8 done in 0.001 minutes\n",
            "0.1: 8/8 done in 0.001 minutes\n",
            "0.2: 1/8 done in 0.001 minutes\n",
            "0.2: 2/8 done in 0.001 minutes\n",
            "0.2: 3/8 done in 0.001 minutes\n",
            "0.2: 4/8 done in 0.001 minutes\n",
            "0.2: 5/8 done in 0.001 minutes\n",
            "0.2: 6/8 done in 0.001 minutes\n",
            "0.2: 7/8 done in 0.001 minutes\n",
            "0.2: 8/8 done in 0.001 minutes\n",
            "0.3: 1/8 done in 0.001 minutes\n",
            "0.3: 2/8 done in 0.001 minutes\n",
            "0.3: 3/8 done in 0.001 minutes\n",
            "0.3: 4/8 done in 0.001 minutes\n",
            "0.3: 5/8 done in 0.001 minutes\n",
            "0.3: 6/8 done in 0.001 minutes\n",
            "0.3: 7/8 done in 0.001 minutes\n",
            "0.3: 8/8 done in 0.001 minutes\n",
            "0.4: 1/8 done in 0.001 minutes\n",
            "0.4: 2/8 done in 0.001 minutes\n",
            "0.4: 3/8 done in 0.001 minutes\n",
            "0.4: 4/8 done in 0.001 minutes\n",
            "0.4: 5/8 done in 0.001 minutes\n",
            "0.4: 6/8 done in 0.001 minutes\n",
            "0.4: 7/8 done in 0.001 minutes\n",
            "0.4: 8/8 done in 0.001 minutes\n",
            "0.5: 1/8 done in 0.001 minutes\n",
            "0.5: 2/8 done in 0.001 minutes\n",
            "0.5: 3/8 done in 0.001 minutes\n",
            "0.5: 4/8 done in 0.001 minutes\n",
            "0.5: 5/8 done in 0.001 minutes\n",
            "0.5: 6/8 done in 0.001 minutes\n",
            "0.5: 7/8 done in 0.001 minutes\n",
            "0.5: 8/8 done in 0.001 minutes\n",
            "Total time: 0.046 minutes\n"
          ]
        }
      ],
      "id": "ckKpZIC6__nr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Nonrandom"
      ],
      "metadata": {
        "id": "Go7EfOhh__nr"
      },
      "id": "Go7EfOhh__nr"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[1]\n",
        "_scores_matrix_drop_delete001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "Yj8VPiU___nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711efa79-e667-4164-e4f1-995ca3db9ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.001 minutes\n",
            "0.05: 2/8 done in 0.001 minutes\n",
            "0.05: 3/8 done in 0.001 minutes\n",
            "0.05: 4/8 done in 0.001 minutes\n",
            "0.05: 5/8 done in 0.001 minutes\n",
            "0.05: 6/8 done in 0.001 minutes\n",
            "0.05: 7/8 done in 0.001 minutes\n",
            "0.05: 8/8 done in 0.001 minutes\n",
            "0.1: 1/8 done in 0.001 minutes\n",
            "0.1: 2/8 done in 0.001 minutes\n",
            "0.1: 3/8 done in 0.001 minutes\n",
            "0.1: 4/8 done in 0.001 minutes\n",
            "0.1: 5/8 done in 0.001 minutes\n",
            "0.1: 6/8 done in 0.001 minutes\n",
            "0.1: 7/8 done in 0.001 minutes\n",
            "0.1: 8/8 done in 0.001 minutes\n",
            "0.2: 1/8 done in 0.001 minutes\n",
            "0.2: 2/8 done in 0.001 minutes\n",
            "0.2: 3/8 done in 0.001 minutes\n",
            "0.2: 4/8 done in 0.001 minutes\n",
            "0.2: 5/8 done in 0.001 minutes\n",
            "0.2: 6/8 done in 0.001 minutes\n",
            "0.2: 7/8 done in 0.001 minutes\n",
            "0.2: 8/8 done in 0.001 minutes\n",
            "0.3: 1/8 done in 0.001 minutes\n",
            "0.3: 2/8 done in 0.001 minutes\n",
            "0.3: 3/8 done in 0.001 minutes\n",
            "0.3: 4/8 done in 0.001 minutes\n",
            "0.3: 5/8 done in 0.001 minutes\n",
            "0.3: 6/8 done in 0.001 minutes\n",
            "0.3: 7/8 done in 0.001 minutes\n",
            "0.3: 8/8 done in 0.001 minutes\n",
            "0.4: 1/8 done in 0.001 minutes\n",
            "0.4: 2/8 done in 0.001 minutes\n",
            "0.4: 3/8 done in 0.001 minutes\n",
            "0.4: 4/8 done in 0.001 minutes\n",
            "0.4: 5/8 done in 0.001 minutes\n",
            "0.4: 6/8 done in 0.001 minutes\n",
            "0.4: 7/8 done in 0.001 minutes\n",
            "0.4: 8/8 done in 0.001 minutes\n",
            "0.5: 1/8 done in 0.001 minutes\n",
            "0.5: 2/8 done in 0.001 minutes\n",
            "0.5: 3/8 done in 0.001 minutes\n",
            "0.5: 4/8 done in 0.001 minutes\n",
            "0.5: 5/8 done in 0.001 minutes\n",
            "0.5: 6/8 done in 0.001 minutes\n",
            "0.5: 7/8 done in 0.001 minutes\n",
            "0.5: 8/8 done in 0.001 minutes\n",
            "Total time: 0.048 minutes\n"
          ]
        }
      ],
      "id": "Yj8VPiU___nr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polluted Random"
      ],
      "metadata": {
        "id": "K_fxgtvR__nr"
      },
      "id": "K_fxgtvR__nr"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_type = pollution_types[2]\n",
        "_scores_matrix_drop_delete001_avg[pollution_type] = cleaning(pollution_type, ref, technique, distance, threshold, dataset=dataset)"
      ],
      "metadata": {
        "id": "_TYxcHg___ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed9aa31-27fa-46cd-f822-f5e28489e0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.001 minutes\n",
            "0.05: 2/8 done in 0.001 minutes\n",
            "0.05: 3/8 done in 0.001 minutes\n",
            "0.05: 4/8 done in 0.001 minutes\n",
            "0.05: 5/8 done in 0.001 minutes\n",
            "0.05: 6/8 done in 0.001 minutes\n",
            "0.05: 7/8 done in 0.001 minutes\n",
            "0.05: 8/8 done in 0.001 minutes\n",
            "0.1: 1/8 done in 0.001 minutes\n",
            "0.1: 2/8 done in 0.001 minutes\n",
            "0.1: 3/8 done in 0.001 minutes\n",
            "0.1: 4/8 done in 0.001 minutes\n",
            "0.1: 5/8 done in 0.001 minutes\n",
            "0.1: 6/8 done in 0.001 minutes\n",
            "0.1: 7/8 done in 0.001 minutes\n",
            "0.1: 8/8 done in 0.001 minutes\n",
            "0.2: 1/8 done in 0.001 minutes\n",
            "0.2: 2/8 done in 0.001 minutes\n",
            "0.2: 3/8 done in 0.001 minutes\n",
            "0.2: 4/8 done in 0.001 minutes\n",
            "0.2: 5/8 done in 0.001 minutes\n",
            "0.2: 6/8 done in 0.001 minutes\n",
            "0.2: 7/8 done in 0.001 minutes\n",
            "0.2: 8/8 done in 0.001 minutes\n",
            "0.3: 1/8 done in 0.001 minutes\n",
            "0.3: 2/8 done in 0.001 minutes\n",
            "0.3: 3/8 done in 0.001 minutes\n",
            "0.3: 4/8 done in 0.001 minutes\n",
            "0.3: 5/8 done in 0.001 minutes\n",
            "0.3: 6/8 done in 0.001 minutes\n",
            "0.3: 7/8 done in 0.001 minutes\n",
            "0.3: 8/8 done in 0.001 minutes\n",
            "0.4: 1/8 done in 0.001 minutes\n",
            "0.4: 2/8 done in 0.001 minutes\n",
            "0.4: 3/8 done in 0.001 minutes\n",
            "0.4: 4/8 done in 0.001 minutes\n",
            "0.4: 5/8 done in 0.001 minutes\n",
            "0.4: 6/8 done in 0.001 minutes\n",
            "0.4: 7/8 done in 0.001 minutes\n",
            "0.4: 8/8 done in 0.001 minutes\n",
            "0.5: 1/8 done in 0.001 minutes\n",
            "0.5: 2/8 done in 0.001 minutes\n",
            "0.5: 3/8 done in 0.001 minutes\n",
            "0.5: 4/8 done in 0.001 minutes\n",
            "0.5: 5/8 done in 0.001 minutes\n",
            "0.5: 6/8 done in 0.001 minutes\n",
            "0.5: 7/8 done in 0.001 minutes\n",
            "0.5: 8/8 done in 0.001 minutes\n",
            "Total time: 0.048 minutes\n"
          ]
        }
      ],
      "id": "_TYxcHg___ns"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_{technique}-{threshold}_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(_scores_matrix_drop_delete001_avg, f)"
      ],
      "metadata": {
        "id": "lycmUyrQ__ns"
      },
      "execution_count": null,
      "outputs": [],
      "id": "lycmUyrQ__ns"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Credit (WIP)"
      ],
      "metadata": {
        "id": "ON3wOXABfM7r"
      },
      "id": "ON3wOXABfM7r"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_types = [\"DISTORTED-activity\", \"POLLUTED.NORND-activity\", \"POLLUTED.RANDOM-activity\", \"SYNONYM\", \"HOMONYM\"]"
      ],
      "metadata": {
        "id": "3GAx4fRofT2m"
      },
      "id": "3GAx4fRofT2m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "Z5s8KDGOfM7r"
      },
      "id": "Z5s8KDGOfM7r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defines"
      ],
      "metadata": {
        "id": "nhXALg4tfM7s"
      },
      "id": "nhXALg4tfM7s"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"Credit\""
      ],
      "metadata": {
        "id": "kPNKrtH5fM7s"
      },
      "execution_count": null,
      "outputs": [],
      "id": "kPNKrtH5fM7s"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "directory_path = f'./{dataset}/{dataset}/{dataset}_prepared/'\n",
        "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-12T09:24:23.706194Z",
          "start_time": "2024-07-12T09:24:23.701590Z"
        },
        "id": "jtgwQ4HJfM7s"
      },
      "execution_count": null,
      "id": "jtgwQ4HJfM7s"
    },
    {
      "cell_type": "code",
      "source": [
        "files.remove(f'{dataset}-TRAIN-CLEAN.csv')"
      ],
      "metadata": {
        "id": "5oFe-GrMfM7s"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5oFe-GrMfM7s"
    },
    {
      "cell_type": "code",
      "source": [
        "df_ref = pd.read_csv(f'./{dataset}/{dataset}/{dataset}_prepared/{dataset}-TRAIN-CLEAN.csv')\n",
        "ref = df_ref.CCDOEV"
      ],
      "metadata": {
        "id": "fqTHMAP5fM7s"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fqTHMAP5fM7s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline"
      ],
      "metadata": {
        "id": "920J5bY2eHAe"
      },
      "id": "920J5bY2eHAe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute DQ metrics for all corrupted datasets, to use as a baseline\n",
        "dq_dict = {}\n",
        "for pollution_type in pollution_types:\n",
        "  dq_dict[pollution_type] = {}\n",
        "  for percentage in percentages:\n",
        "    dq_dict[pollution_type][percentage] = {}\n",
        "    for i in range(8):\n",
        "      df = pd.read_csv(f\"{directory_path}{dataset}-TRAIN-{pollution_type}-{percentage}-{i}.csv\")\n",
        "      labels = df.CCDOEV\n",
        "      dq_dict[pollution_type][percentage][i] = DQ_assess(df, dq)| dict(zip(dq_scorings, conf_matrix(ref, labels)))"
      ],
      "metadata": {
        "id": "URbywgNUeHAe"
      },
      "execution_count": null,
      "outputs": [],
      "id": "URbywgNUeHAe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Average the metrics\n",
        "dq_dict_avg = {}\n",
        "for pollution_type in pollution_types:\n",
        "  dq_dict_avg[pollution_type] = {}\n",
        "  for percentage in percentages:\n",
        "    dq_dict_avg[pollution_type][percentage] = {}\n",
        "    for metric in metrics:\n",
        "      dq_dict_avg[pollution_type][percentage][metric] = np.mean([dq_dict[pollution_type][percentage][i][metric] for i in range(8)])\n",
        "\n",
        "scorings = DQ_assess(df_ref, dq) | dict(zip(dq_scorings, conf_matrix(ref, ref)))\n",
        "\n",
        "dq_dict_avg[\"CLEAN\"] = {percentage:scorings for percentage in percentages}"
      ],
      "metadata": {
        "id": "POYy5w9weHAf"
      },
      "execution_count": null,
      "outputs": [],
      "id": "POYy5w9weHAf"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}-REF_scores_matrix_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(dq_dict_avg, f)"
      ],
      "metadata": {
        "id": "NwwIapU-eHAf"
      },
      "execution_count": null,
      "outputs": [],
      "id": "NwwIapU-eHAf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patterns comparisons"
      ],
      "metadata": {
        "id": "h4wgExh7IG49"
      },
      "id": "h4wgExh7IG49"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DISTORTED"
      ],
      "metadata": {
        "id": "CTeovmakZV5K"
      },
      "id": "CTeovmakZV5K"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_PATTERNER_DISTORTED_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(cleaning_patterns(\"DISTORTED-activity\", ref, dataset=dataset), f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy2z7DvwZBu1",
        "outputId": "fcfe2e08-eb9d-4a55-8c6e-6b6899f53ccb"
      },
      "id": "Jy2z7DvwZBu1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.091 minutes\n",
            "0.05: 2/8 done in 0.094 minutes\n",
            "0.05: 3/8 done in 0.076 minutes\n",
            "0.05: 4/8 done in 0.075 minutes\n",
            "0.05: 5/8 done in 0.074 minutes\n",
            "0.05: 6/8 done in 0.073 minutes\n",
            "0.05: 7/8 done in 0.072 minutes\n",
            "0.05: 8/8 done in 0.075 minutes\n",
            "0.1: 1/8 done in 0.121 minutes\n",
            "0.1: 2/8 done in 0.121 minutes\n",
            "0.1: 3/8 done in 0.128 minutes\n",
            "0.1: 4/8 done in 0.126 minutes\n",
            "0.1: 5/8 done in 0.122 minutes\n",
            "0.1: 6/8 done in 0.121 minutes\n",
            "0.1: 7/8 done in 0.121 minutes\n",
            "0.1: 8/8 done in 0.12 minutes\n",
            "0.2: 1/8 done in 0.245 minutes\n",
            "0.2: 2/8 done in 0.245 minutes\n",
            "0.2: 3/8 done in 0.254 minutes\n",
            "0.2: 4/8 done in 0.25 minutes\n",
            "0.2: 5/8 done in 0.251 minutes\n",
            "0.2: 6/8 done in 0.249 minutes\n",
            "0.2: 7/8 done in 0.255 minutes\n",
            "0.2: 8/8 done in 0.24 minutes\n",
            "0.3: 1/8 done in 0.352 minutes\n",
            "0.3: 2/8 done in 0.356 minutes\n",
            "0.3: 3/8 done in 0.359 minutes\n",
            "0.3: 4/8 done in 0.377 minutes\n",
            "0.3: 5/8 done in 0.354 minutes\n",
            "0.3: 6/8 done in 0.369 minutes\n",
            "0.3: 7/8 done in 0.374 minutes\n",
            "0.3: 8/8 done in 0.361 minutes\n",
            "0.4: 1/8 done in 0.498 minutes\n",
            "0.4: 2/8 done in 0.499 minutes\n",
            "0.4: 3/8 done in 0.496 minutes\n",
            "0.4: 4/8 done in 0.506 minutes\n",
            "0.4: 5/8 done in 0.499 minutes\n",
            "0.4: 6/8 done in 0.493 minutes\n",
            "0.4: 7/8 done in 0.495 minutes\n",
            "0.4: 8/8 done in 0.49 minutes\n",
            "0.5: 1/8 done in 0.524 minutes\n",
            "0.5: 2/8 done in 0.433 minutes\n",
            "0.5: 3/8 done in 0.425 minutes\n",
            "0.5: 4/8 done in 0.436 minutes\n",
            "0.5: 5/8 done in 0.41 minutes\n",
            "0.5: 6/8 done in 0.438 minutes\n",
            "0.5: 7/8 done in 0.42 minutes\n",
            "0.5: 8/8 done in 0.429 minutes\n",
            "Total time: 13.992 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SYNONYMOUS"
      ],
      "metadata": {
        "id": "vypNN_ByIMw-"
      },
      "id": "vypNN_ByIMw-"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_PATTERNER_SYNONYM_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(cleaning_patterns(\"SYNONYM\", ref, dataset=dataset), f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcpR5HJtKkDK",
        "outputId": "0d400e24-a6d7-424f-870a-a5688cdc7133"
      },
      "id": "YcpR5HJtKkDK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.016 minutes\n",
            "0.05: 2/8 done in 0.016 minutes\n",
            "0.05: 3/8 done in 0.016 minutes\n",
            "0.05: 4/8 done in 0.016 minutes\n",
            "0.05: 5/8 done in 0.016 minutes\n",
            "0.05: 6/8 done in 0.016 minutes\n",
            "0.05: 7/8 done in 0.016 minutes\n",
            "0.05: 8/8 done in 0.016 minutes\n",
            "0.1: 1/8 done in 0.017 minutes\n",
            "0.1: 2/8 done in 0.017 minutes\n",
            "0.1: 3/8 done in 0.017 minutes\n",
            "0.1: 4/8 done in 0.017 minutes\n",
            "0.1: 5/8 done in 0.017 minutes\n",
            "0.1: 6/8 done in 0.017 minutes\n",
            "0.1: 7/8 done in 0.017 minutes\n",
            "0.1: 8/8 done in 0.017 minutes\n",
            "0.2: 1/8 done in 0.019 minutes\n",
            "0.2: 2/8 done in 0.018 minutes\n",
            "0.2: 3/8 done in 0.019 minutes\n",
            "0.2: 4/8 done in 0.019 minutes\n",
            "0.2: 5/8 done in 0.018 minutes\n",
            "0.2: 6/8 done in 0.018 minutes\n",
            "0.2: 7/8 done in 0.019 minutes\n",
            "0.2: 8/8 done in 0.019 minutes\n",
            "0.3: 1/8 done in 0.019 minutes\n",
            "0.3: 2/8 done in 0.019 minutes\n",
            "0.3: 3/8 done in 0.019 minutes\n",
            "0.3: 4/8 done in 0.019 minutes\n",
            "0.3: 5/8 done in 0.019 minutes\n",
            "0.3: 6/8 done in 0.019 minutes\n",
            "0.3: 7/8 done in 0.019 minutes\n",
            "0.3: 8/8 done in 0.019 minutes\n",
            "0.4: 1/8 done in 0.023 minutes\n",
            "0.4: 2/8 done in 0.024 minutes\n",
            "0.4: 3/8 done in 0.024 minutes\n",
            "0.4: 4/8 done in 0.024 minutes\n",
            "0.4: 5/8 done in 0.023 minutes\n",
            "0.4: 6/8 done in 0.023 minutes\n",
            "0.4: 7/8 done in 0.023 minutes\n",
            "0.4: 8/8 done in 0.023 minutes\n",
            "0.5: 1/8 done in 0.021 minutes\n",
            "0.5: 2/8 done in 0.022 minutes\n",
            "0.5: 3/8 done in 0.021 minutes\n",
            "0.5: 4/8 done in 0.021 minutes\n",
            "0.5: 5/8 done in 0.021 minutes\n",
            "0.5: 6/8 done in 0.022 minutes\n",
            "0.5: 7/8 done in 0.022 minutes\n",
            "0.5: 8/8 done in 0.022 minutes\n",
            "Total time: 0.923 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###HOMONYMOUS"
      ],
      "metadata": {
        "id": "3rXkwOZDIOmt"
      },
      "id": "3rXkwOZDIOmt"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_PATTERNER_HOMONYM_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(cleaning_patterns(\"HOMONYM\", ref, dataset=dataset), f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nObR-RcaLXHk",
        "outputId": "ffd54a0a-29a5-441e-ce4a-3416c401f8cb"
      },
      "id": "nObR-RcaLXHk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.013 minutes\n",
            "0.05: 2/8 done in 0.013 minutes\n",
            "0.05: 3/8 done in 0.013 minutes\n",
            "0.05: 4/8 done in 0.013 minutes\n",
            "0.05: 5/8 done in 0.013 minutes\n",
            "0.05: 6/8 done in 0.013 minutes\n",
            "0.05: 7/8 done in 0.013 minutes\n",
            "0.05: 8/8 done in 0.013 minutes\n",
            "0.1: 1/8 done in 0.013 minutes\n",
            "0.1: 2/8 done in 0.013 minutes\n",
            "0.1: 3/8 done in 0.013 minutes\n",
            "0.1: 4/8 done in 0.013 minutes\n",
            "0.1: 5/8 done in 0.013 minutes\n",
            "0.1: 6/8 done in 0.013 minutes\n",
            "0.1: 7/8 done in 0.013 minutes\n",
            "0.1: 8/8 done in 0.013 minutes\n",
            "0.2: 1/8 done in 0.013 minutes\n",
            "0.2: 2/8 done in 0.013 minutes\n",
            "0.2: 3/8 done in 0.013 minutes\n",
            "0.2: 4/8 done in 0.013 minutes\n",
            "0.2: 5/8 done in 0.013 minutes\n",
            "0.2: 6/8 done in 0.013 minutes\n",
            "0.2: 7/8 done in 0.013 minutes\n",
            "0.2: 8/8 done in 0.013 minutes\n",
            "0.3: 1/8 done in 0.013 minutes\n",
            "0.3: 2/8 done in 0.013 minutes\n",
            "0.3: 3/8 done in 0.013 minutes\n",
            "0.3: 4/8 done in 0.013 minutes\n",
            "0.3: 5/8 done in 0.013 minutes\n",
            "0.3: 6/8 done in 0.014 minutes\n",
            "0.3: 7/8 done in 0.013 minutes\n",
            "0.3: 8/8 done in 0.013 minutes\n",
            "0.4: 1/8 done in 0.013 minutes\n",
            "0.4: 2/8 done in 0.013 minutes\n",
            "0.4: 3/8 done in 0.013 minutes\n",
            "0.4: 4/8 done in 0.013 minutes\n",
            "0.4: 5/8 done in 0.013 minutes\n",
            "0.4: 6/8 done in 0.013 minutes\n",
            "0.4: 7/8 done in 0.013 minutes\n",
            "0.4: 8/8 done in 0.013 minutes\n",
            "0.5: 1/8 done in 0.013 minutes\n",
            "0.5: 2/8 done in 0.013 minutes\n",
            "0.5: 3/8 done in 0.013 minutes\n",
            "0.5: 4/8 done in 0.013 minutes\n",
            "0.5: 5/8 done in 0.013 minutes\n",
            "0.5: 6/8 done in 0.013 minutes\n",
            "0.5: 7/8 done in 0.013 minutes\n",
            "0.5: 8/8 done in 0.013 minutes\n",
            "Total time: 0.618 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pub (WIP)"
      ],
      "metadata": {
        "id": "00A2kPwbdpKR"
      },
      "id": "00A2kPwbdpKR"
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_types = [\"SYNONYM\"]"
      ],
      "metadata": {
        "id": "GbKChtWudpKV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "GbKChtWudpKV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "HWs3dQymdpKW"
      },
      "id": "HWs3dQymdpKW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defines"
      ],
      "metadata": {
        "id": "QiDk921CdpKW"
      },
      "id": "QiDk921CdpKW"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"Pub\""
      ],
      "metadata": {
        "id": "QerochYldpKW"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QerochYldpKW"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "directory_path = f'./{dataset}/{dataset}/{dataset}_prepared/'\n",
        "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-12T09:24:23.706194Z",
          "start_time": "2024-07-12T09:24:23.701590Z"
        },
        "id": "lNSDH7JedpKW"
      },
      "execution_count": null,
      "id": "lNSDH7JedpKW"
    },
    {
      "cell_type": "code",
      "source": [
        "files.remove(f'{dataset}-TRAIN-CLEAN.csv')"
      ],
      "metadata": {
        "id": "NHUNyR5VdpKW"
      },
      "execution_count": null,
      "outputs": [],
      "id": "NHUNyR5VdpKW"
    },
    {
      "cell_type": "code",
      "source": [
        "df_ref = pd.read_csv(f'./{dataset}/{dataset}/{dataset}_prepared/{dataset}-TRAIN-CLEAN.csv')\n",
        "ref = df_ref.CCDOEV"
      ],
      "metadata": {
        "id": "MF50I1S9dpKW"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MF50I1S9dpKW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline"
      ],
      "metadata": {
        "id": "d0Dkk5Q5eJy7"
      },
      "id": "d0Dkk5Q5eJy7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute DQ metrics for all corrupted datasets, to use as a baseline\n",
        "dq_dict = {}\n",
        "for pollution_type in pollution_types:\n",
        "  dq_dict[pollution_type] = {}\n",
        "  for percentage in percentages:\n",
        "    dq_dict[pollution_type][percentage] = {}\n",
        "    for i in range(8):\n",
        "      df = pd.read_csv(f\"{directory_path}{dataset}-TRAIN-{pollution_type}-{percentage}-{i}.csv\")\n",
        "      labels = df.CCDOEV\n",
        "      dq_dict[pollution_type][percentage][i] = DQ_assess(df, dq)| dict(zip(dq_scorings, conf_matrix(ref, labels)))"
      ],
      "metadata": {
        "id": "9u7sYajCeJy8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "9u7sYajCeJy8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Average the metrics\n",
        "dq_dict_avg = {}\n",
        "for pollution_type in pollution_types:\n",
        "  dq_dict_avg[pollution_type] = {}\n",
        "  for percentage in percentages:\n",
        "    dq_dict_avg[pollution_type][percentage] = {}\n",
        "    for metric in metrics:\n",
        "      dq_dict_avg[pollution_type][percentage][metric] = np.mean([dq_dict[pollution_type][percentage][i][metric] for i in range(8)])\n",
        "\n",
        "scorings = DQ_assess(df_ref, dq) | dict(zip(dq_scorings, conf_matrix(ref, ref)))\n",
        "\n",
        "dq_dict_avg[\"CLEAN\"] = {percentage:scorings for percentage in percentages}"
      ],
      "metadata": {
        "id": "pL8NBcs3eJy8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pL8NBcs3eJy8"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}-REF_scores_matrix_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(dq_dict_avg, f)"
      ],
      "metadata": {
        "id": "iHqHbPlneJy8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "iHqHbPlneJy8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patterns comparisons"
      ],
      "metadata": {
        "id": "Xvh-FDJwLbbJ"
      },
      "id": "Xvh-FDJwLbbJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SYNONYMOUS"
      ],
      "metadata": {
        "id": "yMwxB1boLeCc"
      },
      "id": "yMwxB1boLeCc"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"./{dataset}/{dataset}/{dataset}_scores_matrix_PATTERNER_SYNONYM_avg.pickle\", \"wb\") as f:\n",
        "  pickle.dump(cleaning_patterns(\"SYNONYM\", ref, dataset=dataset), f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLODOOo2LeCd",
        "outputId": "307f8e52-7546-4a38-9435-5a88464d06f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05: 1/8 done in 0.016 minutes\n",
            "0.05: 2/8 done in 0.016 minutes\n",
            "0.05: 3/8 done in 0.016 minutes\n",
            "0.05: 4/8 done in 0.016 minutes\n",
            "0.05: 5/8 done in 0.016 minutes\n",
            "0.05: 6/8 done in 0.017 minutes\n",
            "0.05: 7/8 done in 0.015 minutes\n",
            "0.05: 8/8 done in 0.015 minutes\n",
            "0.1: 1/8 done in 0.016 minutes\n",
            "0.1: 2/8 done in 0.017 minutes\n",
            "0.1: 3/8 done in 0.017 minutes\n",
            "0.1: 4/8 done in 0.017 minutes\n",
            "0.1: 5/8 done in 0.016 minutes\n",
            "0.1: 6/8 done in 0.016 minutes\n",
            "0.1: 7/8 done in 0.017 minutes\n",
            "0.1: 8/8 done in 0.017 minutes\n",
            "0.2: 1/8 done in 0.018 minutes\n",
            "0.2: 2/8 done in 0.018 minutes\n",
            "0.2: 3/8 done in 0.018 minutes\n",
            "0.2: 4/8 done in 0.018 minutes\n",
            "0.2: 5/8 done in 0.018 minutes\n",
            "0.2: 6/8 done in 0.018 minutes\n",
            "0.2: 7/8 done in 0.018 minutes\n",
            "0.2: 8/8 done in 0.019 minutes\n",
            "0.3: 1/8 done in 0.029 minutes\n",
            "0.3: 2/8 done in 0.027 minutes\n",
            "0.3: 3/8 done in 0.027 minutes\n",
            "0.3: 4/8 done in 0.029 minutes\n",
            "0.3: 5/8 done in 0.027 minutes\n",
            "0.3: 6/8 done in 0.027 minutes\n",
            "0.3: 7/8 done in 0.028 minutes\n",
            "0.3: 8/8 done in 0.029 minutes\n",
            "0.4: 1/8 done in 0.03 minutes\n",
            "0.4: 2/8 done in 0.028 minutes\n",
            "0.4: 3/8 done in 0.031 minutes\n",
            "0.4: 4/8 done in 0.031 minutes\n",
            "0.4: 5/8 done in 0.029 minutes\n",
            "0.4: 6/8 done in 0.03 minutes\n",
            "0.4: 7/8 done in 0.03 minutes\n",
            "0.4: 8/8 done in 0.03 minutes\n",
            "0.5: 1/8 done in 0.029 minutes\n",
            "0.5: 2/8 done in 0.029 minutes\n",
            "0.5: 3/8 done in 0.029 minutes\n",
            "0.5: 4/8 done in 0.029 minutes\n",
            "0.5: 5/8 done in 0.029 minutes\n",
            "0.5: 6/8 done in 0.029 minutes\n",
            "0.5: 7/8 done in 0.03 minutes\n",
            "0.5: 8/8 done in 0.029 minutes\n",
            "Total time: 1.099 minutes\n"
          ]
        }
      ],
      "id": "DLODOOo2LeCd"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}